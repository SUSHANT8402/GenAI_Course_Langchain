{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cd78ea",
   "metadata": {},
   "source": [
    "### Text Pre-processing using stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3451d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript=\"\"\"\n",
    "Hello guys.\n",
    "\n",
    "So we'll be continuing the discussion.\n",
    "\n",
    "With respect to natural language processing.\n",
    "\n",
    "We are still in text pre-processing techniques.\n",
    "\n",
    "We have seen tokenization.\n",
    "\n",
    "We have seen stemming.\n",
    "\n",
    "We have also seen its different types.\n",
    "\n",
    "Along with that we have seen Lemmatization.\n",
    "\n",
    "Now we are going to consider a topic which is called as Stopwords.\n",
    "\n",
    "So in this video I'm going to discuss about Stopwords the importance of Stopwords.\n",
    "\n",
    "And again I'll show you with the help of NLTK.\n",
    "\n",
    "Now, text processing is a very important step in natural language processing because you really need\n",
    "\n",
    "to clean the data.\n",
    "\n",
    "You need to make the data in the right format.\n",
    "\n",
    "Later on, we'll try to convert all this text data into vectors, and then only we'll be able to train\n",
    "\n",
    "the model.\n",
    "\n",
    "Because model you know, whenever we say any machine learning model internally we really need to train\n",
    "\n",
    "with some mathematical equations.\n",
    "\n",
    "So whenever we train something with mathematical equations there, we really need to give the input\n",
    "\n",
    "data in the form of numerical or floating values.\n",
    "\n",
    "So let us go ahead and let's us understand what exactly Stopwords is.\n",
    "\n",
    "So I have opened a new notebook file over here.\n",
    "\n",
    "So here I have one amazing speech from doctor APJ Abdul Kalam.\n",
    "\n",
    "He was the former President of India and it was an amazing speech.\n",
    "\n",
    "You can probably read out completely over here and obviously it is given in the materials.\n",
    "\n",
    "Now, what I'm actually going to do is that I'm going to probably talk about Stopwords and why it is\n",
    "\n",
    "important that we should try to remove the stop words.\n",
    "\n",
    "Okay.\n",
    "\n",
    "And, uh, just for a definition, what exactly stop words.\n",
    "\n",
    "Now, here in this particular speech, you can see that, uh, there are a lot of sentences like, I\n",
    "\n",
    "have three visions for India in 3000 years of our history, people from all over the world have come\n",
    "\n",
    "and invaded us.\n",
    "\n",
    "So this is the entire speech.\n",
    "\n",
    "It is an amazing speech.\n",
    "\n",
    "If you are probably learning it, I would like to just, uh, tell you that.\n",
    "\n",
    "Please read this.\n",
    "\n",
    "You'll be getting a lot of information out of it.\n",
    "\n",
    "Very motivational speech altogether.\n",
    "\n",
    "Now, from this particular speech, you can see that.\n",
    "\n",
    "And I can definitely say this as paragraph or corpus right now here there are some words like I the\n",
    "\n",
    "have and, you know, uh, let's say off uh, the you know, two there y right.\n",
    "\n",
    "All this kind of words, right?\n",
    "\n",
    "It will not play a very big role when we are doing a task like spam classification.\n",
    "\n",
    "Or let's say if you are trying to do some kind of task with respect to, uh, you know, uh, like spam\n",
    "\n",
    "or ham classification, I have already told about that.\n",
    "\n",
    "And uh, along with that, to just see that whether this is a positive review or negative review, but\n",
    "\n",
    "some of the words like not can actually play a very important role.\n",
    "\n",
    "Not and all.\n",
    "\n",
    "So what we do is that with the help of stop words, you know, we try to remove this particular words\n",
    "\n",
    "because, uh, with this kind of use cases where you are specifically focusing on some of the important\n",
    "\n",
    "words to determine the output, this is all words like I the he she off there is not at all required.\n",
    "\n",
    "So what we can do is that we can basically pass this entire paragraph to that particular stop words\n",
    "\n",
    "and see that what all words can be basically removed, okay.\n",
    "\n",
    "And that is the importance of stopwords in short.\n",
    "\n",
    "So let us go ahead right now.\n",
    "\n",
    "I'll just go ahead and execute it.\n",
    "\n",
    "Let me make some cells so that it will be very much easy for you all to understand and how we can apply\n",
    "\n",
    "Stopwords.\n",
    "\n",
    "Along with Stopwords, you can also apply stemming.\n",
    "\n",
    "So I'll show you both the combination, uh, which will be super important for everyone.\n",
    "\n",
    "Okay.\n",
    "\n",
    "So let's go ahead and let's uh, try to do that okay.\n",
    "\n",
    "Now first of all, I really need to import, uh, for stemming.\n",
    "\n",
    "You obviously know what we need to import.\n",
    "\n",
    "So from for stemming I'll write for NLTK dot stem import porter stemmer.\n",
    "\n",
    "So I can basically write Porter stemmer over here and I'll execute it along with this.\n",
    "\n",
    "Uh, I obviously need to also import Stopwords because stopwords for English, it will be different\n",
    "\n",
    "because you'll be having that entire list of words like the he, she and.\n",
    "\n",
    "All right.\n",
    "\n",
    "so what I'm going to do is that I'm going to say that from an NLP k dot corpus import stopwords.\n",
    "\n",
    "So from this I will be able to use the stopwords itself.\n",
    "\n",
    "So now I have imported uh from an antique corpus import Stopwords.\n",
    "\n",
    "Now this Stopwords, you know, I have to also download it.\n",
    "\n",
    "So for that, uh, let me do one thing.\n",
    "\n",
    "I'll also import a NLTK and I will execute it.\n",
    "\n",
    "And along with that, I'll write an LCC dot download.\n",
    "\n",
    "And here in the parameter I am going to give about the stopwords.\n",
    "\n",
    "And there are different different language stopwords also.\n",
    "\n",
    "And we'll also try to see that.\n",
    "\n",
    "So if I probably write this here, you'll be able to see that downloading package Stopwords to this\n",
    "\n",
    "particular location.\n",
    "\n",
    "So the package Stopwords is already up to date and I'm getting true.\n",
    "\n",
    "So in short I've downloaded all the different different languages Stopwords which is already present\n",
    "\n",
    "in the NLTK library.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "Now we have done that.\n",
    "\n",
    "Now let's see that what are the Stopwords that are available in English?\n",
    "\n",
    "So in order to do that I am.\n",
    "\n",
    "I have already imported from NLTK corpus import stopwords.\n",
    "\n",
    "I'll take the Stopwords.\n",
    "\n",
    "I'll copy and paste it over here and I will say dot download okay or instead of download I will just\n",
    "\n",
    "write dot words.\n",
    "\n",
    "And here I just need to give my language.\n",
    "\n",
    "Like what language?\n",
    "\n",
    "I really want to, uh, give it for like English or something else, like German and all.\n",
    "\n",
    "So I'm just going to write this.\n",
    "\n",
    "Let me just write English.\n",
    "\n",
    "And if I execute this here, now you can see the list of all the stop words that you obviously have,\n",
    "\n",
    "and all the stop words can actually be removed.\n",
    "\n",
    "Right now.\n",
    "\n",
    "You may be thinking, Krish, this may depend on data to data.\n",
    "\n",
    "Right now here you can see that guys, this is a list.\n",
    "\n",
    "You can also create your own stopwords in English like let's say over here.\n",
    "\n",
    "Some of the important words are like are and couldn't.\n",
    "\n",
    "Right.\n",
    "\n",
    "These are words can actually play a very important role.\n",
    "\n",
    "Uh, to find out whether a statement is positive or negative, like not is also there.\n",
    "\n",
    "If you probably search for it not, you will also be able to find it not.\n",
    "\n",
    "Okay.\n",
    "\n",
    "So it is always a good way that you create your own stopwords and try to remove all those kind of words\n",
    "\n",
    "from the paragraph.\n",
    "\n",
    "So I hope everybody is able to understand now with respect to English, you have this.\n",
    "\n",
    "Now let's see whether we have with respect to different different language.\n",
    "\n",
    "And obviously you can go ahead and check the documentation, but I will just try to show you with respect\n",
    "\n",
    "to German.\n",
    "\n",
    "So in German also you have this specific stop words.\n",
    "\n",
    "Along with this you can also use French.\n",
    "\n",
    "You have this particular stop words.\n",
    "\n",
    "So with respect to different different texts or different different language of text, you can definitely\n",
    "\n",
    "apply different different stopwords with respect to that.\n",
    "\n",
    "Now you may be thinking, is there Hindi or Arabic or some other?\n",
    "\n",
    "I think for Arabic also, I think it is there.\n",
    "\n",
    "Let's see whether it is there or not.\n",
    "\n",
    "Yes, for Arabic also it is there, but I do not find it for Hindi I guess.\n",
    "\n",
    "So again from the documentation you can check it out.\n",
    "\n",
    "But till Arabic I was able to see it again.\n",
    "\n",
    "All the information will be given in the documentation.\n",
    "\n",
    "Now what I'm actually going to do is that my sentence is already English.\n",
    "\n",
    "Right now I'm going to perform two important tasks.\n",
    "\n",
    "One is I will apply stemming.\n",
    "\n",
    "And before applying stemming, you know what I'm actually going to do wherever I find out the stop words,\n",
    "\n",
    "I'm just going to remove the stop words from this particular paragraph so that this entire paragraph\n",
    "\n",
    "will be shortened up.\n",
    "\n",
    "Right.\n",
    "\n",
    "So for that, what I'm actually going to do.\n",
    "\n",
    "Now, see, whatever things you have learned from starting everything, I'm actually going to cover\n",
    "\n",
    "up.\n",
    "\n",
    "Okay.\n",
    "\n",
    "So first thing first I'm just going to say from NLTK dot stem I'm going to import porter stemmer.\n",
    "\n",
    "Porter stemmer.\n",
    "\n",
    "And I'll go to just execute I'm just going to execute this okay.\n",
    "\n",
    "And then what I'm actually going to do is that I'm just going to write Stemmer is equal to Porter stemmer\n",
    "\n",
    "this.\n",
    "\n",
    "We really need to initialize it.\n",
    "\n",
    "Now when we do this task right now, the next step, what I'm actually going to do is that I'm going\n",
    "\n",
    "to perform the tokenization on the entire paragraph.\n",
    "\n",
    "So for that I can use NLTK, dot, send, tokenize.\n",
    "\n",
    "And here I'm just going to give my paragraph.\n",
    "\n",
    "Now see this guys here I'm going to get my entire paragraph, entire sentences like see I have three\n",
    "\n",
    "visions for India.\n",
    "\n",
    "Then in 3000 years this all things I am able to get.\n",
    "\n",
    "And this is my second sentence.\n",
    "\n",
    "Third sentence.\n",
    "\n",
    "Fourth sentence.\n",
    "\n",
    "Like this.\n",
    "\n",
    "All the sentences in the form of list I'm able to get just by using cent underscore tokenize.\n",
    "\n",
    "Right.\n",
    "\n",
    "This is a tokenization process wherein we take a paragraph, divide that into sentences.\n",
    "\n",
    "Okay, now let me do one thing, is that I'm just going to save this in a variable which is called as\n",
    "\n",
    "sentences, which will let later become a list.\n",
    "\n",
    "Right.\n",
    "\n",
    "So this is my sentences.\n",
    "\n",
    "And if you probably see the type of sentences I'm just going to basically see this.\n",
    "\n",
    "It is a list now.\n",
    "\n",
    "Perfect till here.\n",
    "\n",
    "We have done it amazingly well right.\n",
    "\n",
    "We have done Porter Stemmer on that.\n",
    "\n",
    "Sorry.\n",
    "\n",
    "We have initialized stemmer over here and we have tokenized it.\n",
    "\n",
    "Now understand, what we are going to do is that I'm going to traverse through all the sentences.\n",
    "\n",
    "First of all, apply a stopwords which all words are not present in the stopwords we are only going\n",
    "\n",
    "to take that and apply stemming.\n",
    "\n",
    "This is what we really want to do.\n",
    "\n",
    "So here I'm saying that first of all apply stopwords and filter and then apply tokenization.\n",
    "\n",
    "Right?\n",
    "\n",
    "Sorry.\n",
    "\n",
    "Then apply stemming.\n",
    "\n",
    "So this is the step that I'm actually going to do.\n",
    "\n",
    "Now see this very simple very important.\n",
    "\n",
    "So I'll write a for loop saying that for I in range for I in range.\n",
    "\n",
    "And here I'm going to basically give the length of the sentences.\n",
    "\n",
    "I can also go with respect to sentences.\n",
    "\n",
    "But there I'll not be getting the indexes here.\n",
    "\n",
    "I'll be getting the indices.\n",
    "\n",
    "Okay, so range basically says that whatever length I'm actually giving that becomes an index, right?\n",
    "\n",
    "Zero to that specific length.\n",
    "\n",
    "Now what I'm actually going to take, I'm going to take this specific n um, I and I'm going to write\n",
    "\n",
    "n nltk dot word tokenize because I'm getting in the form of sentences, I need to get each and every\n",
    "\n",
    "word right.\n",
    "\n",
    "So I'm getting the word over here and inside word underscore tokenize I'll give I sorry sentence of\n",
    "\n",
    "I because this will be an index sentences of I.\n",
    "\n",
    "So this will be an index.\n",
    "\n",
    "And here I'll be able to get the word.\n",
    "\n",
    "So here what I'll do I'll make a list of words.\n",
    "\n",
    "So in short I'll be getting the list of words inside the sentences.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "Now till here we have done it.\n",
    "\n",
    "Now after this we are going to apply one very important thing that is.\n",
    "\n",
    "First of all, I need to apply stop words for each and every word and see whether it falls in the stop\n",
    "\n",
    "word or not.\n",
    "\n",
    "If it does not fall in the stop word, then only I have to do the stemming.\n",
    "\n",
    "So understand the task step by step.\n",
    "\n",
    "This is super important with respect to all the steps that I'm actually taking up.\n",
    "\n",
    "Okay, so here I will write a list comprehension.\n",
    "\n",
    "I will say stemmer dot stem okay.\n",
    "\n",
    "And here I'm going to write dot word okay of the word because uh from this particular words, this word\n",
    "\n",
    "is a list of words.\n",
    "\n",
    "And I have to take each and every word.\n",
    "\n",
    "So here I will write a for loop okay.\n",
    "\n",
    "And this is called as list comprehension.\n",
    "\n",
    "So I'll write for word in words if word not in see if the word is not present in the stop words then\n",
    "\n",
    "only you apply stemming.\n",
    "\n",
    "That is what I'm actually trying to do.\n",
    "\n",
    "Okay, so here you can basically see if the word is not in.\n",
    "\n",
    "I'll use a set.\n",
    "\n",
    "Along with that I will download all the all the stop words with respect to English.\n",
    "\n",
    "Right.\n",
    "\n",
    "So why I'm using step set because some of the words may get repeated.\n",
    "\n",
    "So I don't want that.\n",
    "\n",
    "So I'm going to basically write it over here right now through this.\n",
    "\n",
    "What I'm actually going to do I'll get that specific word that is not present in the stop words.\n",
    "\n",
    "And only stemming will be getting applied to that specific word.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "Now here, what I'm actually going to do is that I'm going to save it in a variable called as words\n",
    "\n",
    "perfect.\n",
    "\n",
    "I hope it is very much clear.\n",
    "\n",
    "I'm getting back everything after doing the stemming back in the words itself.\n",
    "\n",
    "And then finally, what I'm actually going to do is that I'm going to take this sentences, and I'm\n",
    "\n",
    "going to replace it on the same index with respect to this words.\n",
    "\n",
    "But once we get this words right, I need to join all these words together.\n",
    "\n",
    "So how do I join?\n",
    "\n",
    "There will obviously be a space dot.\n",
    "\n",
    "I'll just use dot join so that it will join together and it will convert that into a sentences.\n",
    "\n",
    "So this exactly is converting all the words into sentences, right.\n",
    "\n",
    "This is very much simple.\n",
    "\n",
    "And we have actually done this.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "So here what all things we have done again let me repeat I'm I'm iterating through each and every sentence.\n",
    "\n",
    "And then I'm doing a word tokenize that basically means for every sentences I'm getting the list of\n",
    "\n",
    "words.\n",
    "\n",
    "And from that list of words I'm iterating, I'm seeing that whether it is present in the stop words,\n",
    "\n",
    "if it is not present, I'm doing the stemming.\n",
    "\n",
    "After stemming, I'm again storing back in that same list, and then I'm converting all these words\n",
    "\n",
    "into sentences I can say, converting all the list of words into sentences.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "Now, once I execute it.\n",
    "\n",
    "And now if I go and see my sentences here, you'll be able to see now I three vision India right in\n",
    "\n",
    "3000 year history.\n",
    "\n",
    "Right.\n",
    "\n",
    "So here I h I s t o r y became RI okay people, people it became people.\n",
    "\n",
    "World came, invaded us, invade it, became captured.\n",
    "\n",
    "Land conquer mined from.\n",
    "\n",
    "You can see all the special words like like I, I have.\n",
    "\n",
    "Everything is gone.\n",
    "\n",
    "See, see this I is there have is gone.\n",
    "\n",
    "Right.\n",
    "\n",
    "Though you will not be able to find out though anyway, right?\n",
    "\n",
    "So whatever.\n",
    "\n",
    "Stop.\n",
    "\n",
    "Words were present over here that all got removed.\n",
    "\n",
    "And then only we performed the stemming.\n",
    "\n",
    "Right now you may be saying crush.\n",
    "\n",
    "Uh, the stemming does not look very good, right?\n",
    "\n",
    "So for that, what you need to do, I've already taught you with respect to snowball stemmer, so I\n",
    "\n",
    "will just import this.\n",
    "\n",
    "Okay.\n",
    "\n",
    "And it is very simple.\n",
    "\n",
    "Simple.\n",
    "\n",
    "I think you can do the same task again.\n",
    "\n",
    "So snowball stemmer and then I will try to import this with respect to English.\n",
    "\n",
    "And obviously after this you'll be able to get good sentence.\n",
    "\n",
    "Right.\n",
    "\n",
    "So let me just remove this one.\n",
    "\n",
    "So snowball stemmer I've already done it and I'm going to copy the same thing.\n",
    "\n",
    "Okay.\n",
    "\n",
    "And here I'm just going to say apply snowball stemmer stemming.\n",
    "\n",
    "Right.\n",
    "\n",
    "And then instead of stemmer I will just write this word that is snowball stemmer.\n",
    "\n",
    "That's it.\n",
    "\n",
    "Yeah.\n",
    "\n",
    "And now once I execute it, uh, let me go back again, back to the sentences, because that sentences\n",
    "\n",
    "have got changed now.\n",
    "\n",
    "So where is the sentences?\n",
    "\n",
    "Let's see.\n",
    "\n",
    "Okay.\n",
    "\n",
    "Now this is the sentences I've got executed now.\n",
    "\n",
    "Now I'm just going to execute this.\n",
    "\n",
    "Now if I probably go and see my sentences here, you can see that now it is good right now.\n",
    "\n",
    "So uh, one more important thing that snowball has done.\n",
    "\n",
    "See over here, I still have capital letters, right?\n",
    "\n",
    "Like there may be some of the sentences which may be in small letter it also.\n",
    "\n",
    "So that becomes a repeated word.\n",
    "\n",
    "But since this is a capital letter, it will be considered as a separate word right for the model to\n",
    "\n",
    "understand.\n",
    "\n",
    "Right?\n",
    "\n",
    "So what it does is that snowball.\n",
    "\n",
    "One more advantage is that it is making sure that all the letter is becoming small.\n",
    "\n",
    "Right.\n",
    "\n",
    "So all the letter is becoming small.\n",
    "\n",
    "And for some of the words it is not even giving a good result like poverty has become poverty.\n",
    "\n",
    "But if you try to do this with the help of Lemmatization, you can also get a good word.\n",
    "\n",
    "Now let's try it with the help of Lemmatization.\n",
    "\n",
    "So I'm just going to, uh, do the same thing.\n",
    "\n",
    "Okay?\n",
    "\n",
    "I hope everybody is understood with respect to snowball stemmer.\n",
    "\n",
    "Now, what I'm going to do is that again, going to go back to my Lemmatization code.\n",
    "\n",
    "So I'm just going to import this NLTK dot stem.\n",
    "\n",
    "And it is very simple guys.\n",
    "\n",
    "I think we are just repeating things so that you also practice in a better way okay.\n",
    "\n",
    "so here I've got the word net lemmatizer I'm going to initialize it.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "This is done.\n",
    "\n",
    "Now I'm going to go to go ahead and copy the same code right.\n",
    "\n",
    "And I will just write it over here.\n",
    "\n",
    "And instead of writing snowball I'm just going to copy this I'm going to paste it over here.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "So I've done it.\n",
    "\n",
    "But let me just go ahead and execute the sentence part again because I need to get the updated sentence.\n",
    "\n",
    "So I think it is somewhere here.\n",
    "\n",
    "Paragraph.\n",
    "\n",
    "Okay.\n",
    "\n",
    "And uh, here is the sentence.\n",
    "\n",
    "Okay.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "Now let me just go ahead and execute the same thing.\n",
    "\n",
    "And now if you okay I'm getting an A has no Stem okay.\n",
    "\n",
    "Sorry.\n",
    "\n",
    "It should be lemmatize.\n",
    "\n",
    "Lemmatize.\n",
    "\n",
    "Okay.\n",
    "\n",
    "So Lemmatize or Lemmatize.\n",
    "\n",
    "Now, as you see, some time it took.\n",
    "\n",
    "Right?\n",
    "\n",
    "Because it is basically checking from the entire corpus.\n",
    "\n",
    "Now if I probably go and see the sentences now, you have all amazing things with respect to words that\n",
    "\n",
    "are coming up correctly and all the things are here, right.\n",
    "\n",
    "So with respect to this, you are able to get some good thing.\n",
    "\n",
    "Now one more thing you can do is that after this word you can also put the post tag.\n",
    "\n",
    "Now if you put the post tag to V right now, you see what will be the output.\n",
    "\n",
    "You'll get a better output I guess because most of the words it will be basically considering as, um,\n",
    "\n",
    "you know, as an adverb or sorry as a verb.\n",
    "\n",
    "So but anyhow, we will try to understand about post tag again.\n",
    "\n",
    "More more things.\n",
    "\n",
    "Right.\n",
    "\n",
    "So I three visions India in 3000 years history people come would world come invade us capture land.\n",
    "\n",
    "So all the stop words has got deleted.\n",
    "\n",
    "Now we are getting a very good one.\n",
    "\n",
    "You know, uh, at least better than stemming.\n",
    "\n",
    "Okay.\n",
    "\n",
    "And the other one that is snowball stemming.\n",
    "\n",
    "Right.\n",
    "\n",
    "So this was the entire process with respect to text pre-processing.\n",
    "\n",
    "And here we have discussed with stop words and how you should also go ahead and do the text pre-processing.\n",
    "\n",
    "I hope everybody got that idea.\n",
    "\n",
    "Now in Lemmatization also you can see that it is not lowering it.\n",
    "\n",
    "So what you can actually do is that you can basically lower all the sentences.\n",
    "\n",
    "right.\n",
    "\n",
    "So let's say if you write sentences of I is equal to sentences dot of I dot two lower right.\n",
    "\n",
    "So you can basically give two lower.\n",
    "\n",
    "Let's see whether it will work or not.\n",
    "\n",
    "Uh, and uh let's see whether it will completely work or not.\n",
    "\n",
    "I'm not sure whether dot two lower will work with respect to list, but I think it should work.\n",
    "\n",
    "I'm just going to execute this again.\n",
    "\n",
    "Go down okay and apply this Lemmatizer.\n",
    "\n",
    "Okay.\n",
    "\n",
    "Uh str object has no attribute to lower okay.\n",
    "\n",
    "So it's okay.\n",
    "\n",
    "Not a problem.\n",
    "\n",
    "Not a problem.\n",
    "\n",
    "What I'm actually going to do I'm just going to comment this.\n",
    "\n",
    "And before writing here I'll just say word to lower okay.\n",
    "\n",
    "You have to definitely try different different things okay.\n",
    "\n",
    "And it's all about Google.\n",
    "\n",
    "You know, just Google it.\n",
    "\n",
    "You'll be able to get it.\n",
    "\n",
    "So again I'm going to execute this.\n",
    "\n",
    "And now I think it will execute I know it is.\n",
    "\n",
    "I'm doing a lot of up and downs.\n",
    "\n",
    "But just try to follow the lecture.\n",
    "\n",
    "Uh string object has no attribute to lower y to underscore lower is there.\n",
    "\n",
    "To lower.\n",
    "\n",
    "Um, okay.\n",
    "\n",
    "Let me just see.\n",
    "\n",
    "Uh, str two lower case.\n",
    "\n",
    "Right.\n",
    "\n",
    "Python.\n",
    "\n",
    "Let me just see this.\n",
    "\n",
    "It's okay if I don't have any other way to see it, but I think dot lower will definitely work.\n",
    "\n",
    "Let's see.\n",
    "\n",
    "Dot lower.\n",
    "\n",
    "Okay.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "It has worked.\n",
    "\n",
    "Now, now if I go and see the sentences, it has done okay.\n",
    "\n",
    "So I don't have any any regrets to search in the Google.\n",
    "\n",
    "You should also do the search in the Google.\n",
    "\n",
    "So now here you can see all the small letters are there along with the lemmatization.\n",
    "\n",
    "So this is the entire text pre-processing.\n",
    "\n",
    "We can also apply some regular expression before this so that we can do the cleaning of the sentence.\n",
    "\n",
    "So I'll remove this word.\n",
    "\n",
    "And I think uh, this will also work if I probably just comment this out with to lower or just lower.\n",
    "\n",
    "Okay.\n",
    "\n",
    "Just check it out.\n",
    "\n",
    "It is up to you.\n",
    "\n",
    "So I'll just comment this out so that you can try it out.\n",
    "\n",
    "Okay.\n",
    "\n",
    "But in short, uh, we have understood what Stopwords can actually do and how we can basically apply\n",
    "\n",
    "things.\n",
    "\n",
    "Okay, so yes, uh, this was it from my side.\n",
    "\n",
    "I think you are liking this entire series.\n",
    "\n",
    "Uh, we will be learning more things as we go ahead.\n",
    "\n",
    "Um, uh, we have post tags and all.\n",
    "\n",
    "We have entity name recognitions.\n",
    "\n",
    "Also, many things are there which is going to come.\n",
    "\n",
    "So yes, uh, keep on learning, keep on practicing.\n",
    "\n",
    "Uh, I will see you all in the next video.\n",
    "\n",
    "Thank you.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbea1b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1539c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\susha/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\susha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a60c0f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "50812be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nHello guys.', \"So we'll be continuing the discussion.\", 'With respect to natural language processing.', 'We are still in text pre-processing techniques.', 'We have seen tokenization.', 'We have seen stemming.', 'We have also seen its different types.', 'Along with that we have seen Lemmatization.', 'Now we are going to consider a topic which is called as Stopwords.', \"So in this video I'm going to discuss about Stopwords the importance of Stopwords.\", \"And again I'll show you with the help of NLTK.\", 'Now, text processing is a very important step in natural language processing because you really need\\n\\nto clean the data.', 'You need to make the data in the right format.', \"Later on, we'll try to convert all this text data into vectors, and then only we'll be able to train\\n\\nthe model.\", 'Because model you know, whenever we say any machine learning model internally we really need to train\\n\\nwith some mathematical equations.', 'So whenever we train something with mathematical equations there, we really need to give the input\\n\\ndata in the form of numerical or floating values.', \"So let us go ahead and let's us understand what exactly Stopwords is.\", 'So I have opened a new notebook file over here.', 'So here I have one amazing speech from doctor APJ Abdul Kalam.', 'He was the former President of India and it was an amazing speech.', 'You can probably read out completely over here and obviously it is given in the materials.', \"Now, what I'm actually going to do is that I'm going to probably talk about Stopwords and why it is\\n\\nimportant that we should try to remove the stop words.\", 'Okay.', 'And, uh, just for a definition, what exactly stop words.', 'Now, here in this particular speech, you can see that, uh, there are a lot of sentences like, I\\n\\nhave three visions for India in 3000 years of our history, people from all over the world have come\\n\\nand invaded us.', 'So this is the entire speech.', 'It is an amazing speech.', 'If you are probably learning it, I would like to just, uh, tell you that.', 'Please read this.', \"You'll be getting a lot of information out of it.\", 'Very motivational speech altogether.', 'Now, from this particular speech, you can see that.', \"And I can definitely say this as paragraph or corpus right now here there are some words like I the\\n\\nhave and, you know, uh, let's say off uh, the you know, two there y right.\", 'All this kind of words, right?', 'It will not play a very big role when we are doing a task like spam classification.', \"Or let's say if you are trying to do some kind of task with respect to, uh, you know, uh, like spam\\n\\nor ham classification, I have already told about that.\", 'And uh, along with that, to just see that whether this is a positive review or negative review, but\\n\\nsome of the words like not can actually play a very important role.', 'Not and all.', 'So what we do is that with the help of stop words, you know, we try to remove this particular words\\n\\nbecause, uh, with this kind of use cases where you are specifically focusing on some of the important\\n\\nwords to determine the output, this is all words like I the he she off there is not at all required.', 'So what we can do is that we can basically pass this entire paragraph to that particular stop words\\n\\nand see that what all words can be basically removed, okay.', 'And that is the importance of stopwords in short.', 'So let us go ahead right now.', \"I'll just go ahead and execute it.\", 'Let me make some cells so that it will be very much easy for you all to understand and how we can apply\\n\\nStopwords.', 'Along with Stopwords, you can also apply stemming.', \"So I'll show you both the combination, uh, which will be super important for everyone.\", 'Okay.', \"So let's go ahead and let's uh, try to do that okay.\", 'Now first of all, I really need to import, uh, for stemming.', 'You obviously know what we need to import.', \"So from for stemming I'll write for NLTK dot stem import porter stemmer.\", \"So I can basically write Porter stemmer over here and I'll execute it along with this.\", \"Uh, I obviously need to also import Stopwords because stopwords for English, it will be different\\n\\nbecause you'll be having that entire list of words like the he, she and.\", 'All right.', \"so what I'm going to do is that I'm going to say that from an NLP k dot corpus import stopwords.\", 'So from this I will be able to use the stopwords itself.', 'So now I have imported uh from an antique corpus import Stopwords.', 'Now this Stopwords, you know, I have to also download it.', 'So for that, uh, let me do one thing.', \"I'll also import a NLTK and I will execute it.\", \"And along with that, I'll write an LCC dot download.\", 'And here in the parameter I am going to give about the stopwords.', 'And there are different different language stopwords also.', \"And we'll also try to see that.\", \"So if I probably write this here, you'll be able to see that downloading package Stopwords to this\\n\\nparticular location.\", \"So the package Stopwords is already up to date and I'm getting true.\", \"So in short I've downloaded all the different different languages Stopwords which is already present\\n\\nin the NLTK library.\", 'Perfect.', 'Now we have done that.', \"Now let's see that what are the Stopwords that are available in English?\", 'So in order to do that I am.', 'I have already imported from NLTK corpus import stopwords.', \"I'll take the Stopwords.\", \"I'll copy and paste it over here and I will say dot download okay or instead of download I will just\\n\\nwrite dot words.\", 'And here I just need to give my language.', 'Like what language?', 'I really want to, uh, give it for like English or something else, like German and all.', \"So I'm just going to write this.\", 'Let me just write English.', 'And if I execute this here, now you can see the list of all the stop words that you obviously have,\\n\\nand all the stop words can actually be removed.', 'Right now.', 'You may be thinking, Krish, this may depend on data to data.', 'Right now here you can see that guys, this is a list.', \"You can also create your own stopwords in English like let's say over here.\", \"Some of the important words are like are and couldn't.\", 'Right.', 'These are words can actually play a very important role.', 'Uh, to find out whether a statement is positive or negative, like not is also there.', 'If you probably search for it not, you will also be able to find it not.', 'Okay.', 'So it is always a good way that you create your own stopwords and try to remove all those kind of words\\n\\nfrom the paragraph.', 'So I hope everybody is able to understand now with respect to English, you have this.', \"Now let's see whether we have with respect to different different language.\", 'And obviously you can go ahead and check the documentation, but I will just try to show you with respect\\n\\nto German.', 'So in German also you have this specific stop words.', 'Along with this you can also use French.', 'You have this particular stop words.', 'So with respect to different different texts or different different language of text, you can definitely\\n\\napply different different stopwords with respect to that.', 'Now you may be thinking, is there Hindi or Arabic or some other?', 'I think for Arabic also, I think it is there.', \"Let's see whether it is there or not.\", 'Yes, for Arabic also it is there, but I do not find it for Hindi I guess.', 'So again from the documentation you can check it out.', 'But till Arabic I was able to see it again.', 'All the information will be given in the documentation.', \"Now what I'm actually going to do is that my sentence is already English.\", \"Right now I'm going to perform two important tasks.\", 'One is I will apply stemming.', \"And before applying stemming, you know what I'm actually going to do wherever I find out the stop words,\\n\\nI'm just going to remove the stop words from this particular paragraph so that this entire paragraph\\n\\nwill be shortened up.\", 'Right.', \"So for that, what I'm actually going to do.\", \"Now, see, whatever things you have learned from starting everything, I'm actually going to cover\\n\\nup.\", 'Okay.', \"So first thing first I'm just going to say from NLTK dot stem I'm going to import porter stemmer.\", 'Porter stemmer.', \"And I'll go to just execute I'm just going to execute this okay.\", \"And then what I'm actually going to do is that I'm just going to write Stemmer is equal to Porter stemmer\\n\\nthis.\", 'We really need to initialize it.', \"Now when we do this task right now, the next step, what I'm actually going to do is that I'm going\\n\\nto perform the tokenization on the entire paragraph.\", 'So for that I can use NLTK, dot, send, tokenize.', \"And here I'm just going to give my paragraph.\", \"Now see this guys here I'm going to get my entire paragraph, entire sentences like see I have three\\n\\nvisions for India.\", 'Then in 3000 years this all things I am able to get.', 'And this is my second sentence.', 'Third sentence.', 'Fourth sentence.', 'Like this.', \"All the sentences in the form of list I'm able to get just by using cent underscore tokenize.\", 'Right.', 'This is a tokenization process wherein we take a paragraph, divide that into sentences.', \"Okay, now let me do one thing, is that I'm just going to save this in a variable which is called as\\n\\nsentences, which will let later become a list.\", 'Right.', 'So this is my sentences.', \"And if you probably see the type of sentences I'm just going to basically see this.\", 'It is a list now.', 'Perfect till here.', 'We have done it amazingly well right.', 'We have done Porter Stemmer on that.', 'Sorry.', 'We have initialized stemmer over here and we have tokenized it.', \"Now understand, what we are going to do is that I'm going to traverse through all the sentences.\", 'First of all, apply a stopwords which all words are not present in the stopwords we are only going\\n\\nto take that and apply stemming.', 'This is what we really want to do.', \"So here I'm saying that first of all apply stopwords and filter and then apply tokenization.\", 'Right?', 'Sorry.', 'Then apply stemming.', \"So this is the step that I'm actually going to do.\", 'Now see this very simple very important.', \"So I'll write a for loop saying that for I in range for I in range.\", \"And here I'm going to basically give the length of the sentences.\", 'I can also go with respect to sentences.', \"But there I'll not be getting the indexes here.\", \"I'll be getting the indices.\", \"Okay, so range basically says that whatever length I'm actually giving that becomes an index, right?\", 'Zero to that specific length.', \"Now what I'm actually going to take, I'm going to take this specific n um, I and I'm going to write\\n\\nn nltk dot word tokenize because I'm getting in the form of sentences, I need to get each and every\\n\\nword right.\", \"So I'm getting the word over here and inside word underscore tokenize I'll give I sorry sentence of\\n\\nI because this will be an index sentences of I.\", 'So this will be an index.', \"And here I'll be able to get the word.\", \"So here what I'll do I'll make a list of words.\", \"So in short I'll be getting the list of words inside the sentences.\", 'Perfect.', 'Now till here we have done it.', 'Now after this we are going to apply one very important thing that is.', 'First of all, I need to apply stop words for each and every word and see whether it falls in the stop\\n\\nword or not.', 'If it does not fall in the stop word, then only I have to do the stemming.', 'So understand the task step by step.', \"This is super important with respect to all the steps that I'm actually taking up.\", 'Okay, so here I will write a list comprehension.', 'I will say stemmer dot stem okay.', \"And here I'm going to write dot word okay of the word because uh from this particular words, this word\\n\\nis a list of words.\", 'And I have to take each and every word.', 'So here I will write a for loop okay.', 'And this is called as list comprehension.', \"So I'll write for word in words if word not in see if the word is not present in the stop words then\\n\\nonly you apply stemming.\", \"That is what I'm actually trying to do.\", 'Okay, so here you can basically see if the word is not in.', \"I'll use a set.\", 'Along with that I will download all the all the stop words with respect to English.', 'Right.', \"So why I'm using step set because some of the words may get repeated.\", \"So I don't want that.\", \"So I'm going to basically write it over here right now through this.\", \"What I'm actually going to do I'll get that specific word that is not present in the stop words.\", 'And only stemming will be getting applied to that specific word.', 'Perfect.', \"Now here, what I'm actually going to do is that I'm going to save it in a variable called as words\\n\\nperfect.\", 'I hope it is very much clear.', \"I'm getting back everything after doing the stemming back in the words itself.\", \"And then finally, what I'm actually going to do is that I'm going to take this sentences, and I'm\\n\\ngoing to replace it on the same index with respect to this words.\", 'But once we get this words right, I need to join all these words together.', 'So how do I join?', 'There will obviously be a space dot.', \"I'll just use dot join so that it will join together and it will convert that into a sentences.\", 'So this exactly is converting all the words into sentences, right.', 'This is very much simple.', 'And we have actually done this.', 'Perfect.', \"So here what all things we have done again let me repeat I'm I'm iterating through each and every sentence.\", \"And then I'm doing a word tokenize that basically means for every sentences I'm getting the list of\\n\\nwords.\", \"And from that list of words I'm iterating, I'm seeing that whether it is present in the stop words,\\n\\nif it is not present, I'm doing the stemming.\", \"After stemming, I'm again storing back in that same list, and then I'm converting all these words\\n\\ninto sentences I can say, converting all the list of words into sentences.\", 'Perfect.', 'Now, once I execute it.', \"And now if I go and see my sentences here, you'll be able to see now I three vision India right in\\n\\n3000 year history.\", 'Right.', 'So here I h I s t o r y became RI okay people, people it became people.', 'World came, invaded us, invade it, became captured.', 'Land conquer mined from.', 'You can see all the special words like like I, I have.', 'Everything is gone.', 'See, see this I is there have is gone.', 'Right.', 'Though you will not be able to find out though anyway, right?', 'So whatever.', 'Stop.', 'Words were present over here that all got removed.', 'And then only we performed the stemming.', 'Right now you may be saying crush.', 'Uh, the stemming does not look very good, right?', \"So for that, what you need to do, I've already taught you with respect to snowball stemmer, so I\\n\\nwill just import this.\", 'Okay.', 'And it is very simple.', 'Simple.', 'I think you can do the same task again.', 'So snowball stemmer and then I will try to import this with respect to English.', \"And obviously after this you'll be able to get good sentence.\", 'Right.', 'So let me just remove this one.', \"So snowball stemmer I've already done it and I'm going to copy the same thing.\", 'Okay.', \"And here I'm just going to say apply snowball stemmer stemming.\", 'Right.', 'And then instead of stemmer I will just write this word that is snowball stemmer.', \"That's it.\", 'Yeah.', 'And now once I execute it, uh, let me go back again, back to the sentences, because that sentences\\n\\nhave got changed now.', 'So where is the sentences?', \"Let's see.\", 'Okay.', \"Now this is the sentences I've got executed now.\", \"Now I'm just going to execute this.\", 'Now if I probably go and see my sentences here, you can see that now it is good right now.', 'So uh, one more important thing that snowball has done.', 'See over here, I still have capital letters, right?', 'Like there may be some of the sentences which may be in small letter it also.', 'So that becomes a repeated word.', 'But since this is a capital letter, it will be considered as a separate word right for the model to\\n\\nunderstand.', 'Right?', 'So what it does is that snowball.', 'One more advantage is that it is making sure that all the letter is becoming small.', 'Right.', 'So all the letter is becoming small.', 'And for some of the words it is not even giving a good result like poverty has become poverty.', 'But if you try to do this with the help of Lemmatization, you can also get a good word.', \"Now let's try it with the help of Lemmatization.\", \"So I'm just going to, uh, do the same thing.\", 'Okay?', 'I hope everybody is understood with respect to snowball stemmer.', \"Now, what I'm going to do is that again, going to go back to my Lemmatization code.\", \"So I'm just going to import this NLTK dot stem.\", 'And it is very simple guys.', 'I think we are just repeating things so that you also practice in a better way okay.', \"so here I've got the word net lemmatizer I'm going to initialize it.\", 'Perfect.', 'This is done.', \"Now I'm going to go to go ahead and copy the same code right.\", 'And I will just write it over here.', \"And instead of writing snowball I'm just going to copy this I'm going to paste it over here.\", 'Perfect.', \"So I've done it.\", 'But let me just go ahead and execute the sentence part again because I need to get the updated sentence.', 'So I think it is somewhere here.', 'Paragraph.', 'Okay.', 'And uh, here is the sentence.', 'Okay.', 'Perfect.', 'Now let me just go ahead and execute the same thing.', \"And now if you okay I'm getting an A has no Stem okay.\", 'Sorry.', 'It should be lemmatize.', 'Lemmatize.', 'Okay.', 'So Lemmatize or Lemmatize.', 'Now, as you see, some time it took.', 'Right?', 'Because it is basically checking from the entire corpus.', 'Now if I probably go and see the sentences now, you have all amazing things with respect to words that\\n\\nare coming up correctly and all the things are here, right.', 'So with respect to this, you are able to get some good thing.', 'Now one more thing you can do is that after this word you can also put the post tag.', 'Now if you put the post tag to V right now, you see what will be the output.', \"You'll get a better output I guess because most of the words it will be basically considering as, um,\\n\\nyou know, as an adverb or sorry as a verb.\", 'So but anyhow, we will try to understand about post tag again.', 'More more things.', 'Right.', 'So I three visions India in 3000 years history people come would world come invade us capture land.', 'So all the stop words has got deleted.', 'Now we are getting a very good one.', 'You know, uh, at least better than stemming.', 'Okay.', 'And the other one that is snowball stemming.', 'Right.', 'So this was the entire process with respect to text pre-processing.', 'And here we have discussed with stop words and how you should also go ahead and do the text pre-processing.', 'I hope everybody got that idea.', 'Now in Lemmatization also you can see that it is not lowering it.', 'So what you can actually do is that you can basically lower all the sentences.', 'right.', \"So let's say if you write sentences of I is equal to sentences dot of I dot two lower right.\", 'So you can basically give two lower.', \"Let's see whether it will work or not.\", \"Uh, and uh let's see whether it will completely work or not.\", \"I'm not sure whether dot two lower will work with respect to list, but I think it should work.\", \"I'm just going to execute this again.\", 'Go down okay and apply this Lemmatizer.', 'Okay.', 'Uh str object has no attribute to lower okay.', \"So it's okay.\", 'Not a problem.', 'Not a problem.', \"What I'm actually going to do I'm just going to comment this.\", \"And before writing here I'll just say word to lower okay.\", 'You have to definitely try different different things okay.', \"And it's all about Google.\", 'You know, just Google it.', \"You'll be able to get it.\", \"So again I'm going to execute this.\", 'And now I think it will execute I know it is.', \"I'm doing a lot of up and downs.\", 'But just try to follow the lecture.', 'Uh string object has no attribute to lower y to underscore lower is there.', 'To lower.', 'Um, okay.', 'Let me just see.', 'Uh, str two lower case.', 'Right.', 'Python.', 'Let me just see this.', \"It's okay if I don't have any other way to see it, but I think dot lower will definitely work.\", \"Let's see.\", 'Dot lower.', 'Okay.', 'Perfect.', 'It has worked.', 'Now, now if I go and see the sentences, it has done okay.', \"So I don't have any any regrets to search in the Google.\", 'You should also do the search in the Google.', 'So now here you can see all the small letters are there along with the lemmatization.', 'So this is the entire text pre-processing.', 'We can also apply some regular expression before this so that we can do the cleaning of the sentence.', \"So I'll remove this word.\", 'And I think uh, this will also work if I probably just comment this out with to lower or just lower.', 'Okay.', 'Just check it out.', 'It is up to you.', \"So I'll just comment this out so that you can try it out.\", 'Okay.', 'But in short, uh, we have understood what Stopwords can actually do and how we can basically apply\\n\\nthings.', 'Okay, so yes, uh, this was it from my side.', 'I think you are liking this entire series.', 'Uh, we will be learning more things as we go ahead.', 'Um, uh, we have post tags and all.', 'We have entity name recognitions.', 'Also, many things are there which is going to come.', 'So yes, uh, keep on learning, keep on practicing.', 'Uh, I will see you all in the next video.', 'Thank you.', '']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "sentences = re.split(r'(?<=[.!?])\\s+', transcript)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d41ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fec6c0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Sentences: ['hello guy', 'continu discuss', 'respect natur languag process', 'still text pre process techniqu', 'seen token', 'seen stem', 'also seen differ type', 'along seen lemmat', 'go consid topic call stopword', 'video go discuss stopword import stopword', 'show help nltk', 'text process import step natur languag process realli need clean data', 'need make data right format', 'later tri convert text data vector abl train model', 'model know whenev say machin learn model intern realli need train mathemat equat', 'whenev train someth mathemat equat realli need give input data form numer float valu', \"let us go ahead let' us understand exactli stopword\", 'open new notebook file', 'one amaz speech doctor apj abdul kalam', 'former presid india amaz speech', 'probabl read complet obvious given materi', 'actual go go probabl talk stopword import tri remov stop word', 'okay', 'uh definit exactli stop word', 'particular speech see uh lot sentenc like three vision india 3000 year histori peopl world come invad us', 'entir speech', 'amaz speech', 'probabl learn would like uh tell', 'pleas read', 'get lot inform', 'motiv speech altogeth', 'particular speech see', \"definit say paragraph corpu right word like know uh let' say uh know two right\", 'kind word right', 'play big role task like spam classif', \"let' say tri kind task respect uh know uh like spam ham classif alreadi told\", 'uh along see whether posit review neg review word like actual play import role', '', 'help stop word know tri remov particular word uh kind use case specif focus import word determin output word like requir', 'basic pass entir paragraph particular stop word see word basic remov okay', 'import stopword short', 'let us go ahead right', 'go ahead execut', 'let make cell much easi understand appli stopword', 'along stopword also appli stem', 'show combin uh super import everyon', 'okay', \"let' go ahead let' uh tri okay\", 'first realli need import uh stem', 'obvious know need import', 'stem write nltk dot stem import porter stemmer', 'basic write porter stemmer execut along', 'uh obvious need also import stopword stopword english differ entir list word like', 'right', 'go go say nlp k dot corpu import stopword', 'abl use stopword', 'import uh antiqu corpu import stopword', 'stopword know also download', 'uh let one thing', 'also import nltk execut', 'along write lcc dot download', 'paramet go give stopword', 'differ differ languag stopword also', 'also tri see', 'probabl write abl see download packag stopword particular locat', 'packag stopword alreadi date get true', 'short download differ differ languag stopword alreadi present nltk librari', 'perfect', 'done', \"let' see stopword avail english\", 'order', 'alreadi import nltk corpu import stopword', 'take stopword', 'copi past say dot download okay instead download write dot word', 'need give languag', 'like languag', 'realli want uh give like english someth els like german', 'go write', 'let write english', 'execut see list stop word obvious stop word actual remov', 'right', 'may think krish may depend data data', 'right see guy list', \"also creat stopword english like let' say\", 'import word like', 'right', 'word actual play import role', 'uh find whether statement posit neg like also', 'probabl search also abl find', 'okay', 'alway good way creat stopword tri remov kind word paragraph', 'hope everybodi abl understand respect english', \"let' see whether respect differ differ languag\", 'obvious go ahead check document tri show respect german', 'german also specif stop word', 'along also use french', 'particular stop word', 'respect differ differ text differ differ languag text definit appli differ differ stopword respect', 'may think hindi arab', 'think arab also think', \"let' see whether\", 'ye arab also find hindi guess', 'document check', 'till arab abl see', 'inform given document', 'actual go sentenc alreadi english', 'right go perform two import task', 'one appli stem', 'appli stem know actual go wherev find stop word go remov stop word particular paragraph entir paragraph shorten', 'right', 'actual go', 'see whatev thing learn start everyth actual go cover', 'okay', 'first thing first go say nltk dot stem go import porter stemmer', 'porter stemmer', 'go execut go execut okay', 'actual go go write stemmer equal porter stemmer', 'realli need initi', 'task right next step actual go go perform token entir paragraph', 'use nltk dot send token', 'go give paragraph', 'see guy go get entir paragraph entir sentenc like see three vision india', '3000 year thing abl get', 'second sentenc', 'third sentenc', 'fourth sentenc', 'like', 'sentenc form list abl get use cent underscor token', 'right', 'token process wherein take paragraph divid sentenc', 'okay let one thing go save variabl call sentenc let later becom list', 'right', 'sentenc', 'probabl see type sentenc go basic see', 'list', 'perfect till', 'done amazingli well right', 'done porter stemmer', 'sorri', 'initi stemmer token', 'understand go go travers sentenc', 'first appli stopword word present stopword go take appli stem', 'realli want', 'say first appli stopword filter appli token', 'right', 'sorri', 'appli stem', 'step actual go', 'see simpl import', 'write loop say rang rang', 'go basic give length sentenc', 'also go respect sentenc', 'get index', 'get indic', 'okay rang basic say whatev length actual give becom index right', 'zero specif length', 'actual go take go take specif n um go write n nltk dot word token get form sentenc need get everi word right', 'get word insid word underscor token give sorri sentenc index sentenc', 'index', 'abl get word', 'make list word', 'short get list word insid sentenc', 'perfect', 'till done', 'go appli one import thing', 'first need appli stop word everi word see whether fall stop word', 'fall stop word stem', 'understand task step step', 'super import respect step actual take', 'okay write list comprehens', 'say stemmer dot stem okay', 'go write dot word okay word uh particular word word list word', 'take everi word', 'write loop okay', 'call list comprehens', 'write word word word see word present stop word appli stem', 'actual tri', 'okay basic see word', 'use set', 'along download stop word respect english', 'right', 'use step set word may get repeat', 'want', 'go basic write right', 'actual go get specif word present stop word', 'stem get appli specif word', 'perfect', 'actual go go save variabl call word perfect', 'hope much clear', 'get back everyth stem back word', 'final actual go go take sentenc go replac index respect word', 'get word right need join word togeth', 'join', 'obvious space dot', 'use dot join join togeth convert sentenc', 'exactli convert word sentenc right', 'much simpl', 'actual done', 'perfect', 'thing done let repeat iter everi sentenc', 'word token basic mean everi sentenc get list word', 'list word iter see whether present stop word present stem', 'stem store back list convert word sentenc say convert list word sentenc', 'perfect', 'execut', 'go see sentenc abl see three vision india right 3000 year histori', 'right', 'h r becam ri okay peopl peopl becam peopl', 'world came invad us invad becam captur', 'land conquer mine', 'see special word like like', 'everyth gone', 'see see gone', 'right', 'though abl find though anyway right', 'whatev', 'stop', 'word present got remov', 'perform stem', 'right may say crush', 'uh stem look good right', 'need alreadi taught respect snowbal stemmer import', 'okay', 'simpl', 'simpl', 'think task', 'snowbal stemmer tri import respect english', 'obvious abl get good sentenc', 'right', 'let remov one', 'snowbal stemmer alreadi done go copi thing', 'okay', 'go say appli snowbal stemmer stem', 'right', 'instead stemmer write word snowbal stemmer', \"that'\", 'yeah', 'execut uh let go back back sentenc sentenc got chang', 'sentenc', \"let' see\", 'okay', 'sentenc got execut', 'go execut', 'probabl go see sentenc see good right', 'uh one import thing snowbal done', 'see still capit letter right', 'like may sentenc may small letter also', 'becom repeat word', 'sinc capit letter consid separ word right model understand', 'right', 'snowbal', 'one advantag make sure letter becom small', 'right', 'letter becom small', 'word even give good result like poverti becom poverti', 'tri help lemmat also get good word', \"let' tri help lemmat\", 'go uh thing', 'okay', 'hope everybodi understood respect snowbal stemmer', 'go go go back lemmat code', 'go import nltk dot stem', 'simpl guy', 'think repeat thing also practic better way okay', 'got word net lemmat go initi', 'perfect', 'done', 'go go go ahead copi code right', 'write', 'instead write snowbal go copi go past', 'perfect', 'done', 'let go ahead execut sentenc part need get updat sentenc', 'think somewher', 'paragraph', 'okay', 'uh sentenc', 'okay', 'perfect', 'let go ahead execut thing', 'okay get stem okay', 'sorri', 'lemmat', 'lemmat', 'okay', 'lemmat lemmat', 'see time took', 'right', 'basic check entir corpu', 'probabl go see sentenc amaz thing respect word come correctli thing right', 'respect abl get good thing', 'one thing word also put post tag', 'put post tag v right see output', 'get better output guess word basic consid um know adverb sorri verb', 'anyhow tri understand post tag', 'thing', 'right', 'three vision india 3000 year histori peopl come would world come invad us captur land', 'stop word got delet', 'get good one', 'know uh least better stem', 'okay', 'one snowbal stem', 'right', 'entir process respect text pre process', 'discuss stop word also go ahead text pre process', 'hope everybodi got idea', 'lemmat also see lower', 'actual basic lower sentenc', 'right', \"let' say write sentenc equal sentenc dot dot two lower right\", 'basic give two lower', \"let' see whether work\", \"uh uh let' see whether complet work\", 'sure whether dot two lower work respect list think work', 'go execut', 'go okay appli lemmat', 'okay', 'uh str object attribut lower okay', 'okay', 'problem', 'problem', 'actual go go comment', 'write say word lower okay', 'definit tri differ differ thing okay', 'googl', 'know googl', 'abl get', 'go execut', 'think execut know', 'lot down', 'tri follow lectur', 'uh string object attribut lower underscor lower', 'lower', 'um okay', 'let see', 'uh str two lower case', 'right', 'python', 'let see', 'okay way see think dot lower definit work', \"let' see\", 'dot lower', 'okay', 'perfect', 'work', 'go see sentenc done okay', 'regret search googl', 'also search googl', 'see small letter along lemmat', 'entir text pre process', 'also appli regular express clean sentenc', 'remov word', 'think uh also work probabl comment lower lower', 'okay', 'check', '', 'comment tri', 'okay', 'short uh understood stopword actual basic appli thing', 'okay ye uh side', 'think like entir seri', 'uh learn thing go ahead', 'um uh post tag', 'entiti name recognit', 'also mani thing go come', 'ye uh keep learn keep practic', 'uh see next video', 'thank', '']\n",
      "Stemmed Words: ['hello', 'guy', 'continu', 'discuss', 'respect', 'natur', 'languag', 'process', 'still', 'text', 'pre', 'process', 'techniqu', 'seen', 'token', 'seen', 'stem', 'also', 'seen', 'differ', 'type', 'along', 'seen', 'lemmat', 'go', 'consid', 'topic', 'call', 'stopword', 'video', 'go', 'discuss', 'stopword', 'import', 'stopword', 'show', 'help', 'nltk', 'text', 'process', 'import', 'step', 'natur', 'languag', 'process', 'realli', 'need', 'clean', 'data', 'need', 'make', 'data', 'right', 'format', 'later', 'tri', 'convert', 'text', 'data', 'vector', 'abl', 'train', 'model', 'model', 'know', 'whenev', 'say', 'machin', 'learn', 'model', 'intern', 'realli', 'need', 'train', 'mathemat', 'equat', 'whenev', 'train', 'someth', 'mathemat', 'equat', 'realli', 'need', 'give', 'input', 'data', 'form', 'numer', 'float', 'valu', 'let', 'us', 'go', 'ahead', \"let'\", 'us', 'understand', 'exactli', 'stopword', 'open', 'new', 'notebook', 'file', 'one', 'amaz', 'speech', 'doctor', 'apj', 'abdul', 'kalam', 'former', 'presid', 'india', 'amaz', 'speech', 'probabl', 'read', 'complet', 'obvious', 'given', 'materi', 'actual', 'go', 'go', 'probabl', 'talk', 'stopword', 'import', 'tri', 'remov', 'stop', 'word', 'okay', 'uh', 'definit', 'exactli', 'stop', 'word', 'particular', 'speech', 'see', 'uh', 'lot', 'sentenc', 'like', 'three', 'vision', 'india', '3000', 'year', 'histori', 'peopl', 'world', 'come', 'invad', 'us', 'entir', 'speech', 'amaz', 'speech', 'probabl', 'learn', 'would', 'like', 'uh', 'tell', 'pleas', 'read', 'get', 'lot', 'inform', 'motiv', 'speech', 'altogeth', 'particular', 'speech', 'see', 'definit', 'say', 'paragraph', 'corpu', 'right', 'word', 'like', 'know', 'uh', \"let'\", 'say', 'uh', 'know', 'two', 'right', 'kind', 'word', 'right', 'play', 'big', 'role', 'task', 'like', 'spam', 'classif', \"let'\", 'say', 'tri', 'kind', 'task', 'respect', 'uh', 'know', 'uh', 'like', 'spam', 'ham', 'classif', 'alreadi', 'told', 'uh', 'along', 'see', 'whether', 'posit', 'review', 'neg', 'review', 'word', 'like', 'actual', 'play', 'import', 'role', 'help', 'stop', 'word', 'know', 'tri', 'remov', 'particular', 'word', 'uh', 'kind', 'use', 'case', 'specif', 'focus', 'import', 'word', 'determin', 'output', 'word', 'like', 'requir', 'basic', 'pass', 'entir', 'paragraph', 'particular', 'stop', 'word', 'see', 'word', 'basic', 'remov', 'okay', 'import', 'stopword', 'short', 'let', 'us', 'go', 'ahead', 'right', 'go', 'ahead', 'execut', 'let', 'make', 'cell', 'much', 'easi', 'understand', 'appli', 'stopword', 'along', 'stopword', 'also', 'appli', 'stem', 'show', 'combin', 'uh', 'super', 'import', 'everyon', 'okay', \"let'\", 'go', 'ahead', \"let'\", 'uh', 'tri', 'okay', 'first', 'realli', 'need', 'import', 'uh', 'stem', 'obvious', 'know', 'need', 'import', 'stem', 'write', 'nltk', 'dot', 'stem', 'import', 'porter', 'stemmer', 'basic', 'write', 'porter', 'stemmer', 'execut', 'along', 'uh', 'obvious', 'need', 'also', 'import', 'stopword', 'stopword', 'english', 'differ', 'entir', 'list', 'word', 'like', 'right', 'go', 'go', 'say', 'nlp', 'k', 'dot', 'corpu', 'import', 'stopword', 'abl', 'use', 'stopword', 'import', 'uh', 'antiqu', 'corpu', 'import', 'stopword', 'stopword', 'know', 'also', 'download', 'uh', 'let', 'one', 'thing', 'also', 'import', 'nltk', 'execut', 'along', 'write', 'lcc', 'dot', 'download', 'paramet', 'go', 'give', 'stopword', 'differ', 'differ', 'languag', 'stopword', 'also', 'also', 'tri', 'see', 'probabl', 'write', 'abl', 'see', 'download', 'packag', 'stopword', 'particular', 'locat', 'packag', 'stopword', 'alreadi', 'date', 'get', 'true', 'short', 'download', 'differ', 'differ', 'languag', 'stopword', 'alreadi', 'present', 'nltk', 'librari', 'perfect', 'done', \"let'\", 'see', 'stopword', 'avail', 'english', 'order', 'alreadi', 'import', 'nltk', 'corpu', 'import', 'stopword', 'take', 'stopword', 'copi', 'past', 'say', 'dot', 'download', 'okay', 'instead', 'download', 'write', 'dot', 'word', 'need', 'give', 'languag', 'like', 'languag', 'realli', 'want', 'uh', 'give', 'like', 'english', 'someth', 'els', 'like', 'german', 'go', 'write', 'let', 'write', 'english', 'execut', 'see', 'list', 'stop', 'word', 'obvious', 'stop', 'word', 'actual', 'remov', 'right', 'may', 'think', 'krish', 'may', 'depend', 'data', 'data', 'right', 'see', 'guy', 'list', 'also', 'creat', 'stopword', 'english', 'like', \"let'\", 'say', 'import', 'word', 'like', 'right', 'word', 'actual', 'play', 'import', 'role', 'uh', 'find', 'whether', 'statement', 'posit', 'neg', 'like', 'also', 'probabl', 'search', 'also', 'abl', 'find', 'okay', 'alway', 'good', 'way', 'creat', 'stopword', 'tri', 'remov', 'kind', 'word', 'paragraph', 'hope', 'everybodi', 'abl', 'understand', 'respect', 'english', \"let'\", 'see', 'whether', 'respect', 'differ', 'differ', 'languag', 'obvious', 'go', 'ahead', 'check', 'document', 'tri', 'show', 'respect', 'german', 'german', 'also', 'specif', 'stop', 'word', 'along', 'also', 'use', 'french', 'particular', 'stop', 'word', 'respect', 'differ', 'differ', 'text', 'differ', 'differ', 'languag', 'text', 'definit', 'appli', 'differ', 'differ', 'stopword', 'respect', 'may', 'think', 'hindi', 'arab', 'think', 'arab', 'also', 'think', \"let'\", 'see', 'whether', 'ye', 'arab', 'also', 'find', 'hindi', 'guess', 'document', 'check', 'till', 'arab', 'abl', 'see', 'inform', 'given', 'document', 'actual', 'go', 'sentenc', 'alreadi', 'english', 'right', 'go', 'perform', 'two', 'import', 'task', 'one', 'appli', 'stem', 'appli', 'stem', 'know', 'actual', 'go', 'wherev', 'find', 'stop', 'word', 'go', 'remov', 'stop', 'word', 'particular', 'paragraph', 'entir', 'paragraph', 'shorten', 'right', 'actual', 'go', 'see', 'whatev', 'thing', 'learn', 'start', 'everyth', 'actual', 'go', 'cover', 'okay', 'first', 'thing', 'first', 'go', 'say', 'nltk', 'dot', 'stem', 'go', 'import', 'porter', 'stemmer', 'porter', 'stemmer', 'go', 'execut', 'go', 'execut', 'okay', 'actual', 'go', 'go', 'write', 'stemmer', 'equal', 'porter', 'stemmer', 'realli', 'need', 'initi', 'task', 'right', 'next', 'step', 'actual', 'go', 'go', 'perform', 'token', 'entir', 'paragraph', 'use', 'nltk', 'dot', 'send', 'token', 'go', 'give', 'paragraph', 'see', 'guy', 'go', 'get', 'entir', 'paragraph', 'entir', 'sentenc', 'like', 'see', 'three', 'vision', 'india', '3000', 'year', 'thing', 'abl', 'get', 'second', 'sentenc', 'third', 'sentenc', 'fourth', 'sentenc', 'like', 'sentenc', 'form', 'list', 'abl', 'get', 'use', 'cent', 'underscor', 'token', 'right', 'token', 'process', 'wherein', 'take', 'paragraph', 'divid', 'sentenc', 'okay', 'let', 'one', 'thing', 'go', 'save', 'variabl', 'call', 'sentenc', 'let', 'later', 'becom', 'list', 'right', 'sentenc', 'probabl', 'see', 'type', 'sentenc', 'go', 'basic', 'see', 'list', 'perfect', 'till', 'done', 'amazingli', 'well', 'right', 'done', 'porter', 'stemmer', 'sorri', 'initi', 'stemmer', 'token', 'understand', 'go', 'go', 'travers', 'sentenc', 'first', 'appli', 'stopword', 'word', 'present', 'stopword', 'go', 'take', 'appli', 'stem', 'realli', 'want', 'say', 'first', 'appli', 'stopword', 'filter', 'appli', 'token', 'right', 'sorri', 'appli', 'stem', 'step', 'actual', 'go', 'see', 'simpl', 'import', 'write', 'loop', 'say', 'rang', 'rang', 'go', 'basic', 'give', 'length', 'sentenc', 'also', 'go', 'respect', 'sentenc', 'get', 'index', 'get', 'indic', 'okay', 'rang', 'basic', 'say', 'whatev', 'length', 'actual', 'give', 'becom', 'index', 'right', 'zero', 'specif', 'length', 'actual', 'go', 'take', 'go', 'take', 'specif', 'n', 'um', 'go', 'write', 'n', 'nltk', 'dot', 'word', 'token', 'get', 'form', 'sentenc', 'need', 'get', 'everi', 'word', 'right', 'get', 'word', 'insid', 'word', 'underscor', 'token', 'give', 'sorri', 'sentenc', 'index', 'sentenc', 'index', 'abl', 'get', 'word', 'make', 'list', 'word', 'short', 'get', 'list', 'word', 'insid', 'sentenc', 'perfect', 'till', 'done', 'go', 'appli', 'one', 'import', 'thing', 'first', 'need', 'appli', 'stop', 'word', 'everi', 'word', 'see', 'whether', 'fall', 'stop', 'word', 'fall', 'stop', 'word', 'stem', 'understand', 'task', 'step', 'step', 'super', 'import', 'respect', 'step', 'actual', 'take', 'okay', 'write', 'list', 'comprehens', 'say', 'stemmer', 'dot', 'stem', 'okay', 'go', 'write', 'dot', 'word', 'okay', 'word', 'uh', 'particular', 'word', 'word', 'list', 'word', 'take', 'everi', 'word', 'write', 'loop', 'okay', 'call', 'list', 'comprehens', 'write', 'word', 'word', 'word', 'see', 'word', 'present', 'stop', 'word', 'appli', 'stem', 'actual', 'tri', 'okay', 'basic', 'see', 'word', 'use', 'set', 'along', 'download', 'stop', 'word', 'respect', 'english', 'right', 'use', 'step', 'set', 'word', 'may', 'get', 'repeat', 'want', 'go', 'basic', 'write', 'right', 'actual', 'go', 'get', 'specif', 'word', 'present', 'stop', 'word', 'stem', 'get', 'appli', 'specif', 'word', 'perfect', 'actual', 'go', 'go', 'save', 'variabl', 'call', 'word', 'perfect', 'hope', 'much', 'clear', 'get', 'back', 'everyth', 'stem', 'back', 'word', 'final', 'actual', 'go', 'go', 'take', 'sentenc', 'go', 'replac', 'index', 'respect', 'word', 'get', 'word', 'right', 'need', 'join', 'word', 'togeth', 'join', 'obvious', 'space', 'dot', 'use', 'dot', 'join', 'join', 'togeth', 'convert', 'sentenc', 'exactli', 'convert', 'word', 'sentenc', 'right', 'much', 'simpl', 'actual', 'done', 'perfect', 'thing', 'done', 'let', 'repeat', 'iter', 'everi', 'sentenc', 'word', 'token', 'basic', 'mean', 'everi', 'sentenc', 'get', 'list', 'word', 'list', 'word', 'iter', 'see', 'whether', 'present', 'stop', 'word', 'present', 'stem', 'stem', 'store', 'back', 'list', 'convert', 'word', 'sentenc', 'say', 'convert', 'list', 'word', 'sentenc', 'perfect', 'execut', 'go', 'see', 'sentenc', 'abl', 'see', 'three', 'vision', 'india', 'right', '3000', 'year', 'histori', 'right', 'h', 'r', 'becam', 'ri', 'okay', 'peopl', 'peopl', 'becam', 'peopl', 'world', 'came', 'invad', 'us', 'invad', 'becam', 'captur', 'land', 'conquer', 'mine', 'see', 'special', 'word', 'like', 'like', 'everyth', 'gone', 'see', 'see', 'gone', 'right', 'though', 'abl', 'find', 'though', 'anyway', 'right', 'whatev', 'stop', 'word', 'present', 'got', 'remov', 'perform', 'stem', 'right', 'may', 'say', 'crush', 'uh', 'stem', 'look', 'good', 'right', 'need', 'alreadi', 'taught', 'respect', 'snowbal', 'stemmer', 'import', 'okay', 'simpl', 'simpl', 'think', 'task', 'snowbal', 'stemmer', 'tri', 'import', 'respect', 'english', 'obvious', 'abl', 'get', 'good', 'sentenc', 'right', 'let', 'remov', 'one', 'snowbal', 'stemmer', 'alreadi', 'done', 'go', 'copi', 'thing', 'okay', 'go', 'say', 'appli', 'snowbal', 'stemmer', 'stem', 'right', 'instead', 'stemmer', 'write', 'word', 'snowbal', 'stemmer', \"that'\", 'yeah', 'execut', 'uh', 'let', 'go', 'back', 'back', 'sentenc', 'sentenc', 'got', 'chang', 'sentenc', \"let'\", 'see', 'okay', 'sentenc', 'got', 'execut', 'go', 'execut', 'probabl', 'go', 'see', 'sentenc', 'see', 'good', 'right', 'uh', 'one', 'import', 'thing', 'snowbal', 'done', 'see', 'still', 'capit', 'letter', 'right', 'like', 'may', 'sentenc', 'may', 'small', 'letter', 'also', 'becom', 'repeat', 'word', 'sinc', 'capit', 'letter', 'consid', 'separ', 'word', 'right', 'model', 'understand', 'right', 'snowbal', 'one', 'advantag', 'make', 'sure', 'letter', 'becom', 'small', 'right', 'letter', 'becom', 'small', 'word', 'even', 'give', 'good', 'result', 'like', 'poverti', 'becom', 'poverti', 'tri', 'help', 'lemmat', 'also', 'get', 'good', 'word', \"let'\", 'tri', 'help', 'lemmat', 'go', 'uh', 'thing', 'okay', 'hope', 'everybodi', 'understood', 'respect', 'snowbal', 'stemmer', 'go', 'go', 'go', 'back', 'lemmat', 'code', 'go', 'import', 'nltk', 'dot', 'stem', 'simpl', 'guy', 'think', 'repeat', 'thing', 'also', 'practic', 'better', 'way', 'okay', 'got', 'word', 'net', 'lemmat', 'go', 'initi', 'perfect', 'done', 'go', 'go', 'go', 'ahead', 'copi', 'code', 'right', 'write', 'instead', 'write', 'snowbal', 'go', 'copi', 'go', 'past', 'perfect', 'done', 'let', 'go', 'ahead', 'execut', 'sentenc', 'part', 'need', 'get', 'updat', 'sentenc', 'think', 'somewher', 'paragraph', 'okay', 'uh', 'sentenc', 'okay', 'perfect', 'let', 'go', 'ahead', 'execut', 'thing', 'okay', 'get', 'stem', 'okay', 'sorri', 'lemmat', 'lemmat', 'okay', 'lemmat', 'lemmat', 'see', 'time', 'took', 'right', 'basic', 'check', 'entir', 'corpu', 'probabl', 'go', 'see', 'sentenc', 'amaz', 'thing', 'respect', 'word', 'come', 'correctli', 'thing', 'right', 'respect', 'abl', 'get', 'good', 'thing', 'one', 'thing', 'word', 'also', 'put', 'post', 'tag', 'put', 'post', 'tag', 'v', 'right', 'see', 'output', 'get', 'better', 'output', 'guess', 'word', 'basic', 'consid', 'um', 'know', 'adverb', 'sorri', 'verb', 'anyhow', 'tri', 'understand', 'post', 'tag', 'thing', 'right', 'three', 'vision', 'india', '3000', 'year', 'histori', 'peopl', 'come', 'would', 'world', 'come', 'invad', 'us', 'captur', 'land', 'stop', 'word', 'got', 'delet', 'get', 'good', 'one', 'know', 'uh', 'least', 'better', 'stem', 'okay', 'one', 'snowbal', 'stem', 'right', 'entir', 'process', 'respect', 'text', 'pre', 'process', 'discuss', 'stop', 'word', 'also', 'go', 'ahead', 'text', 'pre', 'process', 'hope', 'everybodi', 'got', 'idea', 'lemmat', 'also', 'see', 'lower', 'actual', 'basic', 'lower', 'sentenc', 'right', \"let'\", 'say', 'write', 'sentenc', 'equal', 'sentenc', 'dot', 'dot', 'two', 'lower', 'right', 'basic', 'give', 'two', 'lower', \"let'\", 'see', 'whether', 'work', 'uh', 'uh', \"let'\", 'see', 'whether', 'complet', 'work', 'sure', 'whether', 'dot', 'two', 'lower', 'work', 'respect', 'list', 'think', 'work', 'go', 'execut', 'go', 'okay', 'appli', 'lemmat', 'okay', 'uh', 'str', 'object', 'attribut', 'lower', 'okay', 'okay', 'problem', 'problem', 'actual', 'go', 'go', 'comment', 'write', 'say', 'word', 'lower', 'okay', 'definit', 'tri', 'differ', 'differ', 'thing', 'okay', 'googl', 'know', 'googl', 'abl', 'get', 'go', 'execut', 'think', 'execut', 'know', 'lot', 'down', 'tri', 'follow', 'lectur', 'uh', 'string', 'object', 'attribut', 'lower', 'underscor', 'lower', 'lower', 'um', 'okay', 'let', 'see', 'uh', 'str', 'two', 'lower', 'case', 'right', 'python', 'let', 'see', 'okay', 'way', 'see', 'think', 'dot', 'lower', 'definit', 'work', \"let'\", 'see', 'dot', 'lower', 'okay', 'perfect', 'work', 'go', 'see', 'sentenc', 'done', 'okay', 'regret', 'search', 'googl', 'also', 'search', 'googl', 'see', 'small', 'letter', 'along', 'lemmat', 'entir', 'text', 'pre', 'process', 'also', 'appli', 'regular', 'express', 'clean', 'sentenc', 'remov', 'word', 'think', 'uh', 'also', 'work', 'probabl', 'comment', 'lower', 'lower', 'okay', 'check', 'comment', 'tri', 'okay', 'short', 'uh', 'understood', 'stopword', 'actual', 'basic', 'appli', 'thing', 'okay', 'ye', 'uh', 'side', 'think', 'like', 'entir', 'seri', 'uh', 'learn', 'thing', 'go', 'ahead', 'um', 'uh', 'post', 'tag', 'entiti', 'name', 'recognit', 'also', 'mani', 'thing', 'go', 'come', 'ye', 'uh', 'keep', 'learn', 'keep', 'practic', 'uh', 'see', 'next', 'video', 'thank']\n"
     ]
    }
   ],
   "source": [
    "### Apply stopwords and filter and then apply stemming\n",
    "\n",
    "def preprocess_sentences(sentences):\n",
    "    \"\"\"\n",
    "    Preprocesses a list of sentences by performing the following steps:\n",
    "    1. Tokenizes each sentence into words (using regex, not NLTK).\n",
    "    2. Removes English stopwords.\n",
    "    3. Applies stemming to each non-stopword.\n",
    "    4. Reconstructs and replaces the sentence with the processed version.\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of str): The list of raw input sentences.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            - processed_sentences (list of str): Sentences with stopwords removed and words stemmed.\n",
    "            - all_stemmed_words (list of str): Flat list of all processed words from all sentences.\n",
    "    \"\"\"\n",
    "    processed_sentences = []\n",
    "    all_stemmed_words = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", sentence)  # Skip punctuation here\n",
    "\n",
    "        # Filter stopwords and apply stemming\n",
    "        filtered = [stemmer.stem(word) for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "        # Update the sentence with processed tokens\n",
    "        processed_sentences.append(' '.join(filtered))\n",
    "\n",
    "        # Collect all stemmed words\n",
    "        all_stemmed_words.extend(filtered)\n",
    "\n",
    "    return processed_sentences, all_stemmed_words\n",
    "\n",
    "# Call the function\n",
    "processed_sentences, words = preprocess_sentences(sentences)\n",
    "\n",
    "# Output the results\n",
    "print(\"Processed Sentences:\", processed_sentences)\n",
    "print(\"Stemmed Words:\", words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33ad1244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Sentences: ['hello guy', 'continu discuss', 'respect natur languag process', 'still text pre process techniqu', 'seen token', 'seen stem', 'also seen differ type', 'along seen lemmat', 'go consid topic call stopword', 'video go discuss stopword import stopword', 'show help nltk', 'text process import step natur languag process realli need clean data', 'need make data right format', 'later tri convert text data vector abl train model', 'model know whenev say machin learn model intern realli need train mathemat equat', 'whenev train someth mathemat equat realli need give input data form numer float valu', 'let us go ahead let us understand exact stopword', 'open new notebook file', 'one amaz speech doctor apj abdul kalam', 'former presid india amaz speech', 'probabl read complet obvious given materi', 'actual go go probabl talk stopword import tri remov stop word', 'okay', 'uh definit exact stop word', 'particular speech see uh lot sentenc like three vision india 3000 year histori peopl world come invad us', 'entir speech', 'amaz speech', 'probabl learn would like uh tell', 'pleas read', 'get lot inform', 'motiv speech altogeth', 'particular speech see', 'definit say paragraph corpus right word like know uh let say uh know two right', 'kind word right', 'play big role task like spam classif', 'let say tri kind task respect uh know uh like spam ham classif alreadi told', 'uh along see whether posit review negat review word like actual play import role', '', 'help stop word know tri remov particular word uh kind use case specif focus import word determin output word like requir', 'basic pass entir paragraph particular stop word see word basic remov okay', 'import stopword short', 'let us go ahead right', 'go ahead execut', 'let make cell much easi understand appli stopword', 'along stopword also appli stem', 'show combin uh super import everyon', 'okay', 'let go ahead let uh tri okay', 'first realli need import uh stem', 'obvious know need import', 'stem write nltk dot stem import porter stemmer', 'basic write porter stemmer execut along', 'uh obvious need also import stopword stopword english differ entir list word like', 'right', 'go go say nlp k dot corpus import stopword', 'abl use stopword', 'import uh antiqu corpus import stopword', 'stopword know also download', 'uh let one thing', 'also import nltk execut', 'along write lcc dot download', 'paramet go give stopword', 'differ differ languag stopword also', 'also tri see', 'probabl write abl see download packag stopword particular locat', 'packag stopword alreadi date get true', 'short download differ differ languag stopword alreadi present nltk librari', 'perfect', 'done', 'let see stopword avail english', 'order', 'alreadi import nltk corpus import stopword', 'take stopword', 'copi past say dot download okay instead download write dot word', 'need give languag', 'like languag', 'realli want uh give like english someth els like german', 'go write', 'let write english', 'execut see list stop word obvious stop word actual remov', 'right', 'may think krish may depend data data', 'right see guy list', 'also creat stopword english like let say', 'import word like', 'right', 'word actual play import role', 'uh find whether statement posit negat like also', 'probabl search also abl find', 'okay', 'alway good way creat stopword tri remov kind word paragraph', 'hope everybodi abl understand respect english', 'let see whether respect differ differ languag', 'obvious go ahead check document tri show respect german', 'german also specif stop word', 'along also use french', 'particular stop word', 'respect differ differ text differ differ languag text definit appli differ differ stopword respect', 'may think hindi arab', 'think arab also think', 'let see whether', 'yes arab also find hindi guess', 'document check', 'till arab abl see', 'inform given document', 'actual go sentenc alreadi english', 'right go perform two import task', 'one appli stem', 'appli stem know actual go wherev find stop word go remov stop word particular paragraph entir paragraph shorten', 'right', 'actual go', 'see whatev thing learn start everyth actual go cover', 'okay', 'first thing first go say nltk dot stem go import porter stemmer', 'porter stemmer', 'go execut go execut okay', 'actual go go write stemmer equal porter stemmer', 'realli need initi', 'task right next step actual go go perform token entir paragraph', 'use nltk dot send token', 'go give paragraph', 'see guy go get entir paragraph entir sentenc like see three vision india', '3000 year thing abl get', 'second sentenc', 'third sentenc', 'fourth sentenc', 'like', 'sentenc form list abl get use cent underscor token', 'right', 'token process wherein take paragraph divid sentenc', 'okay let one thing go save variabl call sentenc let later becom list', 'right', 'sentenc', 'probabl see type sentenc go basic see', 'list', 'perfect till', 'done amaz well right', 'done porter stemmer', 'sorri', 'initi stemmer token', 'understand go go travers sentenc', 'first appli stopword word present stopword go take appli stem', 'realli want', 'say first appli stopword filter appli token', 'right', 'sorri', 'appli stem', 'step actual go', 'see simpl import', 'write loop say rang rang', 'go basic give length sentenc', 'also go respect sentenc', 'get index', 'get indic', 'okay rang basic say whatev length actual give becom index right', 'zero specif length', 'actual go take go take specif n um go write n nltk dot word token get form sentenc need get everi word right', 'get word insid word underscor token give sorri sentenc index sentenc', 'index', 'abl get word', 'make list word', 'short get list word insid sentenc', 'perfect', 'till done', 'go appli one import thing', 'first need appli stop word everi word see whether fall stop word', 'fall stop word stem', 'understand task step step', 'super import respect step actual take', 'okay write list comprehens', 'say stemmer dot stem okay', 'go write dot word okay word uh particular word word list word', 'take everi word', 'write loop okay', 'call list comprehens', 'write word word word see word present stop word appli stem', 'actual tri', 'okay basic see word', 'use set', 'along download stop word respect english', 'right', 'use step set word may get repeat', 'want', 'go basic write right', 'actual go get specif word present stop word', 'stem get appli specif word', 'perfect', 'actual go go save variabl call word perfect', 'hope much clear', 'get back everyth stem back word', 'final actual go go take sentenc go replac index respect word', 'get word right need join word togeth', 'join', 'obvious space dot', 'use dot join join togeth convert sentenc', 'exact convert word sentenc right', 'much simpl', 'actual done', 'perfect', 'thing done let repeat iter everi sentenc', 'word token basic mean everi sentenc get list word', 'list word iter see whether present stop word present stem', 'stem store back list convert word sentenc say convert list word sentenc', 'perfect', 'execut', 'go see sentenc abl see three vision india right 3000 year histori', 'right', 'h r becam ri okay peopl peopl becam peopl', 'world came invad us invad becam captur', 'land conquer mine', 'see special word like like', 'everyth gone', 'see see gone', 'right', 'though abl find though anyway right', 'whatev', 'stop', 'word present got remov', 'perform stem', 'right may say crush', 'uh stem look good right', 'need alreadi taught respect snowbal stemmer import', 'okay', 'simpl', 'simpl', 'think task', 'snowbal stemmer tri import respect english', 'obvious abl get good sentenc', 'right', 'let remov one', 'snowbal stemmer alreadi done go copi thing', 'okay', 'go say appli snowbal stemmer stem', 'right', 'instead stemmer write word snowbal stemmer', 'that', 'yeah', 'execut uh let go back back sentenc sentenc got chang', 'sentenc', 'let see', 'okay', 'sentenc got execut', 'go execut', 'probabl go see sentenc see good right', 'uh one import thing snowbal done', 'see still capit letter right', 'like may sentenc may small letter also', 'becom repeat word', 'sinc capit letter consid separ word right model understand', 'right', 'snowbal', 'one advantag make sure letter becom small', 'right', 'letter becom small', 'word even give good result like poverti becom poverti', 'tri help lemmat also get good word', 'let tri help lemmat', 'go uh thing', 'okay', 'hope everybodi understood respect snowbal stemmer', 'go go go back lemmat code', 'go import nltk dot stem', 'simpl guy', 'think repeat thing also practic better way okay', 'got word net lemmat go initi', 'perfect', 'done', 'go go go ahead copi code right', 'write', 'instead write snowbal go copi go past', 'perfect', 'done', 'let go ahead execut sentenc part need get updat sentenc', 'think somewher', 'paragraph', 'okay', 'uh sentenc', 'okay', 'perfect', 'let go ahead execut thing', 'okay get stem okay', 'sorri', 'lemmat', 'lemmat', 'okay', 'lemmat lemmat', 'see time took', 'right', 'basic check entir corpus', 'probabl go see sentenc amaz thing respect word come correct thing right', 'respect abl get good thing', 'one thing word also put post tag', 'put post tag v right see output', 'get better output guess word basic consid um know adverb sorri verb', 'anyhow tri understand post tag', 'thing', 'right', 'three vision india 3000 year histori peopl come would world come invad us captur land', 'stop word got delet', 'get good one', 'know uh least better stem', 'okay', 'one snowbal stem', 'right', 'entir process respect text pre process', 'discuss stop word also go ahead text pre process', 'hope everybodi got idea', 'lemmat also see lower', 'actual basic lower sentenc', 'right', 'let say write sentenc equal sentenc dot dot two lower right', 'basic give two lower', 'let see whether work', 'uh uh let see whether complet work', 'sure whether dot two lower work respect list think work', 'go execut', 'go okay appli lemmat', 'okay', 'uh str object attribut lower okay', 'okay', 'problem', 'problem', 'actual go go comment', 'write say word lower okay', 'definit tri differ differ thing okay', 'googl', 'know googl', 'abl get', 'go execut', 'think execut know', 'lot down', 'tri follow lectur', 'uh string object attribut lower underscor lower', 'lower', 'um okay', 'let see', 'uh str two lower case', 'right', 'python', 'let see', 'okay way see think dot lower definit work', 'let see', 'dot lower', 'okay', 'perfect', 'work', 'go see sentenc done okay', 'regret search googl', 'also search googl', 'see small letter along lemmat', 'entir text pre process', 'also appli regular express clean sentenc', 'remov word', 'think uh also work probabl comment lower lower', 'okay', 'check', '', 'comment tri', 'okay', 'short uh understood stopword actual basic appli thing', 'okay yes uh side', 'think like entir seri', 'uh learn thing go ahead', 'um uh post tag', 'entiti name recognit', 'also mani thing go come', 'yes uh keep learn keep practic', 'uh see next video', 'thank', '']\n",
      "Stemmed Words: ['hello', 'guy', 'continu', 'discuss', 'respect', 'natur', 'languag', 'process', 'still', 'text', 'pre', 'process', 'techniqu', 'seen', 'token', 'seen', 'stem', 'also', 'seen', 'differ', 'type', 'along', 'seen', 'lemmat', 'go', 'consid', 'topic', 'call', 'stopword', 'video', 'go', 'discuss', 'stopword', 'import', 'stopword', 'show', 'help', 'nltk', 'text', 'process', 'import', 'step', 'natur', 'languag', 'process', 'realli', 'need', 'clean', 'data', 'need', 'make', 'data', 'right', 'format', 'later', 'tri', 'convert', 'text', 'data', 'vector', 'abl', 'train', 'model', 'model', 'know', 'whenev', 'say', 'machin', 'learn', 'model', 'intern', 'realli', 'need', 'train', 'mathemat', 'equat', 'whenev', 'train', 'someth', 'mathemat', 'equat', 'realli', 'need', 'give', 'input', 'data', 'form', 'numer', 'float', 'valu', 'let', 'us', 'go', 'ahead', 'let', 'us', 'understand', 'exact', 'stopword', 'open', 'new', 'notebook', 'file', 'one', 'amaz', 'speech', 'doctor', 'apj', 'abdul', 'kalam', 'former', 'presid', 'india', 'amaz', 'speech', 'probabl', 'read', 'complet', 'obvious', 'given', 'materi', 'actual', 'go', 'go', 'probabl', 'talk', 'stopword', 'import', 'tri', 'remov', 'stop', 'word', 'okay', 'uh', 'definit', 'exact', 'stop', 'word', 'particular', 'speech', 'see', 'uh', 'lot', 'sentenc', 'like', 'three', 'vision', 'india', '3000', 'year', 'histori', 'peopl', 'world', 'come', 'invad', 'us', 'entir', 'speech', 'amaz', 'speech', 'probabl', 'learn', 'would', 'like', 'uh', 'tell', 'pleas', 'read', 'get', 'lot', 'inform', 'motiv', 'speech', 'altogeth', 'particular', 'speech', 'see', 'definit', 'say', 'paragraph', 'corpus', 'right', 'word', 'like', 'know', 'uh', 'let', 'say', 'uh', 'know', 'two', 'right', 'kind', 'word', 'right', 'play', 'big', 'role', 'task', 'like', 'spam', 'classif', 'let', 'say', 'tri', 'kind', 'task', 'respect', 'uh', 'know', 'uh', 'like', 'spam', 'ham', 'classif', 'alreadi', 'told', 'uh', 'along', 'see', 'whether', 'posit', 'review', 'negat', 'review', 'word', 'like', 'actual', 'play', 'import', 'role', 'help', 'stop', 'word', 'know', 'tri', 'remov', 'particular', 'word', 'uh', 'kind', 'use', 'case', 'specif', 'focus', 'import', 'word', 'determin', 'output', 'word', 'like', 'requir', 'basic', 'pass', 'entir', 'paragraph', 'particular', 'stop', 'word', 'see', 'word', 'basic', 'remov', 'okay', 'import', 'stopword', 'short', 'let', 'us', 'go', 'ahead', 'right', 'go', 'ahead', 'execut', 'let', 'make', 'cell', 'much', 'easi', 'understand', 'appli', 'stopword', 'along', 'stopword', 'also', 'appli', 'stem', 'show', 'combin', 'uh', 'super', 'import', 'everyon', 'okay', 'let', 'go', 'ahead', 'let', 'uh', 'tri', 'okay', 'first', 'realli', 'need', 'import', 'uh', 'stem', 'obvious', 'know', 'need', 'import', 'stem', 'write', 'nltk', 'dot', 'stem', 'import', 'porter', 'stemmer', 'basic', 'write', 'porter', 'stemmer', 'execut', 'along', 'uh', 'obvious', 'need', 'also', 'import', 'stopword', 'stopword', 'english', 'differ', 'entir', 'list', 'word', 'like', 'right', 'go', 'go', 'say', 'nlp', 'k', 'dot', 'corpus', 'import', 'stopword', 'abl', 'use', 'stopword', 'import', 'uh', 'antiqu', 'corpus', 'import', 'stopword', 'stopword', 'know', 'also', 'download', 'uh', 'let', 'one', 'thing', 'also', 'import', 'nltk', 'execut', 'along', 'write', 'lcc', 'dot', 'download', 'paramet', 'go', 'give', 'stopword', 'differ', 'differ', 'languag', 'stopword', 'also', 'also', 'tri', 'see', 'probabl', 'write', 'abl', 'see', 'download', 'packag', 'stopword', 'particular', 'locat', 'packag', 'stopword', 'alreadi', 'date', 'get', 'true', 'short', 'download', 'differ', 'differ', 'languag', 'stopword', 'alreadi', 'present', 'nltk', 'librari', 'perfect', 'done', 'let', 'see', 'stopword', 'avail', 'english', 'order', 'alreadi', 'import', 'nltk', 'corpus', 'import', 'stopword', 'take', 'stopword', 'copi', 'past', 'say', 'dot', 'download', 'okay', 'instead', 'download', 'write', 'dot', 'word', 'need', 'give', 'languag', 'like', 'languag', 'realli', 'want', 'uh', 'give', 'like', 'english', 'someth', 'els', 'like', 'german', 'go', 'write', 'let', 'write', 'english', 'execut', 'see', 'list', 'stop', 'word', 'obvious', 'stop', 'word', 'actual', 'remov', 'right', 'may', 'think', 'krish', 'may', 'depend', 'data', 'data', 'right', 'see', 'guy', 'list', 'also', 'creat', 'stopword', 'english', 'like', 'let', 'say', 'import', 'word', 'like', 'right', 'word', 'actual', 'play', 'import', 'role', 'uh', 'find', 'whether', 'statement', 'posit', 'negat', 'like', 'also', 'probabl', 'search', 'also', 'abl', 'find', 'okay', 'alway', 'good', 'way', 'creat', 'stopword', 'tri', 'remov', 'kind', 'word', 'paragraph', 'hope', 'everybodi', 'abl', 'understand', 'respect', 'english', 'let', 'see', 'whether', 'respect', 'differ', 'differ', 'languag', 'obvious', 'go', 'ahead', 'check', 'document', 'tri', 'show', 'respect', 'german', 'german', 'also', 'specif', 'stop', 'word', 'along', 'also', 'use', 'french', 'particular', 'stop', 'word', 'respect', 'differ', 'differ', 'text', 'differ', 'differ', 'languag', 'text', 'definit', 'appli', 'differ', 'differ', 'stopword', 'respect', 'may', 'think', 'hindi', 'arab', 'think', 'arab', 'also', 'think', 'let', 'see', 'whether', 'yes', 'arab', 'also', 'find', 'hindi', 'guess', 'document', 'check', 'till', 'arab', 'abl', 'see', 'inform', 'given', 'document', 'actual', 'go', 'sentenc', 'alreadi', 'english', 'right', 'go', 'perform', 'two', 'import', 'task', 'one', 'appli', 'stem', 'appli', 'stem', 'know', 'actual', 'go', 'wherev', 'find', 'stop', 'word', 'go', 'remov', 'stop', 'word', 'particular', 'paragraph', 'entir', 'paragraph', 'shorten', 'right', 'actual', 'go', 'see', 'whatev', 'thing', 'learn', 'start', 'everyth', 'actual', 'go', 'cover', 'okay', 'first', 'thing', 'first', 'go', 'say', 'nltk', 'dot', 'stem', 'go', 'import', 'porter', 'stemmer', 'porter', 'stemmer', 'go', 'execut', 'go', 'execut', 'okay', 'actual', 'go', 'go', 'write', 'stemmer', 'equal', 'porter', 'stemmer', 'realli', 'need', 'initi', 'task', 'right', 'next', 'step', 'actual', 'go', 'go', 'perform', 'token', 'entir', 'paragraph', 'use', 'nltk', 'dot', 'send', 'token', 'go', 'give', 'paragraph', 'see', 'guy', 'go', 'get', 'entir', 'paragraph', 'entir', 'sentenc', 'like', 'see', 'three', 'vision', 'india', '3000', 'year', 'thing', 'abl', 'get', 'second', 'sentenc', 'third', 'sentenc', 'fourth', 'sentenc', 'like', 'sentenc', 'form', 'list', 'abl', 'get', 'use', 'cent', 'underscor', 'token', 'right', 'token', 'process', 'wherein', 'take', 'paragraph', 'divid', 'sentenc', 'okay', 'let', 'one', 'thing', 'go', 'save', 'variabl', 'call', 'sentenc', 'let', 'later', 'becom', 'list', 'right', 'sentenc', 'probabl', 'see', 'type', 'sentenc', 'go', 'basic', 'see', 'list', 'perfect', 'till', 'done', 'amaz', 'well', 'right', 'done', 'porter', 'stemmer', 'sorri', 'initi', 'stemmer', 'token', 'understand', 'go', 'go', 'travers', 'sentenc', 'first', 'appli', 'stopword', 'word', 'present', 'stopword', 'go', 'take', 'appli', 'stem', 'realli', 'want', 'say', 'first', 'appli', 'stopword', 'filter', 'appli', 'token', 'right', 'sorri', 'appli', 'stem', 'step', 'actual', 'go', 'see', 'simpl', 'import', 'write', 'loop', 'say', 'rang', 'rang', 'go', 'basic', 'give', 'length', 'sentenc', 'also', 'go', 'respect', 'sentenc', 'get', 'index', 'get', 'indic', 'okay', 'rang', 'basic', 'say', 'whatev', 'length', 'actual', 'give', 'becom', 'index', 'right', 'zero', 'specif', 'length', 'actual', 'go', 'take', 'go', 'take', 'specif', 'n', 'um', 'go', 'write', 'n', 'nltk', 'dot', 'word', 'token', 'get', 'form', 'sentenc', 'need', 'get', 'everi', 'word', 'right', 'get', 'word', 'insid', 'word', 'underscor', 'token', 'give', 'sorri', 'sentenc', 'index', 'sentenc', 'index', 'abl', 'get', 'word', 'make', 'list', 'word', 'short', 'get', 'list', 'word', 'insid', 'sentenc', 'perfect', 'till', 'done', 'go', 'appli', 'one', 'import', 'thing', 'first', 'need', 'appli', 'stop', 'word', 'everi', 'word', 'see', 'whether', 'fall', 'stop', 'word', 'fall', 'stop', 'word', 'stem', 'understand', 'task', 'step', 'step', 'super', 'import', 'respect', 'step', 'actual', 'take', 'okay', 'write', 'list', 'comprehens', 'say', 'stemmer', 'dot', 'stem', 'okay', 'go', 'write', 'dot', 'word', 'okay', 'word', 'uh', 'particular', 'word', 'word', 'list', 'word', 'take', 'everi', 'word', 'write', 'loop', 'okay', 'call', 'list', 'comprehens', 'write', 'word', 'word', 'word', 'see', 'word', 'present', 'stop', 'word', 'appli', 'stem', 'actual', 'tri', 'okay', 'basic', 'see', 'word', 'use', 'set', 'along', 'download', 'stop', 'word', 'respect', 'english', 'right', 'use', 'step', 'set', 'word', 'may', 'get', 'repeat', 'want', 'go', 'basic', 'write', 'right', 'actual', 'go', 'get', 'specif', 'word', 'present', 'stop', 'word', 'stem', 'get', 'appli', 'specif', 'word', 'perfect', 'actual', 'go', 'go', 'save', 'variabl', 'call', 'word', 'perfect', 'hope', 'much', 'clear', 'get', 'back', 'everyth', 'stem', 'back', 'word', 'final', 'actual', 'go', 'go', 'take', 'sentenc', 'go', 'replac', 'index', 'respect', 'word', 'get', 'word', 'right', 'need', 'join', 'word', 'togeth', 'join', 'obvious', 'space', 'dot', 'use', 'dot', 'join', 'join', 'togeth', 'convert', 'sentenc', 'exact', 'convert', 'word', 'sentenc', 'right', 'much', 'simpl', 'actual', 'done', 'perfect', 'thing', 'done', 'let', 'repeat', 'iter', 'everi', 'sentenc', 'word', 'token', 'basic', 'mean', 'everi', 'sentenc', 'get', 'list', 'word', 'list', 'word', 'iter', 'see', 'whether', 'present', 'stop', 'word', 'present', 'stem', 'stem', 'store', 'back', 'list', 'convert', 'word', 'sentenc', 'say', 'convert', 'list', 'word', 'sentenc', 'perfect', 'execut', 'go', 'see', 'sentenc', 'abl', 'see', 'three', 'vision', 'india', 'right', '3000', 'year', 'histori', 'right', 'h', 'r', 'becam', 'ri', 'okay', 'peopl', 'peopl', 'becam', 'peopl', 'world', 'came', 'invad', 'us', 'invad', 'becam', 'captur', 'land', 'conquer', 'mine', 'see', 'special', 'word', 'like', 'like', 'everyth', 'gone', 'see', 'see', 'gone', 'right', 'though', 'abl', 'find', 'though', 'anyway', 'right', 'whatev', 'stop', 'word', 'present', 'got', 'remov', 'perform', 'stem', 'right', 'may', 'say', 'crush', 'uh', 'stem', 'look', 'good', 'right', 'need', 'alreadi', 'taught', 'respect', 'snowbal', 'stemmer', 'import', 'okay', 'simpl', 'simpl', 'think', 'task', 'snowbal', 'stemmer', 'tri', 'import', 'respect', 'english', 'obvious', 'abl', 'get', 'good', 'sentenc', 'right', 'let', 'remov', 'one', 'snowbal', 'stemmer', 'alreadi', 'done', 'go', 'copi', 'thing', 'okay', 'go', 'say', 'appli', 'snowbal', 'stemmer', 'stem', 'right', 'instead', 'stemmer', 'write', 'word', 'snowbal', 'stemmer', 'that', 'yeah', 'execut', 'uh', 'let', 'go', 'back', 'back', 'sentenc', 'sentenc', 'got', 'chang', 'sentenc', 'let', 'see', 'okay', 'sentenc', 'got', 'execut', 'go', 'execut', 'probabl', 'go', 'see', 'sentenc', 'see', 'good', 'right', 'uh', 'one', 'import', 'thing', 'snowbal', 'done', 'see', 'still', 'capit', 'letter', 'right', 'like', 'may', 'sentenc', 'may', 'small', 'letter', 'also', 'becom', 'repeat', 'word', 'sinc', 'capit', 'letter', 'consid', 'separ', 'word', 'right', 'model', 'understand', 'right', 'snowbal', 'one', 'advantag', 'make', 'sure', 'letter', 'becom', 'small', 'right', 'letter', 'becom', 'small', 'word', 'even', 'give', 'good', 'result', 'like', 'poverti', 'becom', 'poverti', 'tri', 'help', 'lemmat', 'also', 'get', 'good', 'word', 'let', 'tri', 'help', 'lemmat', 'go', 'uh', 'thing', 'okay', 'hope', 'everybodi', 'understood', 'respect', 'snowbal', 'stemmer', 'go', 'go', 'go', 'back', 'lemmat', 'code', 'go', 'import', 'nltk', 'dot', 'stem', 'simpl', 'guy', 'think', 'repeat', 'thing', 'also', 'practic', 'better', 'way', 'okay', 'got', 'word', 'net', 'lemmat', 'go', 'initi', 'perfect', 'done', 'go', 'go', 'go', 'ahead', 'copi', 'code', 'right', 'write', 'instead', 'write', 'snowbal', 'go', 'copi', 'go', 'past', 'perfect', 'done', 'let', 'go', 'ahead', 'execut', 'sentenc', 'part', 'need', 'get', 'updat', 'sentenc', 'think', 'somewher', 'paragraph', 'okay', 'uh', 'sentenc', 'okay', 'perfect', 'let', 'go', 'ahead', 'execut', 'thing', 'okay', 'get', 'stem', 'okay', 'sorri', 'lemmat', 'lemmat', 'okay', 'lemmat', 'lemmat', 'see', 'time', 'took', 'right', 'basic', 'check', 'entir', 'corpus', 'probabl', 'go', 'see', 'sentenc', 'amaz', 'thing', 'respect', 'word', 'come', 'correct', 'thing', 'right', 'respect', 'abl', 'get', 'good', 'thing', 'one', 'thing', 'word', 'also', 'put', 'post', 'tag', 'put', 'post', 'tag', 'v', 'right', 'see', 'output', 'get', 'better', 'output', 'guess', 'word', 'basic', 'consid', 'um', 'know', 'adverb', 'sorri', 'verb', 'anyhow', 'tri', 'understand', 'post', 'tag', 'thing', 'right', 'three', 'vision', 'india', '3000', 'year', 'histori', 'peopl', 'come', 'would', 'world', 'come', 'invad', 'us', 'captur', 'land', 'stop', 'word', 'got', 'delet', 'get', 'good', 'one', 'know', 'uh', 'least', 'better', 'stem', 'okay', 'one', 'snowbal', 'stem', 'right', 'entir', 'process', 'respect', 'text', 'pre', 'process', 'discuss', 'stop', 'word', 'also', 'go', 'ahead', 'text', 'pre', 'process', 'hope', 'everybodi', 'got', 'idea', 'lemmat', 'also', 'see', 'lower', 'actual', 'basic', 'lower', 'sentenc', 'right', 'let', 'say', 'write', 'sentenc', 'equal', 'sentenc', 'dot', 'dot', 'two', 'lower', 'right', 'basic', 'give', 'two', 'lower', 'let', 'see', 'whether', 'work', 'uh', 'uh', 'let', 'see', 'whether', 'complet', 'work', 'sure', 'whether', 'dot', 'two', 'lower', 'work', 'respect', 'list', 'think', 'work', 'go', 'execut', 'go', 'okay', 'appli', 'lemmat', 'okay', 'uh', 'str', 'object', 'attribut', 'lower', 'okay', 'okay', 'problem', 'problem', 'actual', 'go', 'go', 'comment', 'write', 'say', 'word', 'lower', 'okay', 'definit', 'tri', 'differ', 'differ', 'thing', 'okay', 'googl', 'know', 'googl', 'abl', 'get', 'go', 'execut', 'think', 'execut', 'know', 'lot', 'down', 'tri', 'follow', 'lectur', 'uh', 'string', 'object', 'attribut', 'lower', 'underscor', 'lower', 'lower', 'um', 'okay', 'let', 'see', 'uh', 'str', 'two', 'lower', 'case', 'right', 'python', 'let', 'see', 'okay', 'way', 'see', 'think', 'dot', 'lower', 'definit', 'work', 'let', 'see', 'dot', 'lower', 'okay', 'perfect', 'work', 'go', 'see', 'sentenc', 'done', 'okay', 'regret', 'search', 'googl', 'also', 'search', 'googl', 'see', 'small', 'letter', 'along', 'lemmat', 'entir', 'text', 'pre', 'process', 'also', 'appli', 'regular', 'express', 'clean', 'sentenc', 'remov', 'word', 'think', 'uh', 'also', 'work', 'probabl', 'comment', 'lower', 'lower', 'okay', 'check', 'comment', 'tri', 'okay', 'short', 'uh', 'understood', 'stopword', 'actual', 'basic', 'appli', 'thing', 'okay', 'yes', 'uh', 'side', 'think', 'like', 'entir', 'seri', 'uh', 'learn', 'thing', 'go', 'ahead', 'um', 'uh', 'post', 'tag', 'entiti', 'name', 'recognit', 'also', 'mani', 'thing', 'go', 'come', 'yes', 'uh', 'keep', 'learn', 'keep', 'practic', 'uh', 'see', 'next', 'video', 'thank']\n"
     ]
    }
   ],
   "source": [
    "### Apply stopwords and filter and then apply stemming using snowball stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer=SnowballStemmer('english')\n",
    "def preprocess_sentences(sentences):\n",
    "    \"\"\"\n",
    "    Preprocesses a list of sentences by performing the following steps:\n",
    "    1. Tokenizes each sentence into words (using regex, not NLTK).\n",
    "    2. Removes English stopwords.\n",
    "    3. Applies stemming to each non-stopword.\n",
    "    4. Reconstructs and replaces the sentence with the processed version.\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of str): The list of raw input sentences.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            - processed_sentences (list of str): Sentences with stopwords removed and words stemmed.\n",
    "            - all_stemmed_words (list of str): Flat list of all processed words from all sentences.\n",
    "    \"\"\"\n",
    "    processed_sentences = []\n",
    "    all_stemmed_words = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", sentence)  # Skip punctuation here\n",
    "\n",
    "        # Filter stopwords and apply stemming\n",
    "        filtered = [stemmer.stem(word) for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "        # Update the sentence with processed tokens\n",
    "        processed_sentences.append(' '.join(filtered))\n",
    "\n",
    "        # Collect all stemmed words\n",
    "        all_stemmed_words.extend(filtered)\n",
    "\n",
    "    return processed_sentences, all_stemmed_words\n",
    "\n",
    "# Call the function\n",
    "processed_sentences, words = preprocess_sentences(sentences)\n",
    "\n",
    "# Output the results\n",
    "print(\"Processed Sentences:\", processed_sentences)\n",
    "print(\"Stemmed Words:\", words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e05ad82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Sentences: ['Hello guy', 'continuing discussion', 'respect natural language processing', 'still text pre processing technique', 'seen tokenization', 'seen stemming', 'also seen different type', 'Along seen Lemmatization', 'going consider topic called Stopwords', 'video going discus Stopwords importance Stopwords', 'show help NLTK', 'text processing important step natural language processing really need clean data', 'need make data right format', 'Later try convert text data vector able train model', 'model know whenever say machine learning model internally really need train mathematical equation', 'whenever train something mathematical equation really need give input data form numerical floating value', \"let u go ahead let's u understand exactly Stopwords\", 'opened new notebook file', 'one amazing speech doctor APJ Abdul Kalam', 'former President India amazing speech', 'probably read completely obviously given material', 'actually going going probably talk Stopwords important try remove stop word', 'Okay', 'uh definition exactly stop word', 'particular speech see uh lot sentence like three vision India 3000 year history people world come invaded u', 'entire speech', 'amazing speech', 'probably learning would like uh tell', 'Please read', 'getting lot information', 'motivational speech altogether', 'particular speech see', \"definitely say paragraph corpus right word like know uh let's say uh know two right\", 'kind word right', 'play big role task like spam classification', \"let's say trying kind task respect uh know uh like spam ham classification already told\", 'uh along see whether positive review negative review word like actually play important role', '', 'help stop word know try remove particular word uh kind use case specifically focusing important word determine output word like required', 'basically pas entire paragraph particular stop word see word basically removed okay', 'importance stopwords short', 'let u go ahead right', 'go ahead execute', 'Let make cell much easy understand apply Stopwords', 'Along Stopwords also apply stemming', 'show combination uh super important everyone', 'Okay', \"let's go ahead let's uh try okay\", 'first really need import uh stemming', 'obviously know need import', 'stemming write NLTK dot stem import porter stemmer', 'basically write Porter stemmer execute along', 'Uh obviously need also import Stopwords stopwords English different entire list word like', 'right', 'going going say NLP k dot corpus import stopwords', 'able use stopwords', 'imported uh antique corpus import Stopwords', 'Stopwords know also download', 'uh let one thing', 'also import NLTK execute', 'along write LCC dot download', 'parameter going give stopwords', 'different different language stopwords also', 'also try see', 'probably write able see downloading package Stopwords particular location', 'package Stopwords already date getting true', 'short downloaded different different language Stopwords already present NLTK library', 'Perfect', 'done', \"let's see Stopwords available English\", 'order', 'already imported NLTK corpus import stopwords', 'take Stopwords', 'copy paste say dot download okay instead download write dot word', 'need give language', 'Like language', 'really want uh give like English something else like German', 'going write', 'Let write English', 'execute see list stop word obviously stop word actually removed', 'Right', 'may thinking Krish may depend data data', 'Right see guy list', \"also create stopwords English like let's say\", 'important word like', 'Right', 'word actually play important role', 'Uh find whether statement positive negative like also', 'probably search also able find', 'Okay', 'always good way create stopwords try remove kind word paragraph', 'hope everybody able understand respect English', \"let's see whether respect different different language\", 'obviously go ahead check documentation try show respect German', 'German also specific stop word', 'Along also use French', 'particular stop word', 'respect different different text different different language text definitely apply different different stopwords respect', 'may thinking Hindi Arabic', 'think Arabic also think', \"Let's see whether\", 'Yes Arabic also find Hindi guess', 'documentation check', 'till Arabic able see', 'information given documentation', 'actually going sentence already English', 'Right going perform two important task', 'One apply stemming', 'applying stemming know actually going wherever find stop word going remove stop word particular paragraph entire paragraph shortened', 'Right', 'actually going', 'see whatever thing learned starting everything actually going cover', 'Okay', 'first thing first going say NLTK dot stem going import porter stemmer', 'Porter stemmer', 'go execute going execute okay', 'actually going going write Stemmer equal Porter stemmer', 'really need initialize', 'task right next step actually going going perform tokenization entire paragraph', 'use NLTK dot send tokenize', 'going give paragraph', 'see guy going get entire paragraph entire sentence like see three vision India', '3000 year thing able get', 'second sentence', 'Third sentence', 'Fourth sentence', 'Like', 'sentence form list able get using cent underscore tokenize', 'Right', 'tokenization process wherein take paragraph divide sentence', 'Okay let one thing going save variable called sentence let later become list', 'Right', 'sentence', 'probably see type sentence going basically see', 'list', 'Perfect till', 'done amazingly well right', 'done Porter Stemmer', 'Sorry', 'initialized stemmer tokenized', 'understand going going traverse sentence', 'First apply stopwords word present stopwords going take apply stemming', 'really want', 'saying first apply stopwords filter apply tokenization', 'Right', 'Sorry', 'apply stemming', 'step actually going', 'see simple important', 'write loop saying range range', 'going basically give length sentence', 'also go respect sentence', 'getting index', 'getting index', 'Okay range basically say whatever length actually giving becomes index right', 'Zero specific length', 'actually going take going take specific n um going write n nltk dot word tokenize getting form sentence need get every word right', 'getting word inside word underscore tokenize give sorry sentence index sentence', 'index', 'able get word', 'make list word', 'short getting list word inside sentence', 'Perfect', 'till done', 'going apply one important thing', 'First need apply stop word every word see whether fall stop word', 'fall stop word stemming', 'understand task step step', 'super important respect step actually taking', 'Okay write list comprehension', 'say stemmer dot stem okay', 'going write dot word okay word uh particular word word list word', 'take every word', 'write loop okay', 'called list comprehension', 'write word word word see word present stop word apply stemming', 'actually trying', 'Okay basically see word', 'use set', 'Along download stop word respect English', 'Right', 'using step set word may get repeated', 'want', 'going basically write right', 'actually going get specific word present stop word', 'stemming getting applied specific word', 'Perfect', 'actually going going save variable called word perfect', 'hope much clear', 'getting back everything stemming back word', 'finally actually going going take sentence going replace index respect word', 'get word right need join word together', 'join', 'obviously space dot', 'use dot join join together convert sentence', 'exactly converting word sentence right', 'much simple', 'actually done', 'Perfect', 'thing done let repeat iterating every sentence', 'word tokenize basically mean every sentence getting list word', 'list word iterating seeing whether present stop word present stemming', 'stemming storing back list converting word sentence say converting list word sentence', 'Perfect', 'execute', 'go see sentence able see three vision India right 3000 year history', 'Right', 'h r became RI okay people people became people', 'World came invaded u invade became captured', 'Land conquer mined', 'see special word like like', 'Everything gone', 'See see gone', 'Right', 'Though able find though anyway right', 'whatever', 'Stop', 'Words present got removed', 'performed stemming', 'Right may saying crush', 'Uh stemming look good right', 'need already taught respect snowball stemmer import', 'Okay', 'simple', 'Simple', 'think task', 'snowball stemmer try import respect English', 'obviously able get good sentence', 'Right', 'let remove one', 'snowball stemmer already done going copy thing', 'Okay', 'going say apply snowball stemmer stemming', 'Right', 'instead stemmer write word snowball stemmer', \"That's\", 'Yeah', 'execute uh let go back back sentence sentence got changed', 'sentence', \"Let's see\", 'Okay', 'sentence got executed', 'going execute', 'probably go see sentence see good right', 'uh one important thing snowball done', 'See still capital letter right', 'Like may sentence may small letter also', 'becomes repeated word', 'since capital letter considered separate word right model understand', 'Right', 'snowball', 'One advantage making sure letter becoming small', 'Right', 'letter becoming small', 'word even giving good result like poverty become poverty', 'try help Lemmatization also get good word', \"let's try help Lemmatization\", 'going uh thing', 'Okay', 'hope everybody understood respect snowball stemmer', 'going going go back Lemmatization code', 'going import NLTK dot stem', 'simple guy', 'think repeating thing also practice better way okay', 'got word net lemmatizer going initialize', 'Perfect', 'done', 'going go go ahead copy code right', 'write', 'instead writing snowball going copy going paste', 'Perfect', 'done', 'let go ahead execute sentence part need get updated sentence', 'think somewhere', 'Paragraph', 'Okay', 'uh sentence', 'Okay', 'Perfect', 'let go ahead execute thing', 'okay getting Stem okay', 'Sorry', 'lemmatize', 'Lemmatize', 'Okay', 'Lemmatize Lemmatize', 'see time took', 'Right', 'basically checking entire corpus', 'probably go see sentence amazing thing respect word coming correctly thing right', 'respect able get good thing', 'one thing word also put post tag', 'put post tag V right see output', 'get better output guess word basically considering um know adverb sorry verb', 'anyhow try understand post tag', 'thing', 'Right', 'three vision India 3000 year history people come would world come invade u capture land', 'stop word got deleted', 'getting good one', 'know uh least better stemming', 'Okay', 'one snowball stemming', 'Right', 'entire process respect text pre processing', 'discussed stop word also go ahead text pre processing', 'hope everybody got idea', 'Lemmatization also see lowering', 'actually basically lower sentence', 'right', \"let's say write sentence equal sentence dot dot two lower right\", 'basically give two lower', \"Let's see whether work\", \"Uh uh let's see whether completely work\", 'sure whether dot two lower work respect list think work', 'going execute', 'Go okay apply Lemmatizer', 'Okay', 'Uh str object attribute lower okay', 'okay', 'problem', 'problem', 'actually going going comment', 'writing say word lower okay', 'definitely try different different thing okay', 'Google', 'know Google', 'able get', 'going execute', 'think execute know', 'lot down', 'try follow lecture', 'Uh string object attribute lower underscore lower', 'lower', 'Um okay', 'Let see', 'Uh str two lower case', 'Right', 'Python', 'Let see', 'okay way see think dot lower definitely work', \"Let's see\", 'Dot lower', 'Okay', 'Perfect', 'worked', 'go see sentence done okay', 'regret search Google', 'also search Google', 'see small letter along lemmatization', 'entire text pre processing', 'also apply regular expression cleaning sentence', 'remove word', 'think uh also work probably comment lower lower', 'Okay', 'check', '', 'comment try', 'Okay', 'short uh understood Stopwords actually basically apply thing', 'Okay yes uh side', 'think liking entire series', 'Uh learning thing go ahead', 'Um uh post tag', 'entity name recognition', 'Also many thing going come', 'yes uh keep learning keep practicing', 'Uh see next video', 'Thank', '']\n",
      "lemmatized Words: ['Hello', 'guy', 'continuing', 'discussion', 'respect', 'natural', 'language', 'processing', 'still', 'text', 'pre', 'processing', 'technique', 'seen', 'tokenization', 'seen', 'stemming', 'also', 'seen', 'different', 'type', 'Along', 'seen', 'Lemmatization', 'going', 'consider', 'topic', 'called', 'Stopwords', 'video', 'going', 'discus', 'Stopwords', 'importance', 'Stopwords', 'show', 'help', 'NLTK', 'text', 'processing', 'important', 'step', 'natural', 'language', 'processing', 'really', 'need', 'clean', 'data', 'need', 'make', 'data', 'right', 'format', 'Later', 'try', 'convert', 'text', 'data', 'vector', 'able', 'train', 'model', 'model', 'know', 'whenever', 'say', 'machine', 'learning', 'model', 'internally', 'really', 'need', 'train', 'mathematical', 'equation', 'whenever', 'train', 'something', 'mathematical', 'equation', 'really', 'need', 'give', 'input', 'data', 'form', 'numerical', 'floating', 'value', 'let', 'u', 'go', 'ahead', \"let's\", 'u', 'understand', 'exactly', 'Stopwords', 'opened', 'new', 'notebook', 'file', 'one', 'amazing', 'speech', 'doctor', 'APJ', 'Abdul', 'Kalam', 'former', 'President', 'India', 'amazing', 'speech', 'probably', 'read', 'completely', 'obviously', 'given', 'material', 'actually', 'going', 'going', 'probably', 'talk', 'Stopwords', 'important', 'try', 'remove', 'stop', 'word', 'Okay', 'uh', 'definition', 'exactly', 'stop', 'word', 'particular', 'speech', 'see', 'uh', 'lot', 'sentence', 'like', 'three', 'vision', 'India', '3000', 'year', 'history', 'people', 'world', 'come', 'invaded', 'u', 'entire', 'speech', 'amazing', 'speech', 'probably', 'learning', 'would', 'like', 'uh', 'tell', 'Please', 'read', 'getting', 'lot', 'information', 'motivational', 'speech', 'altogether', 'particular', 'speech', 'see', 'definitely', 'say', 'paragraph', 'corpus', 'right', 'word', 'like', 'know', 'uh', \"let's\", 'say', 'uh', 'know', 'two', 'right', 'kind', 'word', 'right', 'play', 'big', 'role', 'task', 'like', 'spam', 'classification', \"let's\", 'say', 'trying', 'kind', 'task', 'respect', 'uh', 'know', 'uh', 'like', 'spam', 'ham', 'classification', 'already', 'told', 'uh', 'along', 'see', 'whether', 'positive', 'review', 'negative', 'review', 'word', 'like', 'actually', 'play', 'important', 'role', 'help', 'stop', 'word', 'know', 'try', 'remove', 'particular', 'word', 'uh', 'kind', 'use', 'case', 'specifically', 'focusing', 'important', 'word', 'determine', 'output', 'word', 'like', 'required', 'basically', 'pas', 'entire', 'paragraph', 'particular', 'stop', 'word', 'see', 'word', 'basically', 'removed', 'okay', 'importance', 'stopwords', 'short', 'let', 'u', 'go', 'ahead', 'right', 'go', 'ahead', 'execute', 'Let', 'make', 'cell', 'much', 'easy', 'understand', 'apply', 'Stopwords', 'Along', 'Stopwords', 'also', 'apply', 'stemming', 'show', 'combination', 'uh', 'super', 'important', 'everyone', 'Okay', \"let's\", 'go', 'ahead', \"let's\", 'uh', 'try', 'okay', 'first', 'really', 'need', 'import', 'uh', 'stemming', 'obviously', 'know', 'need', 'import', 'stemming', 'write', 'NLTK', 'dot', 'stem', 'import', 'porter', 'stemmer', 'basically', 'write', 'Porter', 'stemmer', 'execute', 'along', 'Uh', 'obviously', 'need', 'also', 'import', 'Stopwords', 'stopwords', 'English', 'different', 'entire', 'list', 'word', 'like', 'right', 'going', 'going', 'say', 'NLP', 'k', 'dot', 'corpus', 'import', 'stopwords', 'able', 'use', 'stopwords', 'imported', 'uh', 'antique', 'corpus', 'import', 'Stopwords', 'Stopwords', 'know', 'also', 'download', 'uh', 'let', 'one', 'thing', 'also', 'import', 'NLTK', 'execute', 'along', 'write', 'LCC', 'dot', 'download', 'parameter', 'going', 'give', 'stopwords', 'different', 'different', 'language', 'stopwords', 'also', 'also', 'try', 'see', 'probably', 'write', 'able', 'see', 'downloading', 'package', 'Stopwords', 'particular', 'location', 'package', 'Stopwords', 'already', 'date', 'getting', 'true', 'short', 'downloaded', 'different', 'different', 'language', 'Stopwords', 'already', 'present', 'NLTK', 'library', 'Perfect', 'done', \"let's\", 'see', 'Stopwords', 'available', 'English', 'order', 'already', 'imported', 'NLTK', 'corpus', 'import', 'stopwords', 'take', 'Stopwords', 'copy', 'paste', 'say', 'dot', 'download', 'okay', 'instead', 'download', 'write', 'dot', 'word', 'need', 'give', 'language', 'Like', 'language', 'really', 'want', 'uh', 'give', 'like', 'English', 'something', 'else', 'like', 'German', 'going', 'write', 'Let', 'write', 'English', 'execute', 'see', 'list', 'stop', 'word', 'obviously', 'stop', 'word', 'actually', 'removed', 'Right', 'may', 'thinking', 'Krish', 'may', 'depend', 'data', 'data', 'Right', 'see', 'guy', 'list', 'also', 'create', 'stopwords', 'English', 'like', \"let's\", 'say', 'important', 'word', 'like', 'Right', 'word', 'actually', 'play', 'important', 'role', 'Uh', 'find', 'whether', 'statement', 'positive', 'negative', 'like', 'also', 'probably', 'search', 'also', 'able', 'find', 'Okay', 'always', 'good', 'way', 'create', 'stopwords', 'try', 'remove', 'kind', 'word', 'paragraph', 'hope', 'everybody', 'able', 'understand', 'respect', 'English', \"let's\", 'see', 'whether', 'respect', 'different', 'different', 'language', 'obviously', 'go', 'ahead', 'check', 'documentation', 'try', 'show', 'respect', 'German', 'German', 'also', 'specific', 'stop', 'word', 'Along', 'also', 'use', 'French', 'particular', 'stop', 'word', 'respect', 'different', 'different', 'text', 'different', 'different', 'language', 'text', 'definitely', 'apply', 'different', 'different', 'stopwords', 'respect', 'may', 'thinking', 'Hindi', 'Arabic', 'think', 'Arabic', 'also', 'think', \"Let's\", 'see', 'whether', 'Yes', 'Arabic', 'also', 'find', 'Hindi', 'guess', 'documentation', 'check', 'till', 'Arabic', 'able', 'see', 'information', 'given', 'documentation', 'actually', 'going', 'sentence', 'already', 'English', 'Right', 'going', 'perform', 'two', 'important', 'task', 'One', 'apply', 'stemming', 'applying', 'stemming', 'know', 'actually', 'going', 'wherever', 'find', 'stop', 'word', 'going', 'remove', 'stop', 'word', 'particular', 'paragraph', 'entire', 'paragraph', 'shortened', 'Right', 'actually', 'going', 'see', 'whatever', 'thing', 'learned', 'starting', 'everything', 'actually', 'going', 'cover', 'Okay', 'first', 'thing', 'first', 'going', 'say', 'NLTK', 'dot', 'stem', 'going', 'import', 'porter', 'stemmer', 'Porter', 'stemmer', 'go', 'execute', 'going', 'execute', 'okay', 'actually', 'going', 'going', 'write', 'Stemmer', 'equal', 'Porter', 'stemmer', 'really', 'need', 'initialize', 'task', 'right', 'next', 'step', 'actually', 'going', 'going', 'perform', 'tokenization', 'entire', 'paragraph', 'use', 'NLTK', 'dot', 'send', 'tokenize', 'going', 'give', 'paragraph', 'see', 'guy', 'going', 'get', 'entire', 'paragraph', 'entire', 'sentence', 'like', 'see', 'three', 'vision', 'India', '3000', 'year', 'thing', 'able', 'get', 'second', 'sentence', 'Third', 'sentence', 'Fourth', 'sentence', 'Like', 'sentence', 'form', 'list', 'able', 'get', 'using', 'cent', 'underscore', 'tokenize', 'Right', 'tokenization', 'process', 'wherein', 'take', 'paragraph', 'divide', 'sentence', 'Okay', 'let', 'one', 'thing', 'going', 'save', 'variable', 'called', 'sentence', 'let', 'later', 'become', 'list', 'Right', 'sentence', 'probably', 'see', 'type', 'sentence', 'going', 'basically', 'see', 'list', 'Perfect', 'till', 'done', 'amazingly', 'well', 'right', 'done', 'Porter', 'Stemmer', 'Sorry', 'initialized', 'stemmer', 'tokenized', 'understand', 'going', 'going', 'traverse', 'sentence', 'First', 'apply', 'stopwords', 'word', 'present', 'stopwords', 'going', 'take', 'apply', 'stemming', 'really', 'want', 'saying', 'first', 'apply', 'stopwords', 'filter', 'apply', 'tokenization', 'Right', 'Sorry', 'apply', 'stemming', 'step', 'actually', 'going', 'see', 'simple', 'important', 'write', 'loop', 'saying', 'range', 'range', 'going', 'basically', 'give', 'length', 'sentence', 'also', 'go', 'respect', 'sentence', 'getting', 'index', 'getting', 'index', 'Okay', 'range', 'basically', 'say', 'whatever', 'length', 'actually', 'giving', 'becomes', 'index', 'right', 'Zero', 'specific', 'length', 'actually', 'going', 'take', 'going', 'take', 'specific', 'n', 'um', 'going', 'write', 'n', 'nltk', 'dot', 'word', 'tokenize', 'getting', 'form', 'sentence', 'need', 'get', 'every', 'word', 'right', 'getting', 'word', 'inside', 'word', 'underscore', 'tokenize', 'give', 'sorry', 'sentence', 'index', 'sentence', 'index', 'able', 'get', 'word', 'make', 'list', 'word', 'short', 'getting', 'list', 'word', 'inside', 'sentence', 'Perfect', 'till', 'done', 'going', 'apply', 'one', 'important', 'thing', 'First', 'need', 'apply', 'stop', 'word', 'every', 'word', 'see', 'whether', 'fall', 'stop', 'word', 'fall', 'stop', 'word', 'stemming', 'understand', 'task', 'step', 'step', 'super', 'important', 'respect', 'step', 'actually', 'taking', 'Okay', 'write', 'list', 'comprehension', 'say', 'stemmer', 'dot', 'stem', 'okay', 'going', 'write', 'dot', 'word', 'okay', 'word', 'uh', 'particular', 'word', 'word', 'list', 'word', 'take', 'every', 'word', 'write', 'loop', 'okay', 'called', 'list', 'comprehension', 'write', 'word', 'word', 'word', 'see', 'word', 'present', 'stop', 'word', 'apply', 'stemming', 'actually', 'trying', 'Okay', 'basically', 'see', 'word', 'use', 'set', 'Along', 'download', 'stop', 'word', 'respect', 'English', 'Right', 'using', 'step', 'set', 'word', 'may', 'get', 'repeated', 'want', 'going', 'basically', 'write', 'right', 'actually', 'going', 'get', 'specific', 'word', 'present', 'stop', 'word', 'stemming', 'getting', 'applied', 'specific', 'word', 'Perfect', 'actually', 'going', 'going', 'save', 'variable', 'called', 'word', 'perfect', 'hope', 'much', 'clear', 'getting', 'back', 'everything', 'stemming', 'back', 'word', 'finally', 'actually', 'going', 'going', 'take', 'sentence', 'going', 'replace', 'index', 'respect', 'word', 'get', 'word', 'right', 'need', 'join', 'word', 'together', 'join', 'obviously', 'space', 'dot', 'use', 'dot', 'join', 'join', 'together', 'convert', 'sentence', 'exactly', 'converting', 'word', 'sentence', 'right', 'much', 'simple', 'actually', 'done', 'Perfect', 'thing', 'done', 'let', 'repeat', 'iterating', 'every', 'sentence', 'word', 'tokenize', 'basically', 'mean', 'every', 'sentence', 'getting', 'list', 'word', 'list', 'word', 'iterating', 'seeing', 'whether', 'present', 'stop', 'word', 'present', 'stemming', 'stemming', 'storing', 'back', 'list', 'converting', 'word', 'sentence', 'say', 'converting', 'list', 'word', 'sentence', 'Perfect', 'execute', 'go', 'see', 'sentence', 'able', 'see', 'three', 'vision', 'India', 'right', '3000', 'year', 'history', 'Right', 'h', 'r', 'became', 'RI', 'okay', 'people', 'people', 'became', 'people', 'World', 'came', 'invaded', 'u', 'invade', 'became', 'captured', 'Land', 'conquer', 'mined', 'see', 'special', 'word', 'like', 'like', 'Everything', 'gone', 'See', 'see', 'gone', 'Right', 'Though', 'able', 'find', 'though', 'anyway', 'right', 'whatever', 'Stop', 'Words', 'present', 'got', 'removed', 'performed', 'stemming', 'Right', 'may', 'saying', 'crush', 'Uh', 'stemming', 'look', 'good', 'right', 'need', 'already', 'taught', 'respect', 'snowball', 'stemmer', 'import', 'Okay', 'simple', 'Simple', 'think', 'task', 'snowball', 'stemmer', 'try', 'import', 'respect', 'English', 'obviously', 'able', 'get', 'good', 'sentence', 'Right', 'let', 'remove', 'one', 'snowball', 'stemmer', 'already', 'done', 'going', 'copy', 'thing', 'Okay', 'going', 'say', 'apply', 'snowball', 'stemmer', 'stemming', 'Right', 'instead', 'stemmer', 'write', 'word', 'snowball', 'stemmer', \"That's\", 'Yeah', 'execute', 'uh', 'let', 'go', 'back', 'back', 'sentence', 'sentence', 'got', 'changed', 'sentence', \"Let's\", 'see', 'Okay', 'sentence', 'got', 'executed', 'going', 'execute', 'probably', 'go', 'see', 'sentence', 'see', 'good', 'right', 'uh', 'one', 'important', 'thing', 'snowball', 'done', 'See', 'still', 'capital', 'letter', 'right', 'Like', 'may', 'sentence', 'may', 'small', 'letter', 'also', 'becomes', 'repeated', 'word', 'since', 'capital', 'letter', 'considered', 'separate', 'word', 'right', 'model', 'understand', 'Right', 'snowball', 'One', 'advantage', 'making', 'sure', 'letter', 'becoming', 'small', 'Right', 'letter', 'becoming', 'small', 'word', 'even', 'giving', 'good', 'result', 'like', 'poverty', 'become', 'poverty', 'try', 'help', 'Lemmatization', 'also', 'get', 'good', 'word', \"let's\", 'try', 'help', 'Lemmatization', 'going', 'uh', 'thing', 'Okay', 'hope', 'everybody', 'understood', 'respect', 'snowball', 'stemmer', 'going', 'going', 'go', 'back', 'Lemmatization', 'code', 'going', 'import', 'NLTK', 'dot', 'stem', 'simple', 'guy', 'think', 'repeating', 'thing', 'also', 'practice', 'better', 'way', 'okay', 'got', 'word', 'net', 'lemmatizer', 'going', 'initialize', 'Perfect', 'done', 'going', 'go', 'go', 'ahead', 'copy', 'code', 'right', 'write', 'instead', 'writing', 'snowball', 'going', 'copy', 'going', 'paste', 'Perfect', 'done', 'let', 'go', 'ahead', 'execute', 'sentence', 'part', 'need', 'get', 'updated', 'sentence', 'think', 'somewhere', 'Paragraph', 'Okay', 'uh', 'sentence', 'Okay', 'Perfect', 'let', 'go', 'ahead', 'execute', 'thing', 'okay', 'getting', 'Stem', 'okay', 'Sorry', 'lemmatize', 'Lemmatize', 'Okay', 'Lemmatize', 'Lemmatize', 'see', 'time', 'took', 'Right', 'basically', 'checking', 'entire', 'corpus', 'probably', 'go', 'see', 'sentence', 'amazing', 'thing', 'respect', 'word', 'coming', 'correctly', 'thing', 'right', 'respect', 'able', 'get', 'good', 'thing', 'one', 'thing', 'word', 'also', 'put', 'post', 'tag', 'put', 'post', 'tag', 'V', 'right', 'see', 'output', 'get', 'better', 'output', 'guess', 'word', 'basically', 'considering', 'um', 'know', 'adverb', 'sorry', 'verb', 'anyhow', 'try', 'understand', 'post', 'tag', 'thing', 'Right', 'three', 'vision', 'India', '3000', 'year', 'history', 'people', 'come', 'would', 'world', 'come', 'invade', 'u', 'capture', 'land', 'stop', 'word', 'got', 'deleted', 'getting', 'good', 'one', 'know', 'uh', 'least', 'better', 'stemming', 'Okay', 'one', 'snowball', 'stemming', 'Right', 'entire', 'process', 'respect', 'text', 'pre', 'processing', 'discussed', 'stop', 'word', 'also', 'go', 'ahead', 'text', 'pre', 'processing', 'hope', 'everybody', 'got', 'idea', 'Lemmatization', 'also', 'see', 'lowering', 'actually', 'basically', 'lower', 'sentence', 'right', \"let's\", 'say', 'write', 'sentence', 'equal', 'sentence', 'dot', 'dot', 'two', 'lower', 'right', 'basically', 'give', 'two', 'lower', \"Let's\", 'see', 'whether', 'work', 'Uh', 'uh', \"let's\", 'see', 'whether', 'completely', 'work', 'sure', 'whether', 'dot', 'two', 'lower', 'work', 'respect', 'list', 'think', 'work', 'going', 'execute', 'Go', 'okay', 'apply', 'Lemmatizer', 'Okay', 'Uh', 'str', 'object', 'attribute', 'lower', 'okay', 'okay', 'problem', 'problem', 'actually', 'going', 'going', 'comment', 'writing', 'say', 'word', 'lower', 'okay', 'definitely', 'try', 'different', 'different', 'thing', 'okay', 'Google', 'know', 'Google', 'able', 'get', 'going', 'execute', 'think', 'execute', 'know', 'lot', 'down', 'try', 'follow', 'lecture', 'Uh', 'string', 'object', 'attribute', 'lower', 'underscore', 'lower', 'lower', 'Um', 'okay', 'Let', 'see', 'Uh', 'str', 'two', 'lower', 'case', 'Right', 'Python', 'Let', 'see', 'okay', 'way', 'see', 'think', 'dot', 'lower', 'definitely', 'work', \"Let's\", 'see', 'Dot', 'lower', 'Okay', 'Perfect', 'worked', 'go', 'see', 'sentence', 'done', 'okay', 'regret', 'search', 'Google', 'also', 'search', 'Google', 'see', 'small', 'letter', 'along', 'lemmatization', 'entire', 'text', 'pre', 'processing', 'also', 'apply', 'regular', 'expression', 'cleaning', 'sentence', 'remove', 'word', 'think', 'uh', 'also', 'work', 'probably', 'comment', 'lower', 'lower', 'Okay', 'check', 'comment', 'try', 'Okay', 'short', 'uh', 'understood', 'Stopwords', 'actually', 'basically', 'apply', 'thing', 'Okay', 'yes', 'uh', 'side', 'think', 'liking', 'entire', 'series', 'Uh', 'learning', 'thing', 'go', 'ahead', 'Um', 'uh', 'post', 'tag', 'entity', 'name', 'recognition', 'Also', 'many', 'thing', 'going', 'come', 'yes', 'uh', 'keep', 'learning', 'keep', 'practicing', 'Uh', 'see', 'next', 'video', 'Thank']\n"
     ]
    }
   ],
   "source": [
    "### Apply stopwords and filter and then apply stemming using word lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "def preprocess_sentences(sentences):\n",
    "    \"\"\"\n",
    "    Preprocesses a list of sentences by performing the following steps:\n",
    "    1. Tokenizes each sentence into words (using regex, not NLTK).\n",
    "    2. Removes English stopwords.\n",
    "    3. Applies lemmatization to each non-stopword.\n",
    "    4. Reconstructs and replaces the sentence with the processed version.\n",
    "    \n",
    "    Args:\n",
    "        sentences (list of str): The list of raw input sentences.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            - processed_sentences (list of str): Sentences with stopwords removed and words stemmed.\n",
    "            - all_stemmed_words (list of str): Flat list of all processed words from all sentences.\n",
    "    \"\"\"\n",
    "    processed_sentences = []\n",
    "    all_lemmatized_words = []\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Tokenize the sentence\n",
    "        tokens = re.findall(r\"\\b\\w+(?:'\\w+)?\\b\", sentence)  # Skip punctuation here\n",
    "\n",
    "        # Filter stopwords and apply stemming\n",
    "        filtered = [lemmatizer.lemmatize(word) for word in tokens if word.lower() not in stop_words]\n",
    "\n",
    "        # Update the sentence with processed tokens\n",
    "        processed_sentences.append(' '.join(filtered))\n",
    "\n",
    "        # Collect all stemmed words\n",
    "        all_lemmatized_words.extend(filtered)\n",
    "\n",
    "    return processed_sentences, all_lemmatized_words\n",
    "\n",
    "# Call the function\n",
    "processed_sentences, words = preprocess_sentences(sentences)\n",
    "\n",
    "# Output the results\n",
    "print(\"Processed Sentences:\", processed_sentences)\n",
    "print(\"lemmatized Words:\", words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eaa453",
   "metadata": {},
   "source": [
    "### PART OF SPEECH TAGGING USING NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e138dbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\susha/nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5b07b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original sentence: \n",
      "Hello guys.\n",
      "POS tags: [('\\n', 'SPACE'), ('Hello', 'PROPN'), ('guys', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So we'll be continuing the discussion.\n",
      "POS tags: [('So', 'ADV'), ('we', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('continuing', 'VERB'), ('the', 'DET'), ('discussion', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: With respect to natural language processing.\n",
      "POS tags: [('With', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We are still in text pre-processing techniques.\n",
      "POS tags: [('We', 'PRON'), ('are', 'AUX'), ('still', 'ADV'), ('in', 'ADP'), ('text', 'NOUN'), ('pre', 'ADJ'), ('-', 'ADJ'), ('processing', 'ADJ'), ('techniques', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We have seen tokenization.\n",
      "POS tags: [('We', 'PRON'), ('have', 'AUX'), ('seen', 'VERB'), ('tokenization', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We have seen stemming.\n",
      "POS tags: [('We', 'PRON'), ('have', 'AUX'), ('seen', 'VERB'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We have also seen its different types.\n",
      "POS tags: [('We', 'PRON'), ('have', 'AUX'), ('also', 'ADV'), ('seen', 'VERB'), ('its', 'PRON'), ('different', 'ADJ'), ('types', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Along with that we have seen Lemmatization.\n",
      "POS tags: [('Along', 'ADP'), ('with', 'ADP'), ('that', 'SCONJ'), ('we', 'PRON'), ('have', 'AUX'), ('seen', 'VERB'), ('Lemmatization', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now we are going to consider a topic which is called as Stopwords.\n",
      "POS tags: [('Now', 'ADV'), ('we', 'PRON'), ('are', 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('consider', 'VERB'), ('a', 'DET'), ('topic', 'NOUN'), ('which', 'PRON'), ('is', 'AUX'), ('called', 'VERB'), ('as', 'ADP'), ('Stopwords', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So in this video I'm going to discuss about Stopwords the importance of Stopwords.\n",
      "POS tags: [('So', 'ADV'), ('in', 'ADP'), ('this', 'DET'), ('video', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('discuss', 'VERB'), ('about', 'ADP'), ('Stopwords', 'PROPN'), ('the', 'DET'), ('importance', 'NOUN'), ('of', 'ADP'), ('Stopwords', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And again I'll show you with the help of NLTK.\n",
      "POS tags: [('And', 'CCONJ'), ('again', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('show', 'VERB'), ('you', 'PRON'), ('with', 'ADP'), ('the', 'DET'), ('help', 'NOUN'), ('of', 'ADP'), ('NLTK', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, text processing is a very important step in natural language processing because you really need\n",
      "\n",
      "to clean the data.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('text', 'NOUN'), ('processing', 'NOUN'), ('is', 'AUX'), ('a', 'DET'), ('very', 'ADV'), ('important', 'ADJ'), ('step', 'NOUN'), ('in', 'ADP'), ('natural', 'ADJ'), ('language', 'NOUN'), ('processing', 'NOUN'), ('because', 'SCONJ'), ('you', 'PRON'), ('really', 'ADV'), ('need', 'VERB'), ('\\n\\n', 'SPACE'), ('to', 'PART'), ('clean', 'VERB'), ('the', 'DET'), ('data', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You need to make the data in the right format.\n",
      "POS tags: [('You', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('make', 'VERB'), ('the', 'DET'), ('data', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('right', 'ADJ'), ('format', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Later on, we'll try to convert all this text data into vectors, and then only we'll be able to train\n",
      "\n",
      "the model.\n",
      "POS tags: [('Later', 'ADV'), ('on', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), (\"'ll\", 'AUX'), ('try', 'VERB'), ('to', 'PART'), ('convert', 'VERB'), ('all', 'DET'), ('this', 'DET'), ('text', 'NOUN'), ('data', 'NOUN'), ('into', 'ADP'), ('vectors', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('then', 'ADV'), ('only', 'ADV'), ('we', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('train', 'VERB'), ('\\n\\n', 'SPACE'), ('the', 'DET'), ('model', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Because model you know, whenever we say any machine learning model internally we really need to train\n",
      "\n",
      "with some mathematical equations.\n",
      "POS tags: [('Because', 'SCONJ'), ('model', 'NOUN'), ('you', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('whenever', 'SCONJ'), ('we', 'PRON'), ('say', 'VERB'), ('any', 'DET'), ('machine', 'NOUN'), ('learning', 'NOUN'), ('model', 'NOUN'), ('internally', 'ADV'), ('we', 'PRON'), ('really', 'ADV'), ('need', 'VERB'), ('to', 'PART'), ('train', 'VERB'), ('\\n\\n', 'SPACE'), ('with', 'ADP'), ('some', 'DET'), ('mathematical', 'ADJ'), ('equations', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So whenever we train something with mathematical equations there, we really need to give the input\n",
      "\n",
      "data in the form of numerical or floating values.\n",
      "POS tags: [('So', 'ADV'), ('whenever', 'SCONJ'), ('we', 'PRON'), ('train', 'VERB'), ('something', 'PRON'), ('with', 'ADP'), ('mathematical', 'ADJ'), ('equations', 'NOUN'), ('there', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('really', 'ADV'), ('need', 'VERB'), ('to', 'PART'), ('give', 'VERB'), ('the', 'DET'), ('input', 'NOUN'), ('\\n\\n', 'SPACE'), ('data', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('numerical', 'ADJ'), ('or', 'CCONJ'), ('floating', 'VERB'), ('values', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So let us go ahead and let's us understand what exactly Stopwords is.\n",
      "POS tags: [('So', 'ADV'), ('let', 'VERB'), ('us', 'PRON'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('us', 'PRON'), ('understand', 'VERB'), ('what', 'PRON'), ('exactly', 'ADV'), ('Stopwords', 'PROPN'), ('is', 'AUX'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I have opened a new notebook file over here.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), ('have', 'AUX'), ('opened', 'VERB'), ('a', 'DET'), ('new', 'ADJ'), ('notebook', 'NOUN'), ('file', 'NOUN'), ('over', 'ADV'), ('here', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So here I have one amazing speech from doctor APJ Abdul Kalam.\n",
      "POS tags: [('So', 'ADV'), ('here', 'ADV'), ('I', 'PRON'), ('have', 'VERB'), ('one', 'NUM'), ('amazing', 'ADJ'), ('speech', 'NOUN'), ('from', 'ADP'), ('doctor', 'NOUN'), ('APJ', 'PROPN'), ('Abdul', 'PROPN'), ('Kalam', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: He was the former President of India and it was an amazing speech.\n",
      "POS tags: [('He', 'PRON'), ('was', 'AUX'), ('the', 'DET'), ('former', 'ADJ'), ('President', 'PROPN'), ('of', 'ADP'), ('India', 'PROPN'), ('and', 'CCONJ'), ('it', 'PRON'), ('was', 'AUX'), ('an', 'DET'), ('amazing', 'ADJ'), ('speech', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You can probably read out completely over here and obviously it is given in the materials.\n",
      "POS tags: [('You', 'PRON'), ('can', 'AUX'), ('probably', 'ADV'), ('read', 'VERB'), ('out', 'ADP'), ('completely', 'ADV'), ('over', 'ADV'), ('here', 'ADV'), ('and', 'CCONJ'), ('obviously', 'ADV'), ('it', 'PRON'), ('is', 'AUX'), ('given', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('materials', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, what I'm actually going to do is that I'm going to probably talk about Stopwords and why it is\n",
      "\n",
      "important that we should try to remove the stop words.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('probably', 'ADV'), ('talk', 'VERB'), ('about', 'ADP'), ('Stopwords', 'PROPN'), ('and', 'CCONJ'), ('why', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('\\n\\n', 'SPACE'), ('important', 'ADJ'), ('that', 'SCONJ'), ('we', 'PRON'), ('should', 'AUX'), ('try', 'VERB'), ('to', 'PART'), ('remove', 'VERB'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And, uh, just for a definition, what exactly stop words.\n",
      "POS tags: [('And', 'CCONJ'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('just', 'ADV'), ('for', 'ADP'), ('a', 'DET'), ('definition', 'NOUN'), (',', 'PUNCT'), ('what', 'PRON'), ('exactly', 'ADV'), ('stop', 'VERB'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, here in this particular speech, you can see that, uh, there are a lot of sentences like, I\n",
      "\n",
      "have three visions for India in 3000 years of our history, people from all over the world have come\n",
      "\n",
      "and invaded us.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('here', 'ADV'), ('in', 'ADP'), ('this', 'DET'), ('particular', 'ADJ'), ('speech', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('that', 'SCONJ'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('there', 'PRON'), ('are', 'VERB'), ('a', 'DET'), ('lot', 'NOUN'), ('of', 'ADP'), ('sentences', 'NOUN'), ('like', 'ADP'), (',', 'PUNCT'), ('I', 'PRON'), ('\\n\\n', 'SPACE'), ('have', 'VERB'), ('three', 'NUM'), ('visions', 'NOUN'), ('for', 'ADP'), ('India', 'PROPN'), ('in', 'ADP'), ('3000', 'NUM'), ('years', 'NOUN'), ('of', 'ADP'), ('our', 'PRON'), ('history', 'NOUN'), (',', 'PUNCT'), ('people', 'NOUN'), ('from', 'ADP'), ('all', 'ADV'), ('over', 'ADP'), ('the', 'DET'), ('world', 'NOUN'), ('have', 'AUX'), ('come', 'VERB'), ('\\n\\n', 'SPACE'), ('and', 'CCONJ'), ('invaded', 'VERB'), ('us', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So this is the entire speech.\n",
      "POS tags: [('So', 'ADV'), ('this', 'PRON'), ('is', 'AUX'), ('the', 'DET'), ('entire', 'ADJ'), ('speech', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: It is an amazing speech.\n",
      "POS tags: [('It', 'PRON'), ('is', 'AUX'), ('an', 'DET'), ('amazing', 'ADJ'), ('speech', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: If you are probably learning it, I would like to just, uh, tell you that.\n",
      "POS tags: [('If', 'SCONJ'), ('you', 'PRON'), ('are', 'AUX'), ('probably', 'ADV'), ('learning', 'VERB'), ('it', 'PRON'), (',', 'PUNCT'), ('I', 'PRON'), ('would', 'AUX'), ('like', 'VERB'), ('to', 'PART'), ('just', 'ADV'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('tell', 'VERB'), ('you', 'PRON'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Please read this.\n",
      "POS tags: [('Please', 'INTJ'), ('read', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You'll be getting a lot of information out of it.\n",
      "POS tags: [('You', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('getting', 'VERB'), ('a', 'DET'), ('lot', 'NOUN'), ('of', 'ADP'), ('information', 'NOUN'), ('out', 'ADP'), ('of', 'ADP'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Very motivational speech altogether.\n",
      "POS tags: [('Very', 'ADV'), ('motivational', 'ADJ'), ('speech', 'NOUN'), ('altogether', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, from this particular speech, you can see that.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('from', 'ADP'), ('this', 'DET'), ('particular', 'ADJ'), ('speech', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And I can definitely say this as paragraph or corpus right now here there are some words like I the\n",
      "\n",
      "have and, you know, uh, let's say off uh, the you know, two there y right.\n",
      "POS tags: [('And', 'CCONJ'), ('I', 'PRON'), ('can', 'AUX'), ('definitely', 'ADV'), ('say', 'VERB'), ('this', 'PRON'), ('as', 'ADP'), ('paragraph', 'NOUN'), ('or', 'CCONJ'), ('corpus', 'NOUN'), ('right', 'ADV'), ('now', 'ADV'), ('here', 'ADV'), ('there', 'PRON'), ('are', 'VERB'), ('some', 'DET'), ('words', 'NOUN'), ('like', 'SCONJ'), ('I', 'PRON'), ('the', 'DET'), ('\\n\\n', 'SPACE'), ('have', 'VERB'), ('and', 'CCONJ'), (',', 'PUNCT'), ('you', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('let', 'VERB'), (\"'s\", 'PRON'), ('say', 'VERB'), ('off', 'ADP'), ('uh', 'INTJ'), (',', 'PUNCT'), ('the', 'DET'), ('you', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('two', 'NUM'), ('there', 'ADV'), ('y', 'PROPN'), ('right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: All this kind of words, right?\n",
      "POS tags: [('All', 'DET'), ('this', 'DET'), ('kind', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), (',', 'PUNCT'), ('right', 'ADJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: It will not play a very big role when we are doing a task like spam classification.\n",
      "POS tags: [('It', 'PRON'), ('will', 'AUX'), ('not', 'PART'), ('play', 'VERB'), ('a', 'DET'), ('very', 'ADV'), ('big', 'ADJ'), ('role', 'NOUN'), ('when', 'SCONJ'), ('we', 'PRON'), ('are', 'AUX'), ('doing', 'VERB'), ('a', 'DET'), ('task', 'NOUN'), ('like', 'ADP'), ('spam', 'NOUN'), ('classification', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Or let's say if you are trying to do some kind of task with respect to, uh, you know, uh, like spam\n",
      "\n",
      "or ham classification, I have already told about that.\n",
      "POS tags: [('Or', 'CCONJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('say', 'VERB'), ('if', 'SCONJ'), ('you', 'PRON'), ('are', 'AUX'), ('trying', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('some', 'DET'), ('kind', 'NOUN'), ('of', 'ADP'), ('task', 'NOUN'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('you', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('like', 'ADP'), ('spam', 'NOUN'), ('\\n\\n', 'SPACE'), ('or', 'CCONJ'), ('ham', 'PROPN'), ('classification', 'NOUN'), (',', 'PUNCT'), ('I', 'PRON'), ('have', 'AUX'), ('already', 'ADV'), ('told', 'VERB'), ('about', 'ADP'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And uh, along with that, to just see that whether this is a positive review or negative review, but\n",
      "\n",
      "some of the words like not can actually play a very important role.\n",
      "POS tags: [('And', 'CCONJ'), ('uh', 'INTJ'), (',', 'PUNCT'), ('along', 'ADP'), ('with', 'ADP'), ('that', 'PRON'), (',', 'PUNCT'), ('to', 'PART'), ('just', 'ADV'), ('see', 'VERB'), ('that', 'SCONJ'), ('whether', 'SCONJ'), ('this', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('positive', 'ADJ'), ('review', 'NOUN'), ('or', 'CCONJ'), ('negative', 'ADJ'), ('review', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('\\n\\n', 'SPACE'), ('some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('words', 'NOUN'), ('like', 'INTJ'), ('not', 'PART'), ('can', 'AUX'), ('actually', 'ADV'), ('play', 'VERB'), ('a', 'DET'), ('very', 'ADV'), ('important', 'ADJ'), ('role', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Not and all.\n",
      "POS tags: [('Not', 'PART'), ('and', 'CCONJ'), ('all', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So what we do is that with the help of stop words, you know, we try to remove this particular words\n",
      "\n",
      "because, uh, with this kind of use cases where you are specifically focusing on some of the important\n",
      "\n",
      "words to determine the output, this is all words like I the he she off there is not at all required.\n",
      "POS tags: [('So', 'ADV'), ('what', 'PRON'), ('we', 'PRON'), ('do', 'AUX'), ('is', 'AUX'), ('that', 'SCONJ'), ('with', 'ADP'), ('the', 'DET'), ('help', 'NOUN'), ('of', 'ADP'), ('stop', 'VERB'), ('words', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('we', 'PRON'), ('try', 'VERB'), ('to', 'PART'), ('remove', 'VERB'), ('this', 'DET'), ('particular', 'ADJ'), ('words', 'NOUN'), ('\\n\\n', 'SPACE'), ('because', 'SCONJ'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('with', 'ADP'), ('this', 'DET'), ('kind', 'NOUN'), ('of', 'ADP'), ('use', 'NOUN'), ('cases', 'NOUN'), ('where', 'SCONJ'), ('you', 'PRON'), ('are', 'AUX'), ('specifically', 'ADV'), ('focusing', 'VERB'), ('on', 'ADP'), ('some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('important', 'ADJ'), ('\\n\\n', 'SPACE'), ('words', 'NOUN'), ('to', 'PART'), ('determine', 'VERB'), ('the', 'DET'), ('output', 'NOUN'), (',', 'PUNCT'), ('this', 'PRON'), ('is', 'AUX'), ('all', 'DET'), ('words', 'NOUN'), ('like', 'ADP'), ('I', 'PRON'), ('the', 'DET'), ('he', 'PRON'), ('she', 'PRON'), ('off', 'ADV'), ('there', 'ADV'), ('is', 'VERB'), ('not', 'PART'), ('at', 'ADV'), ('all', 'ADV'), ('required', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So what we can do is that we can basically pass this entire paragraph to that particular stop words\n",
      "\n",
      "and see that what all words can be basically removed, okay.\n",
      "POS tags: [('So', 'ADV'), ('what', 'PRON'), ('we', 'PRON'), ('can', 'AUX'), ('do', 'AUX'), ('is', 'AUX'), ('that', 'SCONJ'), ('we', 'PRON'), ('can', 'AUX'), ('basically', 'ADV'), ('pass', 'VERB'), ('this', 'DET'), ('entire', 'ADJ'), ('paragraph', 'NOUN'), ('to', 'ADP'), ('that', 'DET'), ('particular', 'ADJ'), ('stop', 'VERB'), ('words', 'NOUN'), ('\\n\\n', 'SPACE'), ('and', 'CCONJ'), ('see', 'VERB'), ('that', 'SCONJ'), ('what', 'PRON'), ('all', 'DET'), ('words', 'NOUN'), ('can', 'AUX'), ('be', 'AUX'), ('basically', 'ADV'), ('removed', 'VERB'), (',', 'PUNCT'), ('okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And that is the importance of stopwords in short.\n",
      "POS tags: [('And', 'CCONJ'), ('that', 'PRON'), ('is', 'AUX'), ('the', 'DET'), ('importance', 'NOUN'), ('of', 'ADP'), ('stopwords', 'NOUN'), ('in', 'ADP'), ('short', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So let us go ahead right now.\n",
      "POS tags: [('So', 'ADV'), ('let', 'VERB'), ('us', 'PRON'), ('go', 'VERB'), ('ahead', 'ADV'), ('right', 'ADV'), ('now', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'll just go ahead and execute it.\n",
      "POS tags: [('I', 'PRON'), (\"'ll\", 'AUX'), ('just', 'ADV'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('execute', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let me make some cells so that it will be very much easy for you all to understand and how we can apply\n",
      "\n",
      "Stopwords.\n",
      "POS tags: [('Let', 'VERB'), ('me', 'PRON'), ('make', 'VERB'), ('some', 'DET'), ('cells', 'NOUN'), ('so', 'SCONJ'), ('that', 'SCONJ'), ('it', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('very', 'ADV'), ('much', 'ADV'), ('easy', 'ADJ'), ('for', 'SCONJ'), ('you', 'PRON'), ('all', 'PRON'), ('to', 'PART'), ('understand', 'VERB'), ('and', 'CCONJ'), ('how', 'SCONJ'), ('we', 'PRON'), ('can', 'AUX'), ('apply', 'VERB'), ('\\n\\n', 'SPACE'), ('Stopwords', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Along with Stopwords, you can also apply stemming.\n",
      "POS tags: [('Along', 'ADP'), ('with', 'ADP'), ('Stopwords', 'PROPN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('also', 'ADV'), ('apply', 'VERB'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'll show you both the combination, uh, which will be super important for everyone.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('show', 'VERB'), ('you', 'PRON'), ('both', 'DET'), ('the', 'DET'), ('combination', 'NOUN'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('which', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('super', 'ADV'), ('important', 'ADJ'), ('for', 'ADP'), ('everyone', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So let's go ahead and let's uh, try to do that okay.\n",
      "POS tags: [('So', 'ADV'), ('let', 'VERB'), (\"'s\", 'PRON'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('uh', 'INTJ'), (',', 'PUNCT'), ('try', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('that', 'PRON'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now first of all, I really need to import, uh, for stemming.\n",
      "POS tags: [('Now', 'INTJ'), ('first', 'ADV'), ('of', 'ADP'), ('all', 'PRON'), (',', 'PUNCT'), ('I', 'PRON'), ('really', 'ADV'), ('need', 'VERB'), ('to', 'PART'), ('import', 'VERB'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('for', 'ADP'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You obviously know what we need to import.\n",
      "POS tags: [('You', 'PRON'), ('obviously', 'ADV'), ('know', 'VERB'), ('what', 'PRON'), ('we', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('import', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So from for stemming I'll write for NLTK dot stem import porter stemmer.\n",
      "POS tags: [('So', 'ADV'), ('from', 'ADP'), ('for', 'ADP'), ('stemming', 'VERB'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('write', 'VERB'), ('for', 'ADP'), ('NLTK', 'NOUN'), ('dot', 'NOUN'), ('stem', 'NOUN'), ('import', 'NOUN'), ('porter', 'NOUN'), ('stemmer', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I can basically write Porter stemmer over here and I'll execute it along with this.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), ('can', 'AUX'), ('basically', 'ADV'), ('write', 'VERB'), ('Porter', 'PROPN'), ('stemmer', 'NOUN'), ('over', 'ADP'), ('here', 'ADV'), ('and', 'CCONJ'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('execute', 'VERB'), ('it', 'PRON'), ('along', 'ADP'), ('with', 'ADP'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh, I obviously need to also import Stopwords because stopwords for English, it will be different\n",
      "\n",
      "because you'll be having that entire list of words like the he, she and.\n",
      "POS tags: [('Uh', 'INTJ'), (',', 'PUNCT'), ('I', 'PRON'), ('obviously', 'ADV'), ('need', 'VERB'), ('to', 'PART'), ('also', 'ADV'), ('import', 'VERB'), ('Stopwords', 'PROPN'), ('because', 'SCONJ'), ('stopwords', 'NOUN'), ('for', 'ADP'), ('English', 'PROPN'), (',', 'PUNCT'), ('it', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('different', 'ADJ'), ('\\n\\n', 'SPACE'), ('because', 'SCONJ'), ('you', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('having', 'VERB'), ('that', 'DET'), ('entire', 'ADJ'), ('list', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), ('like', 'ADP'), ('the', 'DET'), ('he', 'PRON'), (',', 'PUNCT'), ('she', 'PRON'), ('and', 'CCONJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: All right.\n",
      "POS tags: [('All', 'ADV'), ('right', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: so what I'm going to do is that I'm going to say that from an NLP k dot corpus import stopwords.\n",
      "POS tags: [('so', 'ADV'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('say', 'VERB'), ('that', 'SCONJ'), ('from', 'ADP'), ('an', 'DET'), ('NLP', 'PROPN'), ('k', 'NOUN'), ('dot', 'NOUN'), ('corpus', 'X'), ('import', 'NOUN'), ('stopwords', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So from this I will be able to use the stopwords itself.\n",
      "POS tags: [('So', 'ADV'), ('from', 'ADP'), ('this', 'PRON'), ('I', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('use', 'VERB'), ('the', 'DET'), ('stopwords', 'NOUN'), ('itself', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So now I have imported uh from an antique corpus import Stopwords.\n",
      "POS tags: [('So', 'ADV'), ('now', 'ADV'), ('I', 'PRON'), ('have', 'AUX'), ('imported', 'VERB'), ('uh', 'INTJ'), ('from', 'ADP'), ('an', 'DET'), ('antique', 'ADJ'), ('corpus', 'X'), ('import', 'NOUN'), ('Stopwords', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now this Stopwords, you know, I have to also download it.\n",
      "POS tags: [('Now', 'INTJ'), ('this', 'DET'), ('Stopwords', 'PROPN'), (',', 'PUNCT'), ('you', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('I', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('also', 'ADV'), ('download', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So for that, uh, let me do one thing.\n",
      "POS tags: [('So', 'ADV'), ('for', 'ADP'), ('that', 'PRON'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('let', 'VERB'), ('me', 'PRON'), ('do', 'VERB'), ('one', 'NUM'), ('thing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'll also import a NLTK and I will execute it.\n",
      "POS tags: [('I', 'PRON'), (\"'ll\", 'AUX'), ('also', 'ADV'), ('import', 'VERB'), ('a', 'DET'), ('NLTK', 'PROPN'), ('and', 'CCONJ'), ('I', 'PRON'), ('will', 'AUX'), ('execute', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And along with that, I'll write an LCC dot download.\n",
      "POS tags: [('And', 'CCONJ'), ('along', 'ADP'), ('with', 'ADP'), ('that', 'PRON'), (',', 'PUNCT'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('write', 'VERB'), ('an', 'DET'), ('LCC', 'PROPN'), ('dot', 'NOUN'), ('download', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here in the parameter I am going to give about the stopwords.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('in', 'ADP'), ('the', 'DET'), ('parameter', 'NOUN'), ('I', 'PRON'), ('am', 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('give', 'VERB'), ('about', 'ADP'), ('the', 'DET'), ('stopwords', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And there are different different language stopwords also.\n",
      "POS tags: [('And', 'CCONJ'), ('there', 'PRON'), ('are', 'VERB'), ('different', 'ADJ'), ('different', 'ADJ'), ('language', 'NOUN'), ('stopwords', 'NOUN'), ('also', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And we'll also try to see that.\n",
      "POS tags: [('And', 'CCONJ'), ('we', 'PRON'), (\"'ll\", 'AUX'), ('also', 'ADV'), ('try', 'VERB'), ('to', 'PART'), ('see', 'VERB'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So if I probably write this here, you'll be able to see that downloading package Stopwords to this\n",
      "\n",
      "particular location.\n",
      "POS tags: [('So', 'ADV'), ('if', 'SCONJ'), ('I', 'PRON'), ('probably', 'ADV'), ('write', 'VERB'), ('this', 'PRON'), ('here', 'ADV'), (',', 'PUNCT'), ('you', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('see', 'VERB'), ('that', 'PRON'), ('downloading', 'VERB'), ('package', 'NOUN'), ('Stopwords', 'PROPN'), ('to', 'ADP'), ('this', 'DET'), ('\\n\\n', 'SPACE'), ('particular', 'ADJ'), ('location', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So the package Stopwords is already up to date and I'm getting true.\n",
      "POS tags: [('So', 'ADV'), ('the', 'DET'), ('package', 'NOUN'), ('Stopwords', 'PROPN'), ('is', 'AUX'), ('already', 'ADV'), ('up', 'ADP'), ('to', 'ADP'), ('date', 'NOUN'), ('and', 'CCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('getting', 'VERB'), ('true', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So in short I've downloaded all the different different languages Stopwords which is already present\n",
      "\n",
      "in the NLTK library.\n",
      "POS tags: [('So', 'ADV'), ('in', 'ADP'), ('short', 'ADJ'), ('I', 'PRON'), (\"'ve\", 'AUX'), ('downloaded', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('different', 'ADJ'), ('different', 'ADJ'), ('languages', 'NOUN'), ('Stopwords', 'PROPN'), ('which', 'PRON'), ('is', 'AUX'), ('already', 'ADV'), ('present', 'ADJ'), ('\\n\\n', 'SPACE'), ('in', 'ADP'), ('the', 'DET'), ('NLTK', 'PROPN'), ('library', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now we have done that.\n",
      "POS tags: [('Now', 'ADV'), ('we', 'PRON'), ('have', 'AUX'), ('done', 'VERB'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now let's see that what are the Stopwords that are available in English?\n",
      "POS tags: [('Now', 'INTJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('see', 'VERB'), ('that', 'SCONJ'), ('what', 'PRON'), ('are', 'AUX'), ('the', 'DET'), ('Stopwords', 'PROPN'), ('that', 'PRON'), ('are', 'AUX'), ('available', 'ADJ'), ('in', 'ADP'), ('English', 'PROPN'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: So in order to do that I am.\n",
      "POS tags: [('So', 'ADV'), ('in', 'ADP'), ('order', 'NOUN'), ('to', 'PART'), ('do', 'AUX'), ('that', 'PRON'), ('I', 'PRON'), ('am', 'AUX'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I have already imported from NLTK corpus import stopwords.\n",
      "POS tags: [('I', 'PRON'), ('have', 'AUX'), ('already', 'ADV'), ('imported', 'VERB'), ('from', 'ADP'), ('NLTK', 'PROPN'), ('corpus', 'PROPN'), ('import', 'NOUN'), ('stopwords', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'll take the Stopwords.\n",
      "POS tags: [('I', 'PRON'), (\"'ll\", 'AUX'), ('take', 'VERB'), ('the', 'DET'), ('Stopwords', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'll copy and paste it over here and I will say dot download okay or instead of download I will just\n",
      "\n",
      "write dot words.\n",
      "POS tags: [('I', 'PRON'), (\"'ll\", 'AUX'), ('copy', 'VERB'), ('and', 'CCONJ'), ('paste', 'VERB'), ('it', 'PRON'), ('over', 'ADP'), ('here', 'ADV'), ('and', 'CCONJ'), ('I', 'PRON'), ('will', 'AUX'), ('say', 'VERB'), ('dot', 'NOUN'), ('download', 'NOUN'), ('okay', 'INTJ'), ('or', 'CCONJ'), ('instead', 'ADV'), ('of', 'ADP'), ('download', 'NOUN'), ('I', 'PRON'), ('will', 'AUX'), ('just', 'ADV'), ('\\n\\n', 'SPACE'), ('write', 'VERB'), ('dot', 'NOUN'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here I just need to give my language.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('I', 'PRON'), ('just', 'ADV'), ('need', 'VERB'), ('to', 'PART'), ('give', 'VERB'), ('my', 'PRON'), ('language', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Like what language?\n",
      "POS tags: [('Like', 'ADP'), ('what', 'PRON'), ('language', 'NOUN'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: I really want to, uh, give it for like English or something else, like German and all.\n",
      "POS tags: [('I', 'PRON'), ('really', 'ADV'), ('want', 'VERB'), ('to', 'PART'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('give', 'VERB'), ('it', 'PRON'), ('for', 'ADP'), ('like', 'ADP'), ('English', 'PROPN'), ('or', 'CCONJ'), ('something', 'PRON'), ('else', 'ADV'), (',', 'PUNCT'), ('like', 'ADP'), ('German', 'PROPN'), ('and', 'CCONJ'), ('all', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'm just going to write this.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('write', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let me just write English.\n",
      "POS tags: [('Let', 'VERB'), ('me', 'PRON'), ('just', 'ADV'), ('write', 'VERB'), ('English', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And if I execute this here, now you can see the list of all the stop words that you obviously have,\n",
      "\n",
      "and all the stop words can actually be removed.\n",
      "POS tags: [('And', 'CCONJ'), ('if', 'SCONJ'), ('I', 'PRON'), ('execute', 'VERB'), ('this', 'PRON'), ('here', 'ADV'), (',', 'PUNCT'), ('now', 'ADV'), ('you', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('the', 'DET'), ('list', 'NOUN'), ('of', 'ADP'), ('all', 'DET'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('that', 'PRON'), ('you', 'PRON'), ('obviously', 'ADV'), ('have', 'VERB'), (',', 'PUNCT'), ('\\n\\n', 'SPACE'), ('and', 'CCONJ'), ('all', 'DET'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('can', 'AUX'), ('actually', 'ADV'), ('be', 'AUX'), ('removed', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right now.\n",
      "POS tags: [('Right', 'ADV'), ('now', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You may be thinking, Krish, this may depend on data to data.\n",
      "POS tags: [('You', 'PRON'), ('may', 'AUX'), ('be', 'AUX'), ('thinking', 'VERB'), (',', 'PUNCT'), ('Krish', 'PROPN'), (',', 'PUNCT'), ('this', 'PRON'), ('may', 'AUX'), ('depend', 'VERB'), ('on', 'ADP'), ('data', 'NOUN'), ('to', 'ADP'), ('data', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right now here you can see that guys, this is a list.\n",
      "POS tags: [('Right', 'ADV'), ('now', 'ADV'), ('here', 'ADV'), ('you', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('that', 'SCONJ'), ('guys', 'NOUN'), (',', 'PUNCT'), ('this', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('list', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You can also create your own stopwords in English like let's say over here.\n",
      "POS tags: [('You', 'PRON'), ('can', 'AUX'), ('also', 'ADV'), ('create', 'VERB'), ('your', 'PRON'), ('own', 'ADJ'), ('stopwords', 'NOUN'), ('in', 'ADP'), ('English', 'PROPN'), ('like', 'INTJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('say', 'VERB'), ('over', 'ADV'), ('here', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Some of the important words are like are and couldn't.\n",
      "POS tags: [('Some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('important', 'ADJ'), ('words', 'NOUN'), ('are', 'AUX'), ('like', 'ADP'), ('are', 'AUX'), ('and', 'CCONJ'), ('could', 'AUX'), (\"n't\", 'PART'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: These are words can actually play a very important role.\n",
      "POS tags: [('These', 'PRON'), ('are', 'AUX'), ('words', 'NOUN'), ('can', 'AUX'), ('actually', 'ADV'), ('play', 'VERB'), ('a', 'DET'), ('very', 'ADV'), ('important', 'ADJ'), ('role', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh, to find out whether a statement is positive or negative, like not is also there.\n",
      "POS tags: [('Uh', 'INTJ'), (',', 'PUNCT'), ('to', 'PART'), ('find', 'VERB'), ('out', 'ADP'), ('whether', 'SCONJ'), ('a', 'DET'), ('statement', 'NOUN'), ('is', 'AUX'), ('positive', 'ADJ'), ('or', 'CCONJ'), ('negative', 'ADJ'), (',', 'PUNCT'), ('like', 'INTJ'), ('not', 'PART'), ('is', 'AUX'), ('also', 'ADV'), ('there', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: If you probably search for it not, you will also be able to find it not.\n",
      "POS tags: [('If', 'SCONJ'), ('you', 'PRON'), ('probably', 'ADV'), ('search', 'VERB'), ('for', 'ADP'), ('it', 'PRON'), ('not', 'PART'), (',', 'PUNCT'), ('you', 'PRON'), ('will', 'AUX'), ('also', 'ADV'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('find', 'VERB'), ('it', 'PRON'), ('not', 'PART'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So it is always a good way that you create your own stopwords and try to remove all those kind of words\n",
      "\n",
      "from the paragraph.\n",
      "POS tags: [('So', 'ADV'), ('it', 'PRON'), ('is', 'AUX'), ('always', 'ADV'), ('a', 'DET'), ('good', 'ADJ'), ('way', 'NOUN'), ('that', 'PRON'), ('you', 'PRON'), ('create', 'VERB'), ('your', 'PRON'), ('own', 'ADJ'), ('stopwords', 'NOUN'), ('and', 'CCONJ'), ('try', 'VERB'), ('to', 'PART'), ('remove', 'VERB'), ('all', 'DET'), ('those', 'DET'), ('kind', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), ('\\n\\n', 'SPACE'), ('from', 'ADP'), ('the', 'DET'), ('paragraph', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I hope everybody is able to understand now with respect to English, you have this.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), ('hope', 'VERB'), ('everybody', 'PRON'), ('is', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('understand', 'VERB'), ('now', 'ADV'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('English', 'PROPN'), (',', 'PUNCT'), ('you', 'PRON'), ('have', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now let's see whether we have with respect to different different language.\n",
      "POS tags: [('Now', 'INTJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('see', 'VERB'), ('whether', 'SCONJ'), ('we', 'PRON'), ('have', 'VERB'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('different', 'ADJ'), ('different', 'ADJ'), ('language', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And obviously you can go ahead and check the documentation, but I will just try to show you with respect\n",
      "\n",
      "to German.\n",
      "POS tags: [('And', 'CCONJ'), ('obviously', 'ADV'), ('you', 'PRON'), ('can', 'AUX'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('check', 'VERB'), ('the', 'DET'), ('documentation', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('I', 'PRON'), ('will', 'AUX'), ('just', 'ADV'), ('try', 'VERB'), ('to', 'PART'), ('show', 'VERB'), ('you', 'PRON'), ('with', 'ADP'), ('respect', 'NOUN'), ('\\n\\n', 'SPACE'), ('to', 'ADP'), ('German', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So in German also you have this specific stop words.\n",
      "POS tags: [('So', 'ADV'), ('in', 'ADP'), ('German', 'PROPN'), ('also', 'ADV'), ('you', 'PRON'), ('have', 'VERB'), ('this', 'DET'), ('specific', 'ADJ'), ('stop', 'NOUN'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Along with this you can also use French.\n",
      "POS tags: [('Along', 'ADP'), ('with', 'ADP'), ('this', 'PRON'), ('you', 'PRON'), ('can', 'AUX'), ('also', 'ADV'), ('use', 'VERB'), ('French', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You have this particular stop words.\n",
      "POS tags: [('You', 'PRON'), ('have', 'VERB'), ('this', 'DET'), ('particular', 'ADJ'), ('stop', 'VERB'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So with respect to different different texts or different different language of text, you can definitely\n",
      "\n",
      "apply different different stopwords with respect to that.\n",
      "POS tags: [('So', 'ADV'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('different', 'ADJ'), ('different', 'ADJ'), ('texts', 'NOUN'), ('or', 'CCONJ'), ('different', 'ADJ'), ('different', 'ADJ'), ('language', 'NOUN'), ('of', 'ADP'), ('text', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('definitely', 'ADV'), ('\\n\\n', 'SPACE'), ('apply', 'VERB'), ('different', 'ADJ'), ('different', 'ADJ'), ('stopwords', 'NOUN'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now you may be thinking, is there Hindi or Arabic or some other?\n",
      "POS tags: [('Now', 'ADV'), ('you', 'PRON'), ('may', 'AUX'), ('be', 'AUX'), ('thinking', 'VERB'), (',', 'PUNCT'), ('is', 'AUX'), ('there', 'PRON'), ('Hindi', 'PROPN'), ('or', 'CCONJ'), ('Arabic', 'PROPN'), ('or', 'CCONJ'), ('some', 'DET'), ('other', 'ADJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: I think for Arabic also, I think it is there.\n",
      "POS tags: [('I', 'PRON'), ('think', 'VERB'), ('for', 'ADP'), ('Arabic', 'PROPN'), ('also', 'ADV'), (',', 'PUNCT'), ('I', 'PRON'), ('think', 'VERB'), ('it', 'PRON'), ('is', 'AUX'), ('there', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let's see whether it is there or not.\n",
      "POS tags: [('Let', 'VERB'), (\"'s\", 'PRON'), ('see', 'VERB'), ('whether', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('there', 'ADV'), ('or', 'CCONJ'), ('not', 'PART'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Yes, for Arabic also it is there, but I do not find it for Hindi I guess.\n",
      "POS tags: [('Yes', 'INTJ'), (',', 'PUNCT'), ('for', 'ADP'), ('Arabic', 'PROPN'), ('also', 'ADV'), ('it', 'PRON'), ('is', 'AUX'), ('there', 'ADV'), (',', 'PUNCT'), ('but', 'CCONJ'), ('I', 'PRON'), ('do', 'AUX'), ('not', 'PART'), ('find', 'VERB'), ('it', 'PRON'), ('for', 'ADP'), ('Hindi', 'PROPN'), ('I', 'PRON'), ('guess', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So again from the documentation you can check it out.\n",
      "POS tags: [('So', 'ADV'), ('again', 'ADV'), ('from', 'ADP'), ('the', 'DET'), ('documentation', 'NOUN'), ('you', 'PRON'), ('can', 'AUX'), ('check', 'VERB'), ('it', 'PRON'), ('out', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But till Arabic I was able to see it again.\n",
      "POS tags: [('But', 'CCONJ'), ('till', 'SCONJ'), ('Arabic', 'PROPN'), ('I', 'PRON'), ('was', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('see', 'VERB'), ('it', 'PRON'), ('again', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: All the information will be given in the documentation.\n",
      "POS tags: [('All', 'DET'), ('the', 'DET'), ('information', 'NOUN'), ('will', 'AUX'), ('be', 'AUX'), ('given', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('documentation', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now what I'm actually going to do is that my sentence is already English.\n",
      "POS tags: [('Now', 'INTJ'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('my', 'PRON'), ('sentence', 'NOUN'), ('is', 'AUX'), ('already', 'ADV'), ('English', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right now I'm going to perform two important tasks.\n",
      "POS tags: [('Right', 'ADV'), ('now', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('perform', 'VERB'), ('two', 'NUM'), ('important', 'ADJ'), ('tasks', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: One is I will apply stemming.\n",
      "POS tags: [('One', 'NUM'), ('is', 'AUX'), ('I', 'PRON'), ('will', 'AUX'), ('apply', 'VERB'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And before applying stemming, you know what I'm actually going to do wherever I find out the stop words,\n",
      "\n",
      "I'm just going to remove the stop words from this particular paragraph so that this entire paragraph\n",
      "\n",
      "will be shortened up.\n",
      "POS tags: [('And', 'CCONJ'), ('before', 'ADP'), ('applying', 'VERB'), ('stemming', 'NOUN'), (',', 'PUNCT'), ('you', 'PRON'), ('know', 'VERB'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('wherever', 'SCONJ'), ('I', 'PRON'), ('find', 'VERB'), ('out', 'ADP'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), (',', 'PUNCT'), ('\\n\\n', 'SPACE'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('remove', 'VERB'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('from', 'ADP'), ('this', 'DET'), ('particular', 'ADJ'), ('paragraph', 'NOUN'), ('so', 'SCONJ'), ('that', 'SCONJ'), ('this', 'DET'), ('entire', 'ADJ'), ('paragraph', 'NOUN'), ('\\n\\n', 'SPACE'), ('will', 'AUX'), ('be', 'AUX'), ('shortened', 'VERB'), ('up', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So for that, what I'm actually going to do.\n",
      "POS tags: [('So', 'ADV'), ('for', 'ADP'), ('that', 'PRON'), (',', 'PUNCT'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, see, whatever things you have learned from starting everything, I'm actually going to cover\n",
      "\n",
      "up.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('see', 'VERB'), (',', 'PUNCT'), ('whatever', 'DET'), ('things', 'NOUN'), ('you', 'PRON'), ('have', 'AUX'), ('learned', 'VERB'), ('from', 'ADP'), ('starting', 'VERB'), ('everything', 'PRON'), (',', 'PUNCT'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('cover', 'VERB'), ('\\n\\n', 'SPACE'), ('up', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So first thing first I'm just going to say from NLTK dot stem I'm going to import porter stemmer.\n",
      "POS tags: [('So', 'ADV'), ('first', 'ADJ'), ('thing', 'NOUN'), ('first', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('say', 'VERB'), ('from', 'ADP'), ('NLTK', 'PROPN'), ('dot', 'NOUN'), ('stem', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('import', 'VERB'), ('porter', 'NOUN'), ('stemmer', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Porter stemmer.\n",
      "POS tags: [('Porter', 'NOUN'), ('stemmer', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And I'll go to just execute I'm just going to execute this okay.\n",
      "POS tags: [('And', 'CCONJ'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('go', 'VERB'), ('to', 'PART'), ('just', 'ADV'), ('execute', 'VERB'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('execute', 'VERB'), ('this', 'PRON'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And then what I'm actually going to do is that I'm just going to write Stemmer is equal to Porter stemmer\n",
      "\n",
      "this.\n",
      "POS tags: [('And', 'CCONJ'), ('then', 'ADV'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('write', 'VERB'), ('Stemmer', 'PROPN'), ('is', 'AUX'), ('equal', 'ADJ'), ('to', 'ADP'), ('Porter', 'PROPN'), ('stemmer', 'NOUN'), ('\\n\\n', 'SPACE'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We really need to initialize it.\n",
      "POS tags: [('We', 'PRON'), ('really', 'ADV'), ('need', 'VERB'), ('to', 'PART'), ('initialize', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now when we do this task right now, the next step, what I'm actually going to do is that I'm going\n",
      "\n",
      "to perform the tokenization on the entire paragraph.\n",
      "POS tags: [('Now', 'INTJ'), ('when', 'SCONJ'), ('we', 'PRON'), ('do', 'VERB'), ('this', 'DET'), ('task', 'NOUN'), ('right', 'ADV'), ('now', 'ADV'), (',', 'PUNCT'), ('the', 'DET'), ('next', 'ADJ'), ('step', 'NOUN'), (',', 'PUNCT'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('\\n\\n', 'SPACE'), ('to', 'PART'), ('perform', 'VERB'), ('the', 'DET'), ('tokenization', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('entire', 'ADJ'), ('paragraph', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So for that I can use NLTK, dot, send, tokenize.\n",
      "POS tags: [('So', 'ADV'), ('for', 'ADP'), ('that', 'PRON'), ('I', 'PRON'), ('can', 'AUX'), ('use', 'VERB'), ('NLTK', 'PROPN'), (',', 'PUNCT'), ('dot', 'NOUN'), (',', 'PUNCT'), ('send', 'NOUN'), (',', 'PUNCT'), ('tokenize', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here I'm just going to give my paragraph.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('give', 'VERB'), ('my', 'PRON'), ('paragraph', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now see this guys here I'm going to get my entire paragraph, entire sentences like see I have three\n",
      "\n",
      "visions for India.\n",
      "POS tags: [('Now', 'ADV'), ('see', 'VERB'), ('this', 'DET'), ('guys', 'NOUN'), ('here', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('get', 'VERB'), ('my', 'PRON'), ('entire', 'ADJ'), ('paragraph', 'NOUN'), (',', 'PUNCT'), ('entire', 'ADJ'), ('sentences', 'NOUN'), ('like', 'ADP'), ('see', 'INTJ'), ('I', 'PRON'), ('have', 'VERB'), ('three', 'NUM'), ('\\n\\n', 'SPACE'), ('visions', 'NOUN'), ('for', 'ADP'), ('India', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Then in 3000 years this all things I am able to get.\n",
      "POS tags: [('Then', 'ADV'), ('in', 'ADP'), ('3000', 'NUM'), ('years', 'NOUN'), ('this', 'PRON'), ('all', 'DET'), ('things', 'NOUN'), ('I', 'PRON'), ('am', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('get', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And this is my second sentence.\n",
      "POS tags: [('And', 'CCONJ'), ('this', 'PRON'), ('is', 'AUX'), ('my', 'PRON'), ('second', 'ADJ'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Third sentence.\n",
      "POS tags: [('Third', 'ADJ'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Fourth sentence.\n",
      "POS tags: [('Fourth', 'ADJ'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Like this.\n",
      "POS tags: [('Like', 'ADP'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: All the sentences in the form of list I'm able to get just by using cent underscore tokenize.\n",
      "POS tags: [('All', 'DET'), ('the', 'DET'), ('sentences', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('list', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('get', 'VERB'), ('just', 'ADV'), ('by', 'ADP'), ('using', 'VERB'), ('cent', 'NOUN'), ('underscore', 'NOUN'), ('tokenize', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: This is a tokenization process wherein we take a paragraph, divide that into sentences.\n",
      "POS tags: [('This', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('tokenization', 'NOUN'), ('process', 'NOUN'), ('wherein', 'SCONJ'), ('we', 'PRON'), ('take', 'VERB'), ('a', 'DET'), ('paragraph', 'NOUN'), (',', 'PUNCT'), ('divide', 'VERB'), ('that', 'SCONJ'), ('into', 'ADP'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay, now let me do one thing, is that I'm just going to save this in a variable which is called as\n",
      "\n",
      "sentences, which will let later become a list.\n",
      "POS tags: [('Okay', 'INTJ'), (',', 'PUNCT'), ('now', 'ADV'), ('let', 'VERB'), ('me', 'PRON'), ('do', 'VERB'), ('one', 'NUM'), ('thing', 'NOUN'), (',', 'PUNCT'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('save', 'VERB'), ('this', 'PRON'), ('in', 'ADP'), ('a', 'DET'), ('variable', 'NOUN'), ('which', 'PRON'), ('is', 'AUX'), ('called', 'VERB'), ('as', 'ADP'), ('\\n\\n', 'SPACE'), ('sentences', 'NOUN'), (',', 'PUNCT'), ('which', 'PRON'), ('will', 'AUX'), ('let', 'VERB'), ('later', 'ADV'), ('become', 'VERB'), ('a', 'DET'), ('list', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So this is my sentences.\n",
      "POS tags: [('So', 'ADV'), ('this', 'PRON'), ('is', 'AUX'), ('my', 'PRON'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And if you probably see the type of sentences I'm just going to basically see this.\n",
      "POS tags: [('And', 'CCONJ'), ('if', 'SCONJ'), ('you', 'PRON'), ('probably', 'ADV'), ('see', 'VERB'), ('the', 'DET'), ('type', 'NOUN'), ('of', 'ADP'), ('sentences', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('basically', 'ADV'), ('see', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: It is a list now.\n",
      "POS tags: [('It', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('list', 'NOUN'), ('now', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect till here.\n",
      "POS tags: [('Perfect', 'ADJ'), ('till', 'SCONJ'), ('here', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We have done it amazingly well right.\n",
      "POS tags: [('We', 'PRON'), ('have', 'AUX'), ('done', 'VERB'), ('it', 'PRON'), ('amazingly', 'ADV'), ('well', 'ADV'), ('right', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We have done Porter Stemmer on that.\n",
      "POS tags: [('We', 'PRON'), ('have', 'AUX'), ('done', 'VERB'), ('Porter', 'PROPN'), ('Stemmer', 'PROPN'), ('on', 'ADP'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Sorry.\n",
      "POS tags: [('Sorry', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We have initialized stemmer over here and we have tokenized it.\n",
      "POS tags: [('We', 'PRON'), ('have', 'AUX'), ('initialized', 'VERB'), ('stemmer', 'NOUN'), ('over', 'ADP'), ('here', 'ADV'), ('and', 'CCONJ'), ('we', 'PRON'), ('have', 'AUX'), ('tokenized', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now understand, what we are going to do is that I'm going to traverse through all the sentences.\n",
      "POS tags: [('Now', 'ADV'), ('understand', 'VERB'), (',', 'PUNCT'), ('what', 'PRON'), ('we', 'PRON'), ('are', 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('traverse', 'VERB'), ('through', 'ADP'), ('all', 'DET'), ('the', 'DET'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: First of all, apply a stopwords which all words are not present in the stopwords we are only going\n",
      "\n",
      "to take that and apply stemming.\n",
      "POS tags: [('First', 'ADV'), ('of', 'ADP'), ('all', 'PRON'), (',', 'PUNCT'), ('apply', 'VERB'), ('a', 'DET'), ('stopwords', 'NOUN'), ('which', 'PRON'), ('all', 'DET'), ('words', 'NOUN'), ('are', 'AUX'), ('not', 'PART'), ('present', 'ADJ'), ('in', 'ADP'), ('the', 'DET'), ('stopwords', 'NOUN'), ('we', 'PRON'), ('are', 'AUX'), ('only', 'ADV'), ('going', 'VERB'), ('\\n\\n', 'SPACE'), ('to', 'PART'), ('take', 'VERB'), ('that', 'PRON'), ('and', 'CCONJ'), ('apply', 'VERB'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: This is what we really want to do.\n",
      "POS tags: [('This', 'PRON'), ('is', 'AUX'), ('what', 'PRON'), ('we', 'PRON'), ('really', 'ADV'), ('want', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So here I'm saying that first of all apply stopwords and filter and then apply tokenization.\n",
      "POS tags: [('So', 'ADV'), ('here', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('saying', 'VERB'), ('that', 'SCONJ'), ('first', 'ADV'), ('of', 'ADP'), ('all', 'PRON'), ('apply', 'VERB'), ('stopwords', 'NOUN'), ('and', 'CCONJ'), ('filter', 'NOUN'), ('and', 'CCONJ'), ('then', 'ADV'), ('apply', 'VERB'), ('tokenization', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right?\n",
      "POS tags: [('Right', 'INTJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: Sorry.\n",
      "POS tags: [('Sorry', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Then apply stemming.\n",
      "POS tags: [('Then', 'ADV'), ('apply', 'VERB'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So this is the step that I'm actually going to do.\n",
      "POS tags: [('So', 'ADV'), ('this', 'PRON'), ('is', 'AUX'), ('the', 'DET'), ('step', 'NOUN'), ('that', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now see this very simple very important.\n",
      "POS tags: [('Now', 'ADV'), ('see', 'VERB'), ('this', 'DET'), ('very', 'ADV'), ('simple', 'ADJ'), ('very', 'ADV'), ('important', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'll write a for loop saying that for I in range for I in range.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('write', 'VERB'), ('a', 'PRON'), ('for', 'ADP'), ('loop', 'NOUN'), ('saying', 'VERB'), ('that', 'SCONJ'), ('for', 'SCONJ'), ('I', 'PRON'), ('in', 'ADP'), ('range', 'NOUN'), ('for', 'ADP'), ('I', 'PRON'), ('in', 'ADP'), ('range', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here I'm going to basically give the length of the sentences.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('basically', 'ADV'), ('give', 'VERB'), ('the', 'DET'), ('length', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I can also go with respect to sentences.\n",
      "POS tags: [('I', 'PRON'), ('can', 'AUX'), ('also', 'ADV'), ('go', 'VERB'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But there I'll not be getting the indexes here.\n",
      "POS tags: [('But', 'CCONJ'), ('there', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('not', 'PART'), ('be', 'AUX'), ('getting', 'VERB'), ('the', 'DET'), ('indexes', 'NOUN'), ('here', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'll be getting the indices.\n",
      "POS tags: [('I', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('getting', 'VERB'), ('the', 'DET'), ('indices', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay, so range basically says that whatever length I'm actually giving that becomes an index, right?\n",
      "POS tags: [('Okay', 'INTJ'), (',', 'PUNCT'), ('so', 'ADV'), ('range', 'NOUN'), ('basically', 'ADV'), ('says', 'VERB'), ('that', 'SCONJ'), ('whatever', 'DET'), ('length', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('giving', 'VERB'), ('that', 'PRON'), ('becomes', 'VERB'), ('an', 'DET'), ('index', 'NOUN'), (',', 'PUNCT'), ('right', 'ADJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: Zero to that specific length.\n",
      "POS tags: [('Zero', 'NUM'), ('to', 'ADP'), ('that', 'DET'), ('specific', 'ADJ'), ('length', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now what I'm actually going to take, I'm going to take this specific n um, I and I'm going to write\n",
      "\n",
      "n nltk dot word tokenize because I'm getting in the form of sentences, I need to get each and every\n",
      "\n",
      "word right.\n",
      "POS tags: [('Now', 'INTJ'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('take', 'VERB'), (',', 'PUNCT'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('take', 'VERB'), ('this', 'DET'), ('specific', 'ADJ'), ('n', 'X'), ('um', 'INTJ'), (',', 'PUNCT'), ('I', 'PRON'), ('and', 'CCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('write', 'VERB'), ('\\n\\n', 'SPACE'), ('n', 'ADP'), ('nltk', 'PROPN'), ('dot', 'NOUN'), ('word', 'NOUN'), ('tokenize', 'VERB'), ('because', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('getting', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('form', 'NOUN'), ('of', 'ADP'), ('sentences', 'NOUN'), (',', 'PUNCT'), ('I', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('get', 'VERB'), ('each', 'DET'), ('and', 'CCONJ'), ('every', 'PRON'), ('\\n\\n', 'SPACE'), ('word', 'NOUN'), ('right', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'm getting the word over here and inside word underscore tokenize I'll give I sorry sentence of\n",
      "\n",
      "I because this will be an index sentences of I.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('getting', 'VERB'), ('the', 'DET'), ('word', 'NOUN'), ('over', 'ADP'), ('here', 'ADV'), ('and', 'CCONJ'), ('inside', 'ADP'), ('word', 'NOUN'), ('underscore', 'NOUN'), ('tokenize', 'NOUN'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('give', 'VERB'), ('I', 'PRON'), ('sorry', 'ADJ'), ('sentence', 'NOUN'), ('of', 'ADP'), ('\\n\\n', 'SPACE'), ('I', 'PRON'), ('because', 'SCONJ'), ('this', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('an', 'DET'), ('index', 'NOUN'), ('sentences', 'NOUN'), ('of', 'ADP'), ('I.', 'PROPN')]\n",
      "\n",
      "Original sentence: So this will be an index.\n",
      "POS tags: [('So', 'ADV'), ('this', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('an', 'DET'), ('index', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here I'll be able to get the word.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('get', 'VERB'), ('the', 'DET'), ('word', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So here what I'll do I'll make a list of words.\n",
      "POS tags: [('So', 'ADV'), ('here', 'ADV'), ('what', 'PRON'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('do', 'VERB'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('make', 'VERB'), ('a', 'DET'), ('list', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So in short I'll be getting the list of words inside the sentences.\n",
      "POS tags: [('So', 'ADV'), ('in', 'ADP'), ('short', 'ADJ'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('getting', 'VERB'), ('the', 'DET'), ('list', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), ('inside', 'ADP'), ('the', 'DET'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now till here we have done it.\n",
      "POS tags: [('Now', 'ADV'), ('till', 'SCONJ'), ('here', 'ADV'), ('we', 'PRON'), ('have', 'AUX'), ('done', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now after this we are going to apply one very important thing that is.\n",
      "POS tags: [('Now', 'ADV'), ('after', 'ADP'), ('this', 'PRON'), ('we', 'PRON'), ('are', 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('apply', 'VERB'), ('one', 'NUM'), ('very', 'ADV'), ('important', 'ADJ'), ('thing', 'NOUN'), ('that', 'PRON'), ('is', 'AUX'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: First of all, I need to apply stop words for each and every word and see whether it falls in the stop\n",
      "\n",
      "word or not.\n",
      "POS tags: [('First', 'ADV'), ('of', 'ADP'), ('all', 'PRON'), (',', 'PUNCT'), ('I', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('apply', 'VERB'), ('stop', 'VERB'), ('words', 'NOUN'), ('for', 'ADP'), ('each', 'PRON'), ('and', 'CCONJ'), ('every', 'DET'), ('word', 'NOUN'), ('and', 'CCONJ'), ('see', 'VERB'), ('whether', 'SCONJ'), ('it', 'PRON'), ('falls', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('stop', 'NOUN'), ('\\n\\n', 'SPACE'), ('word', 'NOUN'), ('or', 'CCONJ'), ('not', 'PART'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: If it does not fall in the stop word, then only I have to do the stemming.\n",
      "POS tags: [('If', 'SCONJ'), ('it', 'PRON'), ('does', 'AUX'), ('not', 'PART'), ('fall', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('stop', 'NOUN'), ('word', 'NOUN'), (',', 'PUNCT'), ('then', 'ADV'), ('only', 'ADV'), ('I', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('the', 'DET'), ('stemming', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So understand the task step by step.\n",
      "POS tags: [('So', 'ADV'), ('understand', 'VERB'), ('the', 'DET'), ('task', 'NOUN'), ('step', 'NOUN'), ('by', 'ADP'), ('step', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: This is super important with respect to all the steps that I'm actually taking up.\n",
      "POS tags: [('This', 'PRON'), ('is', 'AUX'), ('super', 'ADV'), ('important', 'ADJ'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('all', 'DET'), ('the', 'DET'), ('steps', 'NOUN'), ('that', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('taking', 'VERB'), ('up', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay, so here I will write a list comprehension.\n",
      "POS tags: [('Okay', 'INTJ'), (',', 'PUNCT'), ('so', 'CCONJ'), ('here', 'ADV'), ('I', 'PRON'), ('will', 'AUX'), ('write', 'VERB'), ('a', 'DET'), ('list', 'NOUN'), ('comprehension', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I will say stemmer dot stem okay.\n",
      "POS tags: [('I', 'PRON'), ('will', 'AUX'), ('say', 'VERB'), ('stemmer', 'NOUN'), ('dot', 'NOUN'), ('stem', 'NOUN'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here I'm going to write dot word okay of the word because uh from this particular words, this word\n",
      "\n",
      "is a list of words.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('write', 'VERB'), ('dot', 'NOUN'), ('word', 'NOUN'), ('okay', 'INTJ'), ('of', 'ADP'), ('the', 'DET'), ('word', 'NOUN'), ('because', 'SCONJ'), ('uh', 'INTJ'), ('from', 'ADP'), ('this', 'DET'), ('particular', 'ADJ'), ('words', 'NOUN'), (',', 'PUNCT'), ('this', 'DET'), ('word', 'NOUN'), ('\\n\\n', 'SPACE'), ('is', 'AUX'), ('a', 'DET'), ('list', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And I have to take each and every word.\n",
      "POS tags: [('And', 'CCONJ'), ('I', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('take', 'VERB'), ('each', 'PRON'), ('and', 'CCONJ'), ('every', 'DET'), ('word', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So here I will write a for loop okay.\n",
      "POS tags: [('So', 'ADV'), ('here', 'ADV'), ('I', 'PRON'), ('will', 'AUX'), ('write', 'VERB'), ('a', 'PRON'), ('for', 'ADP'), ('loop', 'NOUN'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And this is called as list comprehension.\n",
      "POS tags: [('And', 'CCONJ'), ('this', 'PRON'), ('is', 'AUX'), ('called', 'VERB'), ('as', 'ADP'), ('list', 'NOUN'), ('comprehension', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'll write for word in words if word not in see if the word is not present in the stop words then\n",
      "\n",
      "only you apply stemming.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('write', 'VERB'), ('for', 'ADP'), ('word', 'NOUN'), ('in', 'ADP'), ('words', 'NOUN'), ('if', 'SCONJ'), ('word', 'NOUN'), ('not', 'PART'), ('in', 'ADP'), ('see', 'NOUN'), ('if', 'SCONJ'), ('the', 'DET'), ('word', 'NOUN'), ('is', 'AUX'), ('not', 'PART'), ('present', 'ADJ'), ('in', 'ADP'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('then', 'ADV'), ('\\n\\n', 'SPACE'), ('only', 'ADV'), ('you', 'PRON'), ('apply', 'VERB'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: That is what I'm actually trying to do.\n",
      "POS tags: [('That', 'PRON'), ('is', 'AUX'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('trying', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay, so here you can basically see if the word is not in.\n",
      "POS tags: [('Okay', 'INTJ'), (',', 'PUNCT'), ('so', 'CCONJ'), ('here', 'ADV'), ('you', 'PRON'), ('can', 'AUX'), ('basically', 'ADV'), ('see', 'VERB'), ('if', 'SCONJ'), ('the', 'DET'), ('word', 'NOUN'), ('is', 'AUX'), ('not', 'PART'), ('in', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'll use a set.\n",
      "POS tags: [('I', 'PRON'), (\"'ll\", 'AUX'), ('use', 'VERB'), ('a', 'DET'), ('set', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Along with that I will download all the all the stop words with respect to English.\n",
      "POS tags: [('Along', 'ADP'), ('with', 'ADP'), ('that', 'SCONJ'), ('I', 'PRON'), ('will', 'AUX'), ('download', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('all', 'DET'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('English', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So why I'm using step set because some of the words may get repeated.\n",
      "POS tags: [('So', 'ADV'), ('why', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('using', 'VERB'), ('step', 'NOUN'), ('set', 'VERB'), ('because', 'SCONJ'), ('some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('words', 'NOUN'), ('may', 'AUX'), ('get', 'AUX'), ('repeated', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I don't want that.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), ('do', 'AUX'), (\"n't\", 'PART'), ('want', 'VERB'), ('that', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'm going to basically write it over here right now through this.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('basically', 'ADV'), ('write', 'VERB'), ('it', 'PRON'), ('over', 'ADV'), ('here', 'ADV'), ('right', 'ADV'), ('now', 'ADV'), ('through', 'ADP'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: What I'm actually going to do I'll get that specific word that is not present in the stop words.\n",
      "POS tags: [('What', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('get', 'VERB'), ('that', 'DET'), ('specific', 'ADJ'), ('word', 'NOUN'), ('that', 'PRON'), ('is', 'AUX'), ('not', 'PART'), ('present', 'ADJ'), ('in', 'ADP'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And only stemming will be getting applied to that specific word.\n",
      "POS tags: [('And', 'CCONJ'), ('only', 'ADV'), ('stemming', 'VERB'), ('will', 'AUX'), ('be', 'AUX'), ('getting', 'AUX'), ('applied', 'VERB'), ('to', 'ADP'), ('that', 'DET'), ('specific', 'ADJ'), ('word', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now here, what I'm actually going to do is that I'm going to save it in a variable called as words\n",
      "\n",
      "perfect.\n",
      "POS tags: [('Now', 'ADV'), ('here', 'ADV'), (',', 'PUNCT'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('save', 'VERB'), ('it', 'PRON'), ('in', 'ADP'), ('a', 'DET'), ('variable', 'NOUN'), ('called', 'VERB'), ('as', 'SCONJ'), ('words', 'NOUN'), ('\\n\\n', 'SPACE'), ('perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I hope it is very much clear.\n",
      "POS tags: [('I', 'PRON'), ('hope', 'VERB'), ('it', 'PRON'), ('is', 'AUX'), ('very', 'ADV'), ('much', 'ADV'), ('clear', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'm getting back everything after doing the stemming back in the words itself.\n",
      "POS tags: [('I', 'PRON'), (\"'m\", 'AUX'), ('getting', 'VERB'), ('back', 'ADV'), ('everything', 'PRON'), ('after', 'ADP'), ('doing', 'VERB'), ('the', 'DET'), ('stemming', 'NOUN'), ('back', 'ADV'), ('in', 'ADP'), ('the', 'DET'), ('words', 'NOUN'), ('itself', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And then finally, what I'm actually going to do is that I'm going to take this sentences, and I'm\n",
      "\n",
      "going to replace it on the same index with respect to this words.\n",
      "POS tags: [('And', 'CCONJ'), ('then', 'ADV'), ('finally', 'ADV'), (',', 'PUNCT'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('take', 'VERB'), ('this', 'DET'), ('sentences', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('\\n\\n', 'SPACE'), ('going', 'VERB'), ('to', 'PART'), ('replace', 'VERB'), ('it', 'PRON'), ('on', 'ADP'), ('the', 'DET'), ('same', 'ADJ'), ('index', 'NOUN'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('this', 'DET'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But once we get this words right, I need to join all these words together.\n",
      "POS tags: [('But', 'CCONJ'), ('once', 'SCONJ'), ('we', 'PRON'), ('get', 'VERB'), ('this', 'DET'), ('words', 'NOUN'), ('right', 'INTJ'), (',', 'PUNCT'), ('I', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('join', 'VERB'), ('all', 'DET'), ('these', 'DET'), ('words', 'NOUN'), ('together', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So how do I join?\n",
      "POS tags: [('So', 'ADV'), ('how', 'SCONJ'), ('do', 'AUX'), ('I', 'PRON'), ('join', 'VERB'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: There will obviously be a space dot.\n",
      "POS tags: [('There', 'PRON'), ('will', 'AUX'), ('obviously', 'ADV'), ('be', 'AUX'), ('a', 'DET'), ('space', 'NOUN'), ('dot', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'll just use dot join so that it will join together and it will convert that into a sentences.\n",
      "POS tags: [('I', 'PRON'), (\"'ll\", 'AUX'), ('just', 'ADV'), ('use', 'VERB'), ('dot', 'NOUN'), ('join', 'NOUN'), ('so', 'SCONJ'), ('that', 'SCONJ'), ('it', 'PRON'), ('will', 'AUX'), ('join', 'VERB'), ('together', 'ADV'), ('and', 'CCONJ'), ('it', 'PRON'), ('will', 'AUX'), ('convert', 'VERB'), ('that', 'PRON'), ('into', 'ADP'), ('a', 'DET'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So this exactly is converting all the words into sentences, right.\n",
      "POS tags: [('So', 'ADV'), ('this', 'PRON'), ('exactly', 'ADV'), ('is', 'AUX'), ('converting', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('words', 'NOUN'), ('into', 'ADP'), ('sentences', 'NOUN'), (',', 'PUNCT'), ('right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: This is very much simple.\n",
      "POS tags: [('This', 'PRON'), ('is', 'AUX'), ('very', 'ADV'), ('much', 'ADV'), ('simple', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And we have actually done this.\n",
      "POS tags: [('And', 'CCONJ'), ('we', 'PRON'), ('have', 'AUX'), ('actually', 'ADV'), ('done', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So here what all things we have done again let me repeat I'm I'm iterating through each and every sentence.\n",
      "POS tags: [('So', 'ADV'), ('here', 'ADV'), ('what', 'PRON'), ('all', 'DET'), ('things', 'NOUN'), ('we', 'PRON'), ('have', 'AUX'), ('done', 'VERB'), ('again', 'ADV'), ('let', 'VERB'), ('me', 'PRON'), ('repeat', 'VERB'), ('I', 'PRON'), (\"'m\", 'AUX'), ('I', 'PRON'), (\"'m\", 'AUX'), ('iterating', 'VERB'), ('through', 'ADP'), ('each', 'PRON'), ('and', 'CCONJ'), ('every', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And then I'm doing a word tokenize that basically means for every sentences I'm getting the list of\n",
      "\n",
      "words.\n",
      "POS tags: [('And', 'CCONJ'), ('then', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('doing', 'VERB'), ('a', 'DET'), ('word', 'NOUN'), ('tokenize', 'NOUN'), ('that', 'PRON'), ('basically', 'ADV'), ('means', 'VERB'), ('for', 'ADP'), ('every', 'DET'), ('sentences', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('getting', 'VERB'), ('the', 'DET'), ('list', 'NOUN'), ('of', 'ADP'), ('\\n\\n', 'SPACE'), ('words', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And from that list of words I'm iterating, I'm seeing that whether it is present in the stop words,\n",
      "\n",
      "if it is not present, I'm doing the stemming.\n",
      "POS tags: [('And', 'CCONJ'), ('from', 'ADP'), ('that', 'DET'), ('list', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('iterating', 'VERB'), (',', 'PUNCT'), ('I', 'PRON'), (\"'m\", 'AUX'), ('seeing', 'VERB'), ('that', 'SCONJ'), ('whether', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('present', 'ADJ'), ('in', 'ADP'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), (',', 'PUNCT'), ('\\n\\n', 'SPACE'), ('if', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('not', 'PART'), ('present', 'ADJ'), (',', 'PUNCT'), ('I', 'PRON'), (\"'m\", 'AUX'), ('doing', 'VERB'), ('the', 'DET'), ('stemming', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: After stemming, I'm again storing back in that same list, and then I'm converting all these words\n",
      "\n",
      "into sentences I can say, converting all the list of words into sentences.\n",
      "POS tags: [('After', 'ADP'), ('stemming', 'VERB'), (',', 'PUNCT'), ('I', 'PRON'), (\"'m\", 'AUX'), ('again', 'ADV'), ('storing', 'VERB'), ('back', 'ADV'), ('in', 'ADP'), ('that', 'DET'), ('same', 'ADJ'), ('list', 'NOUN'), (',', 'PUNCT'), ('and', 'CCONJ'), ('then', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('converting', 'VERB'), ('all', 'DET'), ('these', 'DET'), ('words', 'NOUN'), ('\\n\\n', 'SPACE'), ('into', 'ADP'), ('sentences', 'NOUN'), ('I', 'PRON'), ('can', 'AUX'), ('say', 'VERB'), (',', 'PUNCT'), ('converting', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('list', 'NOUN'), ('of', 'ADP'), ('words', 'NOUN'), ('into', 'ADP'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, once I execute it.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('once', 'SCONJ'), ('I', 'PRON'), ('execute', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And now if I go and see my sentences here, you'll be able to see now I three vision India right in\n",
      "\n",
      "3000 year history.\n",
      "POS tags: [('And', 'CCONJ'), ('now', 'ADV'), ('if', 'SCONJ'), ('I', 'PRON'), ('go', 'VERB'), ('and', 'CCONJ'), ('see', 'VERB'), ('my', 'PRON'), ('sentences', 'NOUN'), ('here', 'ADV'), (',', 'PUNCT'), ('you', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('see', 'VERB'), ('now', 'ADV'), ('I', 'PRON'), ('three', 'NUM'), ('vision', 'NOUN'), ('India', 'PROPN'), ('right', 'ADV'), ('in', 'ADP'), ('\\n\\n', 'SPACE'), ('3000', 'NUM'), ('year', 'NOUN'), ('history', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So here I h I s t o r y became RI okay people, people it became people.\n",
      "POS tags: [('So', 'ADV'), ('here', 'ADV'), ('I', 'PRON'), ('h', 'INTJ'), ('I', 'PRON'), ('s', 'AUX'), ('t', 'NOUN'), ('o', 'PROPN'), ('r', 'PROPN'), ('y', 'PROPN'), ('became', 'VERB'), ('RI', 'PROPN'), ('okay', 'INTJ'), ('people', 'NOUN'), (',', 'PUNCT'), ('people', 'NOUN'), ('it', 'PRON'), ('became', 'VERB'), ('people', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: World came, invaded us, invade it, became captured.\n",
      "POS tags: [('World', 'PROPN'), ('came', 'VERB'), (',', 'PUNCT'), ('invaded', 'VERB'), ('us', 'PRON'), (',', 'PUNCT'), ('invade', 'VERB'), ('it', 'PRON'), (',', 'PUNCT'), ('became', 'AUX'), ('captured', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Land conquer mined from.\n",
      "POS tags: [('Land', 'NOUN'), ('conquer', 'NOUN'), ('mined', 'VERB'), ('from', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You can see all the special words like like I, I have.\n",
      "POS tags: [('You', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('special', 'ADJ'), ('words', 'NOUN'), ('like', 'INTJ'), ('like', 'INTJ'), ('I', 'PRON'), (',', 'PUNCT'), ('I', 'PRON'), ('have', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Everything is gone.\n",
      "POS tags: [('Everything', 'PRON'), ('is', 'AUX'), ('gone', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: See, see this I is there have is gone.\n",
      "POS tags: [('See', 'VERB'), (',', 'PUNCT'), ('see', 'VERB'), ('this', 'PRON'), ('I', 'PRON'), ('is', 'AUX'), ('there', 'PRON'), ('have', 'VERB'), ('is', 'AUX'), ('gone', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Though you will not be able to find out though anyway, right?\n",
      "POS tags: [('Though', 'SCONJ'), ('you', 'PRON'), ('will', 'AUX'), ('not', 'PART'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('find', 'VERB'), ('out', 'ADP'), ('though', 'ADV'), ('anyway', 'ADV'), (',', 'PUNCT'), ('right', 'ADJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: So whatever.\n",
      "POS tags: [('So', 'ADV'), ('whatever', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Stop.\n",
      "POS tags: [('Stop', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Words were present over here that all got removed.\n",
      "POS tags: [('Words', 'NOUN'), ('were', 'AUX'), ('present', 'ADJ'), ('over', 'ADV'), ('here', 'ADV'), ('that', 'PRON'), ('all', 'PRON'), ('got', 'AUX'), ('removed', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And then only we performed the stemming.\n",
      "POS tags: [('And', 'CCONJ'), ('then', 'ADV'), ('only', 'ADV'), ('we', 'PRON'), ('performed', 'VERB'), ('the', 'DET'), ('stemming', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right now you may be saying crush.\n",
      "POS tags: [('Right', 'ADV'), ('now', 'ADV'), ('you', 'PRON'), ('may', 'AUX'), ('be', 'AUX'), ('saying', 'VERB'), ('crush', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh, the stemming does not look very good, right?\n",
      "POS tags: [('Uh', 'INTJ'), (',', 'PUNCT'), ('the', 'DET'), ('stemming', 'NOUN'), ('does', 'AUX'), ('not', 'PART'), ('look', 'VERB'), ('very', 'ADV'), ('good', 'ADJ'), (',', 'PUNCT'), ('right', 'ADJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: So for that, what you need to do, I've already taught you with respect to snowball stemmer, so I\n",
      "\n",
      "will just import this.\n",
      "POS tags: [('So', 'ADV'), ('for', 'ADP'), ('that', 'PRON'), (',', 'PUNCT'), ('what', 'PRON'), ('you', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('do', 'VERB'), (',', 'PUNCT'), ('I', 'PRON'), (\"'ve\", 'AUX'), ('already', 'ADV'), ('taught', 'VERB'), ('you', 'PRON'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('snowball', 'NOUN'), ('stemmer', 'NOUN'), (',', 'PUNCT'), ('so', 'SCONJ'), ('I', 'PRON'), ('\\n\\n', 'SPACE'), ('will', 'AUX'), ('just', 'ADV'), ('import', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And it is very simple.\n",
      "POS tags: [('And', 'CCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('very', 'ADV'), ('simple', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Simple.\n",
      "POS tags: [('Simple', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I think you can do the same task again.\n",
      "POS tags: [('I', 'PRON'), ('think', 'VERB'), ('you', 'PRON'), ('can', 'AUX'), ('do', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('task', 'NOUN'), ('again', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So snowball stemmer and then I will try to import this with respect to English.\n",
      "POS tags: [('So', 'ADV'), ('snowball', 'NOUN'), ('stemmer', 'NOUN'), ('and', 'CCONJ'), ('then', 'ADV'), ('I', 'PRON'), ('will', 'AUX'), ('try', 'VERB'), ('to', 'PART'), ('import', 'VERB'), ('this', 'PRON'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('English', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And obviously after this you'll be able to get good sentence.\n",
      "POS tags: [('And', 'CCONJ'), ('obviously', 'ADV'), ('after', 'ADP'), ('this', 'PRON'), ('you', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('get', 'VERB'), ('good', 'ADJ'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So let me just remove this one.\n",
      "POS tags: [('So', 'ADV'), ('let', 'VERB'), ('me', 'PRON'), ('just', 'ADV'), ('remove', 'VERB'), ('this', 'DET'), ('one', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So snowball stemmer I've already done it and I'm going to copy the same thing.\n",
      "POS tags: [('So', 'ADV'), ('snowball', 'NOUN'), ('stemmer', 'NOUN'), ('I', 'PRON'), (\"'ve\", 'AUX'), ('already', 'ADV'), ('done', 'VERB'), ('it', 'PRON'), ('and', 'CCONJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('copy', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('thing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here I'm just going to say apply snowball stemmer stemming.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('say', 'VERB'), ('apply', 'VERB'), ('snowball', 'ADJ'), ('stemmer', 'NOUN'), ('stemming', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And then instead of stemmer I will just write this word that is snowball stemmer.\n",
      "POS tags: [('And', 'CCONJ'), ('then', 'ADV'), ('instead', 'ADV'), ('of', 'ADP'), ('stemmer', 'NOUN'), ('I', 'PRON'), ('will', 'AUX'), ('just', 'ADV'), ('write', 'VERB'), ('this', 'DET'), ('word', 'NOUN'), ('that', 'PRON'), ('is', 'AUX'), ('snowball', 'NOUN'), ('stemmer', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: That's it.\n",
      "POS tags: [('That', 'PRON'), (\"'s\", 'AUX'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Yeah.\n",
      "POS tags: [('Yeah', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And now once I execute it, uh, let me go back again, back to the sentences, because that sentences\n",
      "\n",
      "have got changed now.\n",
      "POS tags: [('And', 'CCONJ'), ('now', 'ADV'), ('once', 'SCONJ'), ('I', 'PRON'), ('execute', 'VERB'), ('it', 'PRON'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('let', 'VERB'), ('me', 'PRON'), ('go', 'VERB'), ('back', 'ADV'), ('again', 'ADV'), (',', 'PUNCT'), ('back', 'ADV'), ('to', 'ADP'), ('the', 'DET'), ('sentences', 'NOUN'), (',', 'PUNCT'), ('because', 'SCONJ'), ('that', 'SCONJ'), ('sentences', 'NOUN'), ('\\n\\n', 'SPACE'), ('have', 'AUX'), ('got', 'AUX'), ('changed', 'VERB'), ('now', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So where is the sentences?\n",
      "POS tags: [('So', 'ADV'), ('where', 'SCONJ'), ('is', 'AUX'), ('the', 'DET'), ('sentences', 'NOUN'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let's see.\n",
      "POS tags: [('Let', 'VERB'), (\"'s\", 'PRON'), ('see', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now this is the sentences I've got executed now.\n",
      "POS tags: [('Now', 'INTJ'), ('this', 'PRON'), ('is', 'AUX'), ('the', 'DET'), ('sentences', 'NOUN'), ('I', 'PRON'), (\"'ve\", 'AUX'), ('got', 'AUX'), ('executed', 'VERB'), ('now', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now I'm just going to execute this.\n",
      "POS tags: [('Now', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('execute', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now if I probably go and see my sentences here, you can see that now it is good right now.\n",
      "POS tags: [('Now', 'INTJ'), ('if', 'SCONJ'), ('I', 'PRON'), ('probably', 'ADV'), ('go', 'VERB'), ('and', 'CCONJ'), ('see', 'VERB'), ('my', 'PRON'), ('sentences', 'NOUN'), ('here', 'ADV'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('that', 'SCONJ'), ('now', 'ADV'), ('it', 'PRON'), ('is', 'AUX'), ('good', 'ADJ'), ('right', 'ADV'), ('now', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So uh, one more important thing that snowball has done.\n",
      "POS tags: [('So', 'ADV'), ('uh', 'INTJ'), (',', 'PUNCT'), ('one', 'NUM'), ('more', 'ADV'), ('important', 'ADJ'), ('thing', 'NOUN'), ('that', 'PRON'), ('snowball', 'NOUN'), ('has', 'AUX'), ('done', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: See over here, I still have capital letters, right?\n",
      "POS tags: [('See', 'VERB'), ('over', 'ADP'), ('here', 'ADV'), (',', 'PUNCT'), ('I', 'PRON'), ('still', 'ADV'), ('have', 'VERB'), ('capital', 'NOUN'), ('letters', 'NOUN'), (',', 'PUNCT'), ('right', 'ADJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: Like there may be some of the sentences which may be in small letter it also.\n",
      "POS tags: [('Like', 'INTJ'), ('there', 'PRON'), ('may', 'AUX'), ('be', 'AUX'), ('some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('sentences', 'NOUN'), ('which', 'PRON'), ('may', 'AUX'), ('be', 'AUX'), ('in', 'ADP'), ('small', 'ADJ'), ('letter', 'NOUN'), ('it', 'PRON'), ('also', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So that becomes a repeated word.\n",
      "POS tags: [('So', 'ADV'), ('that', 'PRON'), ('becomes', 'VERB'), ('a', 'DET'), ('repeated', 'VERB'), ('word', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But since this is a capital letter, it will be considered as a separate word right for the model to\n",
      "\n",
      "understand.\n",
      "POS tags: [('But', 'CCONJ'), ('since', 'SCONJ'), ('this', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('capital', 'NOUN'), ('letter', 'NOUN'), (',', 'PUNCT'), ('it', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('considered', 'VERB'), ('as', 'ADP'), ('a', 'DET'), ('separate', 'ADJ'), ('word', 'NOUN'), ('right', 'NOUN'), ('for', 'SCONJ'), ('the', 'DET'), ('model', 'NOUN'), ('to', 'PART'), ('\\n\\n', 'SPACE'), ('understand', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right?\n",
      "POS tags: [('Right', 'INTJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: So what it does is that snowball.\n",
      "POS tags: [('So', 'ADV'), ('what', 'PRON'), ('it', 'PRON'), ('does', 'AUX'), ('is', 'AUX'), ('that', 'PRON'), ('snowball', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: One more advantage is that it is making sure that all the letter is becoming small.\n",
      "POS tags: [('One', 'NUM'), ('more', 'ADJ'), ('advantage', 'NOUN'), ('is', 'AUX'), ('that', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('making', 'VERB'), ('sure', 'ADJ'), ('that', 'SCONJ'), ('all', 'DET'), ('the', 'DET'), ('letter', 'NOUN'), ('is', 'AUX'), ('becoming', 'VERB'), ('small', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So all the letter is becoming small.\n",
      "POS tags: [('So', 'ADV'), ('all', 'DET'), ('the', 'DET'), ('letter', 'NOUN'), ('is', 'AUX'), ('becoming', 'VERB'), ('small', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And for some of the words it is not even giving a good result like poverty has become poverty.\n",
      "POS tags: [('And', 'CCONJ'), ('for', 'ADP'), ('some', 'PRON'), ('of', 'ADP'), ('the', 'DET'), ('words', 'NOUN'), ('it', 'PRON'), ('is', 'AUX'), ('not', 'PART'), ('even', 'ADV'), ('giving', 'VERB'), ('a', 'DET'), ('good', 'ADJ'), ('result', 'NOUN'), ('like', 'ADP'), ('poverty', 'NOUN'), ('has', 'AUX'), ('become', 'VERB'), ('poverty', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But if you try to do this with the help of Lemmatization, you can also get a good word.\n",
      "POS tags: [('But', 'CCONJ'), ('if', 'SCONJ'), ('you', 'PRON'), ('try', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('this', 'PRON'), ('with', 'ADP'), ('the', 'DET'), ('help', 'NOUN'), ('of', 'ADP'), ('Lemmatization', 'PROPN'), (',', 'PUNCT'), ('you', 'PRON'), ('can', 'AUX'), ('also', 'ADV'), ('get', 'VERB'), ('a', 'DET'), ('good', 'ADJ'), ('word', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now let's try it with the help of Lemmatization.\n",
      "POS tags: [('Now', 'INTJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('try', 'VERB'), ('it', 'PRON'), ('with', 'ADP'), ('the', 'DET'), ('help', 'NOUN'), ('of', 'ADP'), ('Lemmatization', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'm just going to, uh, do the same thing.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('do', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('thing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay?\n",
      "POS tags: [('Okay', 'INTJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: I hope everybody is understood with respect to snowball stemmer.\n",
      "POS tags: [('I', 'PRON'), ('hope', 'VERB'), ('everybody', 'PRON'), ('is', 'AUX'), ('understood', 'VERB'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('snowball', 'NOUN'), ('stemmer', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, what I'm going to do is that again, going to go back to my Lemmatization code.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('what', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('again', 'ADV'), (',', 'PUNCT'), ('going', 'VERB'), ('to', 'PART'), ('go', 'VERB'), ('back', 'ADV'), ('to', 'ADP'), ('my', 'PRON'), ('Lemmatization', 'PROPN'), ('code', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'm just going to import this NLTK dot stem.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('import', 'VERB'), ('this', 'DET'), ('NLTK', 'NOUN'), ('dot', 'NOUN'), ('stem', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And it is very simple guys.\n",
      "POS tags: [('And', 'CCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('very', 'ADV'), ('simple', 'ADJ'), ('guys', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I think we are just repeating things so that you also practice in a better way okay.\n",
      "POS tags: [('I', 'PRON'), ('think', 'VERB'), ('we', 'PRON'), ('are', 'AUX'), ('just', 'ADV'), ('repeating', 'VERB'), ('things', 'NOUN'), ('so', 'SCONJ'), ('that', 'SCONJ'), ('you', 'PRON'), ('also', 'ADV'), ('practice', 'VERB'), ('in', 'ADP'), ('a', 'DET'), ('better', 'ADJ'), ('way', 'NOUN'), ('okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: so here I've got the word net lemmatizer I'm going to initialize it.\n",
      "POS tags: [('so', 'ADV'), ('here', 'ADV'), ('I', 'PRON'), (\"'ve\", 'AUX'), ('got', 'VERB'), ('the', 'DET'), ('word', 'NOUN'), ('net', 'NOUN'), ('lemmatizer', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('initialize', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: This is done.\n",
      "POS tags: [('This', 'PRON'), ('is', 'AUX'), ('done', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now I'm going to go to go ahead and copy the same code right.\n",
      "POS tags: [('Now', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('go', 'VERB'), ('to', 'PART'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('copy', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('code', 'NOUN'), ('right', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And I will just write it over here.\n",
      "POS tags: [('And', 'CCONJ'), ('I', 'PRON'), ('will', 'AUX'), ('just', 'ADV'), ('write', 'VERB'), ('it', 'PRON'), ('over', 'ADV'), ('here', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And instead of writing snowball I'm just going to copy this I'm going to paste it over here.\n",
      "POS tags: [('And', 'CCONJ'), ('instead', 'ADV'), ('of', 'ADP'), ('writing', 'VERB'), ('snowball', 'NOUN'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('copy', 'VERB'), ('this', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('paste', 'VERB'), ('it', 'PRON'), ('over', 'ADP'), ('here', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I've done it.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'ve\", 'AUX'), ('done', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But let me just go ahead and execute the sentence part again because I need to get the updated sentence.\n",
      "POS tags: [('But', 'CCONJ'), ('let', 'VERB'), ('me', 'PRON'), ('just', 'ADV'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('execute', 'VERB'), ('the', 'DET'), ('sentence', 'NOUN'), ('part', 'NOUN'), ('again', 'ADV'), ('because', 'SCONJ'), ('I', 'PRON'), ('need', 'VERB'), ('to', 'PART'), ('get', 'VERB'), ('the', 'DET'), ('updated', 'VERB'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I think it is somewhere here.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), ('think', 'VERB'), ('it', 'PRON'), ('is', 'AUX'), ('somewhere', 'ADV'), ('here', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Paragraph.\n",
      "POS tags: [('Paragraph', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And uh, here is the sentence.\n",
      "POS tags: [('And', 'CCONJ'), ('uh', 'INTJ'), (',', 'PUNCT'), ('here', 'ADV'), ('is', 'AUX'), ('the', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now let me just go ahead and execute the same thing.\n",
      "POS tags: [('Now', 'INTJ'), ('let', 'VERB'), ('me', 'PRON'), ('just', 'ADV'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('execute', 'VERB'), ('the', 'DET'), ('same', 'ADJ'), ('thing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And now if you okay I'm getting an A has no Stem okay.\n",
      "POS tags: [('And', 'CCONJ'), ('now', 'ADV'), ('if', 'SCONJ'), ('you', 'PRON'), ('okay', 'ADJ'), ('I', 'PRON'), (\"'m\", 'AUX'), ('getting', 'VERB'), ('an', 'DET'), ('A', 'NOUN'), ('has', 'VERB'), ('no', 'DET'), ('Stem', 'PROPN'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Sorry.\n",
      "POS tags: [('Sorry', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: It should be lemmatize.\n",
      "POS tags: [('It', 'PRON'), ('should', 'AUX'), ('be', 'AUX'), ('lemmatize', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Lemmatize.\n",
      "POS tags: [('Lemmatize', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So Lemmatize or Lemmatize.\n",
      "POS tags: [('So', 'ADV'), ('Lemmatize', 'PROPN'), ('or', 'CCONJ'), ('Lemmatize', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, as you see, some time it took.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('as', 'SCONJ'), ('you', 'PRON'), ('see', 'VERB'), (',', 'PUNCT'), ('some', 'DET'), ('time', 'NOUN'), ('it', 'PRON'), ('took', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right?\n",
      "POS tags: [('Right', 'INTJ'), ('?', 'PUNCT')]\n",
      "\n",
      "Original sentence: Because it is basically checking from the entire corpus.\n",
      "POS tags: [('Because', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('basically', 'ADV'), ('checking', 'VERB'), ('from', 'ADP'), ('the', 'DET'), ('entire', 'ADJ'), ('corpus', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now if I probably go and see the sentences now, you have all amazing things with respect to words that\n",
      "\n",
      "are coming up correctly and all the things are here, right.\n",
      "POS tags: [('Now', 'INTJ'), ('if', 'SCONJ'), ('I', 'PRON'), ('probably', 'ADV'), ('go', 'VERB'), ('and', 'CCONJ'), ('see', 'VERB'), ('the', 'DET'), ('sentences', 'NOUN'), ('now', 'ADV'), (',', 'PUNCT'), ('you', 'PRON'), ('have', 'VERB'), ('all', 'DET'), ('amazing', 'ADJ'), ('things', 'NOUN'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('words', 'NOUN'), ('that', 'PRON'), ('\\n\\n', 'SPACE'), ('are', 'AUX'), ('coming', 'VERB'), ('up', 'ADP'), ('correctly', 'ADV'), ('and', 'CCONJ'), ('all', 'DET'), ('the', 'DET'), ('things', 'NOUN'), ('are', 'AUX'), ('here', 'ADV'), (',', 'PUNCT'), ('right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So with respect to this, you are able to get some good thing.\n",
      "POS tags: [('So', 'ADV'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('this', 'PRON'), (',', 'PUNCT'), ('you', 'PRON'), ('are', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('get', 'VERB'), ('some', 'DET'), ('good', 'ADJ'), ('thing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now one more thing you can do is that after this word you can also put the post tag.\n",
      "POS tags: [('Now', 'ADV'), ('one', 'NUM'), ('more', 'ADJ'), ('thing', 'NOUN'), ('you', 'PRON'), ('can', 'AUX'), ('do', 'VERB'), ('is', 'AUX'), ('that', 'SCONJ'), ('after', 'ADP'), ('this', 'DET'), ('word', 'NOUN'), ('you', 'PRON'), ('can', 'AUX'), ('also', 'ADV'), ('put', 'VERB'), ('the', 'DET'), ('post', 'NOUN'), ('tag', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now if you put the post tag to V right now, you see what will be the output.\n",
      "POS tags: [('Now', 'INTJ'), ('if', 'SCONJ'), ('you', 'PRON'), ('put', 'VERB'), ('the', 'DET'), ('post', 'NOUN'), ('tag', 'NOUN'), ('to', 'ADP'), ('V', 'PROPN'), ('right', 'ADV'), ('now', 'ADV'), (',', 'PUNCT'), ('you', 'PRON'), ('see', 'VERB'), ('what', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('the', 'DET'), ('output', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You'll get a better output I guess because most of the words it will be basically considering as, um,\n",
      "\n",
      "you know, as an adverb or sorry as a verb.\n",
      "POS tags: [('You', 'PRON'), (\"'ll\", 'AUX'), ('get', 'VERB'), ('a', 'DET'), ('better', 'ADJ'), ('output', 'NOUN'), ('I', 'PRON'), ('guess', 'VERB'), ('because', 'SCONJ'), ('most', 'ADJ'), ('of', 'ADP'), ('the', 'DET'), ('words', 'NOUN'), ('it', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('basically', 'ADV'), ('considering', 'VERB'), ('as', 'ADP'), (',', 'PUNCT'), ('um', 'INTJ'), (',', 'PUNCT'), ('\\n\\n', 'SPACE'), ('you', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('as', 'ADP'), ('an', 'DET'), ('adverb', 'NOUN'), ('or', 'CCONJ'), ('sorry', 'ADJ'), ('as', 'ADP'), ('a', 'DET'), ('verb', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So but anyhow, we will try to understand about post tag again.\n",
      "POS tags: [('So', 'ADV'), ('but', 'CCONJ'), ('anyhow', 'ADV'), (',', 'PUNCT'), ('we', 'PRON'), ('will', 'AUX'), ('try', 'VERB'), ('to', 'PART'), ('understand', 'VERB'), ('about', 'ADP'), ('post', 'NOUN'), ('tag', 'NOUN'), ('again', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: More more things.\n",
      "POS tags: [('More', 'ADV'), ('more', 'ADJ'), ('things', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I three visions India in 3000 years history people come would world come invade us capture land.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), ('three', 'NUM'), ('visions', 'NOUN'), ('India', 'PROPN'), ('in', 'ADP'), ('3000', 'NUM'), ('years', 'NOUN'), ('history', 'NOUN'), ('people', 'NOUN'), ('come', 'VERB'), ('would', 'AUX'), ('world', 'NOUN'), ('come', 'VERB'), ('invade', 'VERB'), ('us', 'PRON'), ('capture', 'NOUN'), ('land', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So all the stop words has got deleted.\n",
      "POS tags: [('So', 'ADV'), ('all', 'DET'), ('the', 'DET'), ('stop', 'NOUN'), ('words', 'NOUN'), ('has', 'AUX'), ('got', 'AUX'), ('deleted', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now we are getting a very good one.\n",
      "POS tags: [('Now', 'ADV'), ('we', 'PRON'), ('are', 'AUX'), ('getting', 'VERB'), ('a', 'DET'), ('very', 'ADV'), ('good', 'ADJ'), ('one', 'NUM'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You know, uh, at least better than stemming.\n",
      "POS tags: [('You', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('at', 'ADP'), ('least', 'ADV'), ('better', 'ADJ'), ('than', 'ADP'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And the other one that is snowball stemming.\n",
      "POS tags: [('And', 'CCONJ'), ('the', 'DET'), ('other', 'ADJ'), ('one', 'NOUN'), ('that', 'PRON'), ('is', 'AUX'), ('snowball', 'NOUN'), ('stemming', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So this was the entire process with respect to text pre-processing.\n",
      "POS tags: [('So', 'ADV'), ('this', 'PRON'), ('was', 'AUX'), ('the', 'DET'), ('entire', 'ADJ'), ('process', 'NOUN'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('text', 'NOUN'), ('pre', 'NOUN'), ('-', 'ADJ'), ('processing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And here we have discussed with stop words and how you should also go ahead and do the text pre-processing.\n",
      "POS tags: [('And', 'CCONJ'), ('here', 'ADV'), ('we', 'PRON'), ('have', 'AUX'), ('discussed', 'VERB'), ('with', 'ADP'), ('stop', 'NOUN'), ('words', 'NOUN'), ('and', 'CCONJ'), ('how', 'SCONJ'), ('you', 'PRON'), ('should', 'AUX'), ('also', 'ADV'), ('go', 'VERB'), ('ahead', 'ADV'), ('and', 'CCONJ'), ('do', 'VERB'), ('the', 'DET'), ('text', 'NOUN'), ('pre', 'NOUN'), ('-', 'ADJ'), ('processing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I hope everybody got that idea.\n",
      "POS tags: [('I', 'PRON'), ('hope', 'VERB'), ('everybody', 'PRON'), ('got', 'VERB'), ('that', 'DET'), ('idea', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now in Lemmatization also you can see that it is not lowering it.\n",
      "POS tags: [('Now', 'ADV'), ('in', 'ADP'), ('Lemmatization', 'PROPN'), ('also', 'ADV'), ('you', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('that', 'SCONJ'), ('it', 'PRON'), ('is', 'AUX'), ('not', 'PART'), ('lowering', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So what you can actually do is that you can basically lower all the sentences.\n",
      "POS tags: [('So', 'ADV'), ('what', 'PRON'), ('you', 'PRON'), ('can', 'AUX'), ('actually', 'ADV'), ('do', 'AUX'), ('is', 'AUX'), ('that', 'SCONJ'), ('you', 'PRON'), ('can', 'AUX'), ('basically', 'ADV'), ('lower', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('sentences', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: right.\n",
      "POS tags: [('right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So let's say if you write sentences of I is equal to sentences dot of I dot two lower right.\n",
      "POS tags: [('So', 'ADV'), ('let', 'VERB'), (\"'s\", 'PRON'), ('say', 'VERB'), ('if', 'SCONJ'), ('you', 'PRON'), ('write', 'VERB'), ('sentences', 'NOUN'), ('of', 'ADP'), ('I', 'PRON'), ('is', 'AUX'), ('equal', 'ADJ'), ('to', 'ADP'), ('sentences', 'NOUN'), ('dot', 'NOUN'), ('of', 'ADP'), ('I', 'PRON'), ('dot', 'VERB'), ('two', 'NUM'), ('lower', 'ADJ'), ('right', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So you can basically give two lower.\n",
      "POS tags: [('So', 'ADV'), ('you', 'PRON'), ('can', 'AUX'), ('basically', 'ADV'), ('give', 'VERB'), ('two', 'NUM'), ('lower', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let's see whether it will work or not.\n",
      "POS tags: [('Let', 'VERB'), (\"'s\", 'PRON'), ('see', 'VERB'), ('whether', 'SCONJ'), ('it', 'PRON'), ('will', 'AUX'), ('work', 'VERB'), ('or', 'CCONJ'), ('not', 'PART'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh, and uh let's see whether it will completely work or not.\n",
      "POS tags: [('Uh', 'INTJ'), (',', 'PUNCT'), ('and', 'CCONJ'), ('uh', 'INTJ'), ('let', 'VERB'), (\"'s\", 'PRON'), ('see', 'VERB'), ('whether', 'SCONJ'), ('it', 'PRON'), ('will', 'AUX'), ('completely', 'ADV'), ('work', 'VERB'), ('or', 'CCONJ'), ('not', 'PART'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'm not sure whether dot two lower will work with respect to list, but I think it should work.\n",
      "POS tags: [('I', 'PRON'), (\"'m\", 'AUX'), ('not', 'PART'), ('sure', 'ADJ'), ('whether', 'SCONJ'), ('dot', 'NOUN'), ('two', 'NUM'), ('lower', 'ADJ'), ('will', 'AUX'), ('work', 'VERB'), ('with', 'ADP'), ('respect', 'NOUN'), ('to', 'ADP'), ('list', 'NOUN'), (',', 'PUNCT'), ('but', 'CCONJ'), ('I', 'PRON'), ('think', 'VERB'), ('it', 'PRON'), ('should', 'AUX'), ('work', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'm just going to execute this again.\n",
      "POS tags: [('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('execute', 'VERB'), ('this', 'PRON'), ('again', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Go down okay and apply this Lemmatizer.\n",
      "POS tags: [('Go', 'VERB'), ('down', 'ADP'), ('okay', 'ADV'), ('and', 'CCONJ'), ('apply', 'VERB'), ('this', 'DET'), ('Lemmatizer', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh str object has no attribute to lower okay.\n",
      "POS tags: [('Uh', 'INTJ'), ('str', 'PROPN'), ('object', 'NOUN'), ('has', 'VERB'), ('no', 'DET'), ('attribute', 'NOUN'), ('to', 'PART'), ('lower', 'VERB'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So it's okay.\n",
      "POS tags: [('So', 'ADV'), ('it', 'PRON'), (\"'s\", 'AUX'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Not a problem.\n",
      "POS tags: [('Not', 'PART'), ('a', 'DET'), ('problem', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Not a problem.\n",
      "POS tags: [('Not', 'PART'), ('a', 'DET'), ('problem', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: What I'm actually going to do I'm just going to comment this.\n",
      "POS tags: [('What', 'PRON'), ('I', 'PRON'), (\"'m\", 'AUX'), ('actually', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('do', 'VERB'), ('I', 'PRON'), (\"'m\", 'AUX'), ('just', 'ADV'), ('going', 'VERB'), ('to', 'PART'), ('comment', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And before writing here I'll just say word to lower okay.\n",
      "POS tags: [('And', 'CCONJ'), ('before', 'ADP'), ('writing', 'VERB'), ('here', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('just', 'ADV'), ('say', 'VERB'), ('word', 'NOUN'), ('to', 'PART'), ('lower', 'VERB'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You have to definitely try different different things okay.\n",
      "POS tags: [('You', 'PRON'), ('have', 'VERB'), ('to', 'PART'), ('definitely', 'ADV'), ('try', 'VERB'), ('different', 'ADJ'), ('different', 'ADJ'), ('things', 'NOUN'), ('okay', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And it's all about Google.\n",
      "POS tags: [('And', 'CCONJ'), ('it', 'PRON'), (\"'s\", 'AUX'), ('all', 'ADV'), ('about', 'ADP'), ('Google', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You know, just Google it.\n",
      "POS tags: [('You', 'PRON'), ('know', 'VERB'), (',', 'PUNCT'), ('just', 'ADV'), ('Google', 'PROPN'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You'll be able to get it.\n",
      "POS tags: [('You', 'PRON'), (\"'ll\", 'AUX'), ('be', 'AUX'), ('able', 'ADJ'), ('to', 'PART'), ('get', 'VERB'), ('it', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So again I'm going to execute this.\n",
      "POS tags: [('So', 'ADV'), ('again', 'ADV'), ('I', 'PRON'), (\"'m\", 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('execute', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And now I think it will execute I know it is.\n",
      "POS tags: [('And', 'CCONJ'), ('now', 'ADV'), ('I', 'PRON'), ('think', 'VERB'), ('it', 'PRON'), ('will', 'AUX'), ('execute', 'VERB'), ('I', 'PRON'), ('know', 'VERB'), ('it', 'PRON'), ('is', 'AUX'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I'm doing a lot of up and downs.\n",
      "POS tags: [('I', 'PRON'), (\"'m\", 'AUX'), ('doing', 'VERB'), ('a', 'DET'), ('lot', 'NOUN'), ('of', 'ADP'), ('up', 'NOUN'), ('and', 'CCONJ'), ('downs', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But just try to follow the lecture.\n",
      "POS tags: [('But', 'CCONJ'), ('just', 'ADV'), ('try', 'VERB'), ('to', 'PART'), ('follow', 'VERB'), ('the', 'DET'), ('lecture', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh string object has no attribute to lower y to underscore lower is there.\n",
      "POS tags: [('Uh', 'INTJ'), ('string', 'NOUN'), ('object', 'NOUN'), ('has', 'AUX'), ('no', 'DET'), ('attribute', 'NOUN'), ('to', 'PART'), ('lower', 'ADJ'), ('y', 'PROPN'), ('to', 'PART'), ('underscore', 'VERB'), ('lower', 'ADV'), ('is', 'AUX'), ('there', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: To lower.\n",
      "POS tags: [('To', 'PART'), ('lower', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Um, okay.\n",
      "POS tags: [('Um', 'INTJ'), (',', 'PUNCT'), ('okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let me just see.\n",
      "POS tags: [('Let', 'VERB'), ('me', 'PRON'), ('just', 'ADV'), ('see', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh, str two lower case.\n",
      "POS tags: [('Uh', 'INTJ'), (',', 'PUNCT'), ('str', 'NOUN'), ('two', 'NUM'), ('lower', 'ADJ'), ('case', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Right.\n",
      "POS tags: [('Right', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Python.\n",
      "POS tags: [('Python', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let me just see this.\n",
      "POS tags: [('Let', 'VERB'), ('me', 'PRON'), ('just', 'ADV'), ('see', 'VERB'), ('this', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: It's okay if I don't have any other way to see it, but I think dot lower will definitely work.\n",
      "POS tags: [('It', 'PRON'), (\"'s\", 'AUX'), ('okay', 'ADJ'), ('if', 'SCONJ'), ('I', 'PRON'), ('do', 'AUX'), (\"n't\", 'PART'), ('have', 'VERB'), ('any', 'DET'), ('other', 'ADJ'), ('way', 'NOUN'), ('to', 'PART'), ('see', 'VERB'), ('it', 'PRON'), (',', 'PUNCT'), ('but', 'CCONJ'), ('I', 'PRON'), ('think', 'VERB'), ('dot', 'NOUN'), ('lower', 'ADV'), ('will', 'AUX'), ('definitely', 'ADV'), ('work', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Let's see.\n",
      "POS tags: [('Let', 'VERB'), (\"'s\", 'PRON'), ('see', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Dot lower.\n",
      "POS tags: [('Dot', 'NOUN'), ('lower', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Perfect.\n",
      "POS tags: [('Perfect', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: It has worked.\n",
      "POS tags: [('It', 'PRON'), ('has', 'AUX'), ('worked', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Now, now if I go and see the sentences, it has done okay.\n",
      "POS tags: [('Now', 'ADV'), (',', 'PUNCT'), ('now', 'ADV'), ('if', 'SCONJ'), ('I', 'PRON'), ('go', 'VERB'), ('and', 'CCONJ'), ('see', 'VERB'), ('the', 'DET'), ('sentences', 'NOUN'), (',', 'PUNCT'), ('it', 'PRON'), ('has', 'AUX'), ('done', 'VERB'), ('okay', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I don't have any any regrets to search in the Google.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), ('do', 'AUX'), (\"n't\", 'PART'), ('have', 'VERB'), ('any', 'DET'), ('any', 'DET'), ('regrets', 'NOUN'), ('to', 'PART'), ('search', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('Google', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: You should also do the search in the Google.\n",
      "POS tags: [('You', 'PRON'), ('should', 'AUX'), ('also', 'ADV'), ('do', 'VERB'), ('the', 'DET'), ('search', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('Google', 'PROPN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So now here you can see all the small letters are there along with the lemmatization.\n",
      "POS tags: [('So', 'ADV'), ('now', 'ADV'), ('here', 'ADV'), ('you', 'PRON'), ('can', 'AUX'), ('see', 'VERB'), ('all', 'DET'), ('the', 'DET'), ('small', 'ADJ'), ('letters', 'NOUN'), ('are', 'AUX'), ('there', 'ADV'), ('along', 'ADP'), ('with', 'ADP'), ('the', 'DET'), ('lemmatization', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So this is the entire text pre-processing.\n",
      "POS tags: [('So', 'ADV'), ('this', 'PRON'), ('is', 'AUX'), ('the', 'DET'), ('entire', 'ADJ'), ('text', 'NOUN'), ('pre', 'NOUN'), ('-', 'ADJ'), ('processing', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We can also apply some regular expression before this so that we can do the cleaning of the sentence.\n",
      "POS tags: [('We', 'PRON'), ('can', 'AUX'), ('also', 'ADV'), ('apply', 'VERB'), ('some', 'DET'), ('regular', 'ADJ'), ('expression', 'NOUN'), ('before', 'ADP'), ('this', 'PRON'), ('so', 'SCONJ'), ('that', 'SCONJ'), ('we', 'PRON'), ('can', 'AUX'), ('do', 'VERB'), ('the', 'DET'), ('cleaning', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'll remove this word.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('remove', 'VERB'), ('this', 'DET'), ('word', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: And I think uh, this will also work if I probably just comment this out with to lower or just lower.\n",
      "POS tags: [('And', 'CCONJ'), ('I', 'PRON'), ('think', 'VERB'), ('uh', 'INTJ'), (',', 'PUNCT'), ('this', 'PRON'), ('will', 'AUX'), ('also', 'ADV'), ('work', 'VERB'), ('if', 'SCONJ'), ('I', 'PRON'), ('probably', 'ADV'), ('just', 'ADV'), ('comment', 'VERB'), ('this', 'PRON'), ('out', 'ADP'), ('with', 'ADP'), ('to', 'PART'), ('lower', 'VERB'), ('or', 'CCONJ'), ('just', 'ADV'), ('lower', 'ADJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Just check it out.\n",
      "POS tags: [('Just', 'ADV'), ('check', 'VERB'), ('it', 'PRON'), ('out', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: It is up to you.\n",
      "POS tags: [('It', 'PRON'), ('is', 'AUX'), ('up', 'ADP'), ('to', 'ADP'), ('you', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So I'll just comment this out so that you can try it out.\n",
      "POS tags: [('So', 'ADV'), ('I', 'PRON'), (\"'ll\", 'AUX'), ('just', 'ADV'), ('comment', 'VERB'), ('this', 'PRON'), ('out', 'ADP'), ('so', 'SCONJ'), ('that', 'SCONJ'), ('you', 'PRON'), ('can', 'AUX'), ('try', 'VERB'), ('it', 'PRON'), ('out', 'ADP'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay.\n",
      "POS tags: [('Okay', 'INTJ'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: But in short, uh, we have understood what Stopwords can actually do and how we can basically apply\n",
      "\n",
      "things.\n",
      "POS tags: [('But', 'CCONJ'), ('in', 'ADP'), ('short', 'ADJ'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('we', 'PRON'), ('have', 'AUX'), ('understood', 'VERB'), ('what', 'PRON'), ('Stopwords', 'PROPN'), ('can', 'AUX'), ('actually', 'ADV'), ('do', 'VERB'), ('and', 'CCONJ'), ('how', 'SCONJ'), ('we', 'PRON'), ('can', 'AUX'), ('basically', 'ADV'), ('apply', 'VERB'), ('\\n\\n', 'SPACE'), ('things', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Okay, so yes, uh, this was it from my side.\n",
      "POS tags: [('Okay', 'INTJ'), (',', 'PUNCT'), ('so', 'ADV'), ('yes', 'INTJ'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('this', 'PRON'), ('was', 'AUX'), ('it', 'PRON'), ('from', 'ADP'), ('my', 'PRON'), ('side', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: I think you are liking this entire series.\n",
      "POS tags: [('I', 'PRON'), ('think', 'VERB'), ('you', 'PRON'), ('are', 'AUX'), ('liking', 'VERB'), ('this', 'DET'), ('entire', 'ADJ'), ('series', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh, we will be learning more things as we go ahead.\n",
      "POS tags: [('Uh', 'INTJ'), (',', 'PUNCT'), ('we', 'PRON'), ('will', 'AUX'), ('be', 'AUX'), ('learning', 'VERB'), ('more', 'ADJ'), ('things', 'NOUN'), ('as', 'SCONJ'), ('we', 'PRON'), ('go', 'VERB'), ('ahead', 'ADV'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Um, uh, we have post tags and all.\n",
      "POS tags: [('Um', 'INTJ'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('we', 'PRON'), ('have', 'AUX'), ('post', 'NOUN'), ('tags', 'NOUN'), ('and', 'CCONJ'), ('all', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: We have entity name recognitions.\n",
      "POS tags: [('We', 'PRON'), ('have', 'VERB'), ('entity', 'NOUN'), ('name', 'NOUN'), ('recognitions', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Also, many things are there which is going to come.\n",
      "POS tags: [('Also', 'ADV'), (',', 'PUNCT'), ('many', 'ADJ'), ('things', 'NOUN'), ('are', 'AUX'), ('there', 'PRON'), ('which', 'PRON'), ('is', 'AUX'), ('going', 'VERB'), ('to', 'PART'), ('come', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: So yes, uh, keep on learning, keep on practicing.\n",
      "POS tags: [('So', 'ADV'), ('yes', 'INTJ'), (',', 'PUNCT'), ('uh', 'INTJ'), (',', 'PUNCT'), ('keep', 'VERB'), ('on', 'ADP'), ('learning', 'NOUN'), (',', 'PUNCT'), ('keep', 'VERB'), ('on', 'ADP'), ('practicing', 'VERB'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Uh, I will see you all in the next video.\n",
      "POS tags: [('Uh', 'INTJ'), (',', 'PUNCT'), ('I', 'PRON'), ('will', 'AUX'), ('see', 'VERB'), ('you', 'PRON'), ('all', 'PRON'), ('in', 'ADP'), ('the', 'DET'), ('next', 'ADJ'), ('video', 'NOUN'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: Thank you.\n",
      "POS tags: [('Thank', 'VERB'), ('you', 'PRON'), ('.', 'PUNCT')]\n",
      "\n",
      "Original sentence: \n",
      "POS tags: []\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def pos_tag_spacy(sentences):\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(sentence)\n",
    "        print(f\"\\nOriginal sentence: {sentence}\")\n",
    "        print(\"POS tags:\", [(token.text, token.pos_) for token in doc])\n",
    "\n",
    "\n",
    "pos_tag_spacy(sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed18ee",
   "metadata": {},
   "source": [
    "### Nanmed Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "78ff0f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\susha/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to C:\\Users\\susha/nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\susha/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\susha/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41f85810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entities: [('Along seen Lemmatization', 'WORK_OF_ART'), ('Stopwords', 'PRODUCT'), ('Stopwords', 'PERSON'), ('Stopwords', 'PERSON'), ('Stopwords', 'PERSON'), ('one', 'CARDINAL'), ('Abdul Kalam', 'PERSON'), ('India', 'GPE'), ('Stopwords', 'PERSON'), ('three', 'CARDINAL'), ('India', 'GPE'), ('3000 year', 'DATE'), ('two', 'CARDINAL'), ('Stopwords', 'PERSON'), ('Stopwords', 'PERSON'), ('first', 'ORDINAL'), ('Stopwords', 'PERSON'), ('English', 'LANGUAGE'), ('NLP', 'ORG'), ('Stopwords Stopwords', 'PERSON'), ('one', 'CARDINAL'), ('NLTK', 'ORG'), ('Stopwords', 'PRODUCT'), ('Stopwords', 'PERSON'), ('Stopwords', 'PERSON'), ('NLTK', 'ORG'), ('Stopwords', 'PERSON'), ('English', 'LANGUAGE'), ('NLTK', 'ORG'), ('Stopwords', 'ORG'), ('English', 'LANGUAGE'), ('German', 'NORP'), ('English', 'LANGUAGE'), ('Krish', 'NORP'), ('English', 'LANGUAGE'), ('English', 'LANGUAGE'), ('German', 'NORP'), ('German', 'NORP'), ('Along', 'ORG'), ('French', 'NORP'), ('Hindi Arabic', 'PERSON'), ('Arabic', 'LANGUAGE'), ('Arabic', 'NORP'), ('Hindi', 'ORG'), ('Arabic', 'LANGUAGE'), ('English', 'LANGUAGE'), ('two', 'CARDINAL'), ('One', 'CARDINAL'), ('first', 'ORDINAL'), ('first', 'ORDINAL'), ('Porter', 'PERSON'), ('Stemmer', 'ORG'), ('three', 'CARDINAL'), ('India', 'GPE'), ('3000 year', 'DATE'), ('second', 'ORDINAL'), ('Third', 'ORDINAL'), ('Fourth', 'ORDINAL'), ('one', 'CARDINAL'), ('Perfect', 'PERSON'), ('Porter Stemmer Sorry', 'PERSON'), ('First', 'ORDINAL'), ('first', 'ORDINAL'), ('Zero', 'CARDINAL'), ('Perfect', 'WORK_OF_ART'), ('one', 'CARDINAL'), ('First', 'ORDINAL'), ('English', 'NORP'), ('Perfect', 'ORG'), ('Perfect', 'PRODUCT'), ('Perfect', 'WORK_OF_ART'), ('three', 'CARDINAL'), ('India', 'GPE'), ('3000 year', 'DATE'), ('Stop Words', 'ORG'), ('English', 'NORP'), ('one', 'CARDINAL'), ('one', 'CARDINAL'), ('One', 'CARDINAL'), ('Lemmatization', 'PRODUCT'), ('Lemmatization', 'PRODUCT'), ('Lemmatization', 'PRODUCT'), ('Paragraph Okay', 'ORG'), ('three', 'CARDINAL'), ('India', 'GPE'), ('3000 year', 'DATE'), ('one', 'CARDINAL'), ('Lemmatization', 'PRODUCT'), ('two', 'CARDINAL'), ('two', 'CARDINAL'), ('two', 'CARDINAL'), ('Lemmatizer', 'PRODUCT'), ('Google', 'ORG'), ('Google', 'ORG'), ('two', 'CARDINAL'), ('Right Python', 'ORG'), ('Dot', 'PERSON'), ('Google', 'ORG'), ('Google', 'ORG'), ('Stopwords', 'PERSON')]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load SpaCy's English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_named_entities(words):\n",
    "    \"\"\"\n",
    "    Extracts named entities from a list of words using SpaCy NER.\n",
    "\n",
    "    Args:\n",
    "        words (list of str): List of tokenized words.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (entity_text, entity_label).\n",
    "    \"\"\"\n",
    "    # Join the words into a full sentence\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    # Run SpaCy NLP pipeline\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Extract named entities\n",
    "    named_entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    \n",
    "    return named_entities\n",
    "\n",
    "named_entities = extract_named_entities(words)\n",
    "\n",
    "\n",
    "print(\"Named Entities:\", named_entities)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad3b865",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

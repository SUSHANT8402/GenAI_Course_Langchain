{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87842dcf",
   "metadata": {},
   "source": [
    "# DAY 4 - 4TH JUNE,2025\n",
    "\n",
    "## NLP PRACTICALS\n",
    "\n",
    "##### NLTK is a leading platform for building pyhton programs to work with human language data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3323c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f843a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=\"\"\"\n",
    "Natural Language Processing (NLP) corpus data refers to large, structured or unstructured collections of text that are used for training, evaluating,\n",
    "or testing NLP models and algorithms. These corpora can vary widely in language, domain, size, and annotation type, depending on the intended \n",
    "application—such as sentiment analysis, machine translation, named entity recognition, question answering, or speech recognition. Some well-known \n",
    "general-purpose corpora include the Penn Treebank, which contains syntactically annotated English text; the British National Corpus (BNC), representing a \n",
    "wide cross-section of modern British English; and the Common Crawl, a vast web archive used for large-scale pretraining. Domain-specific corpora also \n",
    "exist, like MIMIC for medical text, the Reuters Corpus for financial news, and Enron emails for corporate communication. Additionally, many corpora are \n",
    "annotated with linguistic information such as part-of-speech tags, syntactic trees, semantic roles, discourse structure, or sentiment labels. In \n",
    "multilingual and cross-lingual NLP, parallel corpora like Europarl or OPUS are widely used, offering aligned sentences in multiple languages to support \n",
    "machine translation and language modeling. Speech and conversational datasets, such as LibriSpeech and Switchboard, provide transcribed audio for speech \n",
    "recognition and dialog systems. With the rise of deep learning, massive unlabeled corpora—like books, web pages, or social media posts—are often used for \n",
    "self-supervised pretraining of transformer models such as BERT, GPT, or T5. Proper use and curation of corpus data are crucial for mitigating biases, \n",
    "ensuring linguistic diversity, and improving the generalization and fairness of NLP systems.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a9b473b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Natural Language Processing (NLP) corpus data refers to large, structured or unstructured collections of text that are used for training, evaluating,\n",
      "or testing NLP models and algorithms. These corpora can vary widely in language, domain, size, and annotation type, depending on the intended \n",
      "application—such as sentiment analysis, machine translation, named entity recognition, question answering, or speech recognition. Some well-known \n",
      "general-purpose corpora include the Penn Treebank, which contains syntactically annotated English text; the British National Corpus (BNC), representing a \n",
      "wide cross-section of modern British English; and the Common Crawl, a vast web archive used for large-scale pretraining. Domain-specific corpora also \n",
      "exist, like MIMIC for medical text, the Reuters Corpus for financial news, and Enron emails for corporate communication. Additionally, many corpora are \n",
      "annotated with linguistic information such as part-of-speech tags, syntactic trees, semantic roles, discourse structure, or sentiment labels. In \n",
      "multilingual and cross-lingual NLP, parallel corpora like Europarl or OPUS are widely used, offering aligned sentences in multiple languages to support \n",
      "machine translation and language modeling. Speech and conversational datasets, such as LibriSpeech and Switchboard, provide transcribed audio for speech \n",
      "recognition and dialog systems. With the rise of deep learning, massive unlabeled corpora—like books, web pages, or social media posts—are often used for \n",
      "self-supervised pretraining of transformer models such as BERT, GPT, or T5. Proper use and curation of corpus data are crucial for mitigating biases, \n",
      "ensuring linguistic diversity, and improving the generalization and fairness of NLP systems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d614be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\susha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5c7d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tokenization\n",
    "#### paragraphs --> sentences\n",
    "\n",
    "####### this is not working\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(corpus)\n",
    "\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "509aa3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural Language Processing (NLP) corpus data refers to large, structured or unstructured collections of text that are used for training, evaluating, or testing NLP models and algorithms.', 'These corpora can vary widely in language, domain, size, and annotation type, depending on the intended  application—such as sentiment analysis, machine translation, named entity recognition, question answering, or speech recognition.', 'Some well-known  general-purpose corpora include the Penn Treebank, which contains syntactically annotated English text; the British National Corpus (BNC), representing a  wide cross-section of modern British English; and the Common Crawl, a vast web archive used for large-scale pretraining.', 'Domain-specific corpora also  exist, like MIMIC for medical text, the Reuters Corpus for financial news, and Enron emails for corporate communication.', 'Additionally, many corpora are  annotated with linguistic information such as part-of-speech tags, syntactic trees, semantic roles, discourse structure, or sentiment labels.', 'In  multilingual and cross-lingual NLP, parallel corpora like Europarl or OPUS are widely used, offering aligned sentences in multiple languages to support  machine translation and language modeling.', 'Speech and conversational datasets, such as LibriSpeech and Switchboard, provide transcribed audio for speech  recognition and dialog systems.', 'With the rise of deep learning, massive unlabeled corpora—like books, web pages, or social media posts—are often used for  self-supervised pretraining of transformer models such as BERT, GPT, or T5.', 'Proper use and curation of corpus data are crucial for mitigating biases,  ensuring linguistic diversity, and improving the generalization and fairness of NLP systems.']\n"
     ]
    }
   ],
   "source": [
    "# Split text into sentences by splitting on '. ' and then clean up whitespace/newlines\n",
    "sentences = [sentence.strip().replace('\\n', ' ') for sentence in corpus.split('. ') if sentence]\n",
    "\n",
    "# Add '.' back to the end of each sentence except the last if not present\n",
    "for i in range(len(sentences) - 1):\n",
    "    if not sentences[i].endswith('.'):\n",
    "        sentences[i] += '.'\n",
    "\n",
    "# Output list of sentences\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddaf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = word_tokenize(corpus)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf67cc53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'corpus',\n",
       " 'data',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'large',\n",
       " ',',\n",
       " 'structured',\n",
       " 'or',\n",
       " 'unstructured',\n",
       " 'collections',\n",
       " 'of',\n",
       " 'text',\n",
       " 'that',\n",
       " 'are',\n",
       " 'used',\n",
       " 'for',\n",
       " 'training',\n",
       " ',',\n",
       " 'evaluating',\n",
       " ',',\n",
       " 'or',\n",
       " 'testing',\n",
       " 'NLP',\n",
       " 'models',\n",
       " 'and',\n",
       " 'algorithms',\n",
       " '.',\n",
       " 'These',\n",
       " 'corpora',\n",
       " 'can',\n",
       " 'vary',\n",
       " 'widely',\n",
       " 'in',\n",
       " 'language',\n",
       " ',',\n",
       " 'domain',\n",
       " ',',\n",
       " 'size',\n",
       " ',',\n",
       " 'and',\n",
       " 'annotation',\n",
       " 'type',\n",
       " ',',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'the',\n",
       " 'intended',\n",
       " 'application',\n",
       " '—',\n",
       " 'such',\n",
       " 'as',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'question',\n",
       " 'answering',\n",
       " ',',\n",
       " 'or',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " '.',\n",
       " 'Some',\n",
       " 'well',\n",
       " '-',\n",
       " 'known',\n",
       " 'general',\n",
       " '-',\n",
       " 'purpose',\n",
       " 'corpora',\n",
       " 'include',\n",
       " 'the',\n",
       " 'Penn',\n",
       " 'Treebank',\n",
       " ',',\n",
       " 'which',\n",
       " 'contains',\n",
       " 'syntactically',\n",
       " 'annotated',\n",
       " 'English',\n",
       " 'text',\n",
       " ';',\n",
       " 'the',\n",
       " 'British',\n",
       " 'National',\n",
       " 'Corpus',\n",
       " '(',\n",
       " 'BNC',\n",
       " '),',\n",
       " 'representing',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'cross',\n",
       " '-',\n",
       " 'section',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'British',\n",
       " 'English',\n",
       " ';',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Common',\n",
       " 'Crawl',\n",
       " ',',\n",
       " 'a',\n",
       " 'vast',\n",
       " 'web',\n",
       " 'archive',\n",
       " 'used',\n",
       " 'for',\n",
       " 'large',\n",
       " '-',\n",
       " 'scale',\n",
       " 'pretraining',\n",
       " '.',\n",
       " 'Domain',\n",
       " '-',\n",
       " 'specific',\n",
       " 'corpora',\n",
       " 'also',\n",
       " 'exist',\n",
       " ',',\n",
       " 'like',\n",
       " 'MIMIC',\n",
       " 'for',\n",
       " 'medical',\n",
       " 'text',\n",
       " ',',\n",
       " 'the',\n",
       " 'Reuters',\n",
       " 'Corpus',\n",
       " 'for',\n",
       " 'financial',\n",
       " 'news',\n",
       " ',',\n",
       " 'and',\n",
       " 'Enron',\n",
       " 'emails',\n",
       " 'for',\n",
       " 'corporate',\n",
       " 'communication',\n",
       " '.',\n",
       " 'Additionally',\n",
       " ',',\n",
       " 'many',\n",
       " 'corpora',\n",
       " 'are',\n",
       " 'annotated',\n",
       " 'with',\n",
       " 'linguistic',\n",
       " 'information',\n",
       " 'such',\n",
       " 'as',\n",
       " 'part',\n",
       " '-',\n",
       " 'of',\n",
       " '-',\n",
       " 'speech',\n",
       " 'tags',\n",
       " ',',\n",
       " 'syntactic',\n",
       " 'trees',\n",
       " ',',\n",
       " 'semantic',\n",
       " 'roles',\n",
       " ',',\n",
       " 'discourse',\n",
       " 'structure',\n",
       " ',',\n",
       " 'or',\n",
       " 'sentiment',\n",
       " 'labels',\n",
       " '.',\n",
       " 'In',\n",
       " 'multilingual',\n",
       " 'and',\n",
       " 'cross',\n",
       " '-',\n",
       " 'lingual',\n",
       " 'NLP',\n",
       " ',',\n",
       " 'parallel',\n",
       " 'corpora',\n",
       " 'like',\n",
       " 'Europarl',\n",
       " 'or',\n",
       " 'OPUS',\n",
       " 'are',\n",
       " 'widely',\n",
       " 'used',\n",
       " ',',\n",
       " 'offering',\n",
       " 'aligned',\n",
       " 'sentences',\n",
       " 'in',\n",
       " 'multiple',\n",
       " 'languages',\n",
       " 'to',\n",
       " 'support',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'and',\n",
       " 'language',\n",
       " 'modeling',\n",
       " '.',\n",
       " 'Speech',\n",
       " 'and',\n",
       " 'conversational',\n",
       " 'datasets',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'LibriSpeech',\n",
       " 'and',\n",
       " 'Switchboard',\n",
       " ',',\n",
       " 'provide',\n",
       " 'transcribed',\n",
       " 'audio',\n",
       " 'for',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " 'and',\n",
       " 'dialog',\n",
       " 'systems',\n",
       " '.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'massive',\n",
       " 'unlabeled',\n",
       " 'corpora',\n",
       " '—',\n",
       " 'like',\n",
       " 'books',\n",
       " ',',\n",
       " 'web',\n",
       " 'pages',\n",
       " ',',\n",
       " 'or',\n",
       " 'social',\n",
       " 'media',\n",
       " 'posts',\n",
       " '—',\n",
       " 'are',\n",
       " 'often',\n",
       " 'used',\n",
       " 'for',\n",
       " 'self',\n",
       " '-',\n",
       " 'supervised',\n",
       " 'pretraining',\n",
       " 'of',\n",
       " 'transformer',\n",
       " 'models',\n",
       " 'such',\n",
       " 'as',\n",
       " 'BERT',\n",
       " ',',\n",
       " 'GPT',\n",
       " ',',\n",
       " 'or',\n",
       " 'T5',\n",
       " '.',\n",
       " 'Proper',\n",
       " 'use',\n",
       " 'and',\n",
       " 'curation',\n",
       " 'of',\n",
       " 'corpus',\n",
       " 'data',\n",
       " 'are',\n",
       " 'crucial',\n",
       " 'for',\n",
       " 'mitigating',\n",
       " 'biases',\n",
       " ',',\n",
       " 'ensuring',\n",
       " 'linguistic',\n",
       " 'diversity',\n",
       " ',',\n",
       " 'and',\n",
       " 'improving',\n",
       " 'the',\n",
       " 'generalization',\n",
       " 'and',\n",
       " 'fairness',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " '.']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2e16c493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Processing',\n",
       " '(',\n",
       " 'NLP',\n",
       " ')',\n",
       " 'corpus',\n",
       " 'data',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'large',\n",
       " ',',\n",
       " 'structured',\n",
       " 'or',\n",
       " 'unstructured',\n",
       " 'collections',\n",
       " 'of',\n",
       " 'text',\n",
       " 'that',\n",
       " 'are',\n",
       " 'used',\n",
       " 'for',\n",
       " 'training',\n",
       " ',',\n",
       " 'evaluating',\n",
       " ',',\n",
       " 'or',\n",
       " 'testing',\n",
       " 'NLP',\n",
       " 'models',\n",
       " 'and',\n",
       " 'algorithms.',\n",
       " 'These',\n",
       " 'corpora',\n",
       " 'can',\n",
       " 'vary',\n",
       " 'widely',\n",
       " 'in',\n",
       " 'language',\n",
       " ',',\n",
       " 'domain',\n",
       " ',',\n",
       " 'size',\n",
       " ',',\n",
       " 'and',\n",
       " 'annotation',\n",
       " 'type',\n",
       " ',',\n",
       " 'depending',\n",
       " 'on',\n",
       " 'the',\n",
       " 'intended',\n",
       " 'application—such',\n",
       " 'as',\n",
       " 'sentiment',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'machine',\n",
       " 'translation',\n",
       " ',',\n",
       " 'named',\n",
       " 'entity',\n",
       " 'recognition',\n",
       " ',',\n",
       " 'question',\n",
       " 'answering',\n",
       " ',',\n",
       " 'or',\n",
       " 'speech',\n",
       " 'recognition.',\n",
       " 'Some',\n",
       " 'well-known',\n",
       " 'general-purpose',\n",
       " 'corpora',\n",
       " 'include',\n",
       " 'the',\n",
       " 'Penn',\n",
       " 'Treebank',\n",
       " ',',\n",
       " 'which',\n",
       " 'contains',\n",
       " 'syntactically',\n",
       " 'annotated',\n",
       " 'English',\n",
       " 'text',\n",
       " ';',\n",
       " 'the',\n",
       " 'British',\n",
       " 'National',\n",
       " 'Corpus',\n",
       " '(',\n",
       " 'BNC',\n",
       " ')',\n",
       " ',',\n",
       " 'representing',\n",
       " 'a',\n",
       " 'wide',\n",
       " 'cross-section',\n",
       " 'of',\n",
       " 'modern',\n",
       " 'British',\n",
       " 'English',\n",
       " ';',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Common',\n",
       " 'Crawl',\n",
       " ',',\n",
       " 'a',\n",
       " 'vast',\n",
       " 'web',\n",
       " 'archive',\n",
       " 'used',\n",
       " 'for',\n",
       " 'large-scale',\n",
       " 'pretraining.',\n",
       " 'Domain-specific',\n",
       " 'corpora',\n",
       " 'also',\n",
       " 'exist',\n",
       " ',',\n",
       " 'like',\n",
       " 'MIMIC',\n",
       " 'for',\n",
       " 'medical',\n",
       " 'text',\n",
       " ',',\n",
       " 'the',\n",
       " 'Reuters',\n",
       " 'Corpus',\n",
       " 'for',\n",
       " 'financial',\n",
       " 'news',\n",
       " ',',\n",
       " 'and',\n",
       " 'Enron',\n",
       " 'emails',\n",
       " 'for',\n",
       " 'corporate',\n",
       " 'communication.',\n",
       " 'Additionally',\n",
       " ',',\n",
       " 'many',\n",
       " 'corpora',\n",
       " 'are',\n",
       " 'annotated',\n",
       " 'with',\n",
       " 'linguistic',\n",
       " 'information',\n",
       " 'such',\n",
       " 'as',\n",
       " 'part-of-speech',\n",
       " 'tags',\n",
       " ',',\n",
       " 'syntactic',\n",
       " 'trees',\n",
       " ',',\n",
       " 'semantic',\n",
       " 'roles',\n",
       " ',',\n",
       " 'discourse',\n",
       " 'structure',\n",
       " ',',\n",
       " 'or',\n",
       " 'sentiment',\n",
       " 'labels.',\n",
       " 'In',\n",
       " 'multilingual',\n",
       " 'and',\n",
       " 'cross-lingual',\n",
       " 'NLP',\n",
       " ',',\n",
       " 'parallel',\n",
       " 'corpora',\n",
       " 'like',\n",
       " 'Europarl',\n",
       " 'or',\n",
       " 'OPUS',\n",
       " 'are',\n",
       " 'widely',\n",
       " 'used',\n",
       " ',',\n",
       " 'offering',\n",
       " 'aligned',\n",
       " 'sentences',\n",
       " 'in',\n",
       " 'multiple',\n",
       " 'languages',\n",
       " 'to',\n",
       " 'support',\n",
       " 'machine',\n",
       " 'translation',\n",
       " 'and',\n",
       " 'language',\n",
       " 'modeling.',\n",
       " 'Speech',\n",
       " 'and',\n",
       " 'conversational',\n",
       " 'datasets',\n",
       " ',',\n",
       " 'such',\n",
       " 'as',\n",
       " 'LibriSpeech',\n",
       " 'and',\n",
       " 'Switchboard',\n",
       " ',',\n",
       " 'provide',\n",
       " 'transcribed',\n",
       " 'audio',\n",
       " 'for',\n",
       " 'speech',\n",
       " 'recognition',\n",
       " 'and',\n",
       " 'dialog',\n",
       " 'systems.',\n",
       " 'With',\n",
       " 'the',\n",
       " 'rise',\n",
       " 'of',\n",
       " 'deep',\n",
       " 'learning',\n",
       " ',',\n",
       " 'massive',\n",
       " 'unlabeled',\n",
       " 'corpora—like',\n",
       " 'books',\n",
       " ',',\n",
       " 'web',\n",
       " 'pages',\n",
       " ',',\n",
       " 'or',\n",
       " 'social',\n",
       " 'media',\n",
       " 'posts—are',\n",
       " 'often',\n",
       " 'used',\n",
       " 'for',\n",
       " 'self-supervised',\n",
       " 'pretraining',\n",
       " 'of',\n",
       " 'transformer',\n",
       " 'models',\n",
       " 'such',\n",
       " 'as',\n",
       " 'BERT',\n",
       " ',',\n",
       " 'GPT',\n",
       " ',',\n",
       " 'or',\n",
       " 'T5.',\n",
       " 'Proper',\n",
       " 'use',\n",
       " 'and',\n",
       " 'curation',\n",
       " 'of',\n",
       " 'corpus',\n",
       " 'data',\n",
       " 'are',\n",
       " 'crucial',\n",
       " 'for',\n",
       " 'mitigating',\n",
       " 'biases',\n",
       " ',',\n",
       " 'ensuring',\n",
       " 'linguistic',\n",
       " 'diversity',\n",
       " ',',\n",
       " 'and',\n",
       " 'improving',\n",
       " 'the',\n",
       " 'generalization',\n",
       " 'and',\n",
       " 'fairness',\n",
       " 'of',\n",
       " 'NLP',\n",
       " 'systems',\n",
       " '.']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "tokenizer=TreebankWordTokenizer()\n",
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa635a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
